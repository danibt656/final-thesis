{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1216511f",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "### - Fuzzy Loss Function\n",
    "\n",
    "### - Training a Net with FuzzyLoss (ft. pytorch_lightning)\n",
    "\n",
    "#### a1) ResNet50\n",
    "\n",
    "#### a2) ResNeXt50_32x4d\n",
    "\n",
    "#### b) VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ddd4569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, ConcatDataset\n",
    "import torchmetrics\n",
    "\n",
    "from fuzzylogic.classes import Domain, Set, Rule\n",
    "from fuzzylogic.hedges import very\n",
    "from fuzzylogic.functions import R, S, alpha, triangular\n",
    "\n",
    "from System import FICAR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# from ray import tune\n",
    "# from ray.tune.integration.pytorch_lightning import TuneReportCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eabf350",
   "metadata": {},
   "source": [
    "# Fuzzy Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f60cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from FuzzyLoss import FuzzyLoss\n",
    "\n",
    "class FL_FCS():\n",
    "    \"\"\" Fuzzy Control System for Focal Loss \"\"\"\n",
    "    def __init__(self):\n",
    "        # Definir dominios de inputs y output\n",
    "        self.balance_deg = Domain(\"balance_deg\", 0, 1, res=0.1)\n",
    "        self.balance_deg.low = S(0.2, 0.8)\n",
    "        self.balance_deg.high = R(0.2,0.8)\n",
    "\n",
    "        self.loss_tminus = Domain(\"loss_tminus\", 0, 2, res=0.01)\n",
    "        self.loss_tminus.low = S(0.25, 1.75)\n",
    "        self.loss_tminus.med = triangular(0.25, 1.75, c=1.0)\n",
    "        self.loss_tminus.high = R(0.25,1.85)\n",
    "\n",
    "        self.delta_gamma = Domain(\"Delta_gamma\", -0.2, 0.2, res=0.01)\n",
    "        self.delta_gamma.ne = S(-0.2, -0.0)\n",
    "        self.delta_gamma.ze = triangular(-0.2, 0.2, c=-0.0)\n",
    "        self.delta_gamma.po = R(0.0, 0.2)\n",
    "\n",
    "        # Reglas\n",
    "        R1 = Rule({(self.balance_deg.low, self.loss_tminus.low): self.delta_gamma.ne})\n",
    "        R2 = Rule({(self.balance_deg.low, self.loss_tminus.med): self.delta_gamma.ne})\n",
    "        R3 = Rule({(self.balance_deg.low, self.loss_tminus.high): self.delta_gamma.ze})\n",
    "        R4 = Rule({(self.balance_deg.high, self.loss_tminus.low): self.delta_gamma.ze})\n",
    "        R5 = Rule({(self.balance_deg.high, self.loss_tminus.med): self.delta_gamma.po})\n",
    "        R6 = Rule({(self.balance_deg.high, self.loss_tminus.high): self.delta_gamma.po})\n",
    "        self.rules = R1 | R2 | R3 | R4 | R5 | R6\n",
    "    \n",
    "    def evaluate(self, bd, lt):\n",
    "        \"\"\" return how much to change current gamma in terms of:\n",
    "            - current class' balance degree\n",
    "            - current focal loss for current class, obtained during step\n",
    "        \"\"\"\n",
    "        values = {self.balance_deg: bd, self.loss_tminus: lt}\n",
    "        delta_gamma = self.rules(values)\n",
    "        return delta_gamma\n",
    "\n",
    "    \n",
    "class FuzzyLoss(torch.nn.CrossEntropyLoss):\n",
    "    \"\"\" Fuzzy-Adaptive Focal Loss\n",
    "    \n",
    "    gamma in [0, +inf)\n",
    "    alpha in [0, 1]\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=0, class_sizes=[1,1], alpha=None):\n",
    "        super(FuzzyLoss, self).__init__()\n",
    "        \n",
    "        self.class_sizes = np.array(class_sizes)\n",
    "        self.n_classes = len(self.class_sizes)\n",
    "        # balance degree of each class (size_i / max(size_j))\n",
    "        self.balance_deg = dict((i, class_sizes[i]/max(class_sizes)) for i in range(len(class_sizes)))\n",
    "        \n",
    "        # initially all classes with same gamma\n",
    "        self.gamma = dict((i, gamma) for i in range(self.n_classes))\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        \n",
    "        self.FCS = FL_FCS()\n",
    "\n",
    "    def forward(self, input_, target):\n",
    "        if input_.dim()>2:\n",
    "            input_ = input_.view(input_.size(0),input_.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input_ = input_.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input_ = input_.contiguous().view(-1,input_.size(2))   # N,H*W,C => N*H*W,C\n",
    "        ground_truth = target\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input_, dim=1)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = logpt.data.exp()\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input_.data.type():\n",
    "                self.alpha = self.alpha.type_as(input_.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "        \n",
    "        loss = torch.Tensor([0.0]*len(pt))\n",
    "        for i, (pt_, logpt_) in enumerate(zip(pt, logpt)):\n",
    "            curr_class = ground_truth[i].item()\n",
    "            # la loss de cada instancia del batch evaluada con su gamma respectiva\n",
    "            loss[i] = -1 * (1-pt_)**self.gamma[curr_class] * logpt_\n",
    "        \n",
    "        # tanto la media como el loss para cada _Instancia_\n",
    "        return loss.mean(), loss\n",
    "        \n",
    "    def update_hyperparams(self, current_losses, targets, alpha=None):\n",
    "        \"\"\" update each class' gamma based on:\n",
    "            - that class's balance degree\n",
    "            - that class's loss in current step\n",
    "        \"\"\"\n",
    "        if alpha is not None:\n",
    "            self.alpha = alpha\n",
    "        if len(current_losses) != len(targets):\n",
    "            raise ValueError('current loss must be same length as targets!')\n",
    "        \n",
    "        # obtener loss media para cada clase\n",
    "        class_loss = {}\n",
    "        targets = targets.cpu().numpy()\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] not in class_loss:\n",
    "                class_loss[targets[i]] = np.array([current_losses[i].item()])\n",
    "            else:\n",
    "                class_loss[targets[i]] = np.append(class_loss[targets[i]], current_losses[i].item())\n",
    "        for k in class_loss.keys():\n",
    "            class_loss[k] = class_loss[k].mean()\n",
    "        \n",
    "        for i in range(self.n_classes):\n",
    "            try:\n",
    "                delta_gamma = self.FCS.evaluate(self.balance_deg[i], class_loss[i])\n",
    "            except:\n",
    "                delta_gamma = 0\n",
    "            self.gamma[i] += delta_gamma\n",
    "            self.gamma[i] = max(self.gamma[i], 0) # enforce gamma >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c20691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF-CELoss :  1.0661571\n",
      "FuzzyLoss':  1.0661571\n",
      "FuzzyLoss\":  1.0661571\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.tensor([0,  1], dtype=torch.int64)\n",
    "y_pred = torch.tensor([[.7 , 0 , 0 ,0 ,  .3], [0, 0.9, 0, 0.1, 0]])\n",
    "\n",
    "print('DF-CELoss : ', torch.nn.CrossEntropyLoss()(y_pred, y_true).numpy())\n",
    "\n",
    "fuzzyloss = FuzzyLoss(gamma=0., class_sizes=[500,5000])\n",
    "loss, losses = fuzzyloss(y_pred, y_true)\n",
    "print('FuzzyLoss\\': ', loss.numpy())\n",
    "fuzzyloss.update_hyperparams(losses, y_true)\n",
    "print('FuzzyLoss\": ', loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a154ade",
   "metadata": {},
   "source": [
    "# Training a Net with FuzzyLoss (ft. `pytorch_lightning`)\n",
    "\n",
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51825087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from System import get_dataloaders_from_path, plot_images_sample\n",
    "\n",
    "dataloaders, dataset_sizes, class_names = get_dataloaders_from_path('../data/PlantVillage/')\n",
    "plot_images_sample(dataloaders['train'])\n",
    "print('NTrain:', len(dataloaders['train'])*32, '// NVal:', len(dataloaders['val'])*32) # 32-img batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e1d2a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "EPOCHS = 200\n",
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "class ResNetCustom(pl.LightningModule):\n",
    "    def __init__(self, gamma=0., class_sizes=[1,1]):\n",
    "        super().__init__()\n",
    "        self.n_classes = len(class_sizes)\n",
    "        \n",
    "        # metrics\n",
    "        task = \"multiclass\" if self.n_classes > 2 else \"binary\"\n",
    "        self.accuracy = torchmetrics.Accuracy(task=task, num_classes=self.n_classes)\n",
    "        self.f1score = torchmetrics.F1Score(task=task, num_classes=self.n_classes)\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.n_classes, bias=True)\n",
    "            \n",
    "        self.fuzzyloss = FuzzyLoss(gamma=gamma, class_sizes=class_sizes).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        y_onehot = F.one_hot(y, num_classes=self.n_classes).long()\n",
    "        acc = self.accuracy(logits, y_onehot)\n",
    "        f1s = self.f1score(logits, y_onehot)\n",
    "        mean_acc.append(acc.item())\n",
    "        mean_f1s.append(f1s.item())\n",
    "        \n",
    "        mean_loss, losses = self.fuzzyloss(logits, y)\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "        # Update focal loss with Fuzzy Control System\n",
    "#         self.fuzzyloss.update_hyperparams(losses, y)\n",
    "        return mean_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "#         return torch.optim.RMSprop(self.parameters(), lr=0.005)\n",
    "#         return torch.optim.SGD(self.model[0].fc.parameters(), lr=0.001, momentum=0.9)\n",
    "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=1e-4)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
    "                                optimizer ,max_lr=0.01,\n",
    "                                steps_per_epoch=len(dataloaders['train']),\n",
    "                                epochs=EPOCHS)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2e3c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ResNetCustom(gamma=0., class_sizes=[1591,373])\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=EPOCHS, devices=1, accelerator=\"gpu\")\n",
    "trainer.fit(model, dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e564303e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean loss\n",
    "x_axis = [i for i in range(200)]\n",
    "\n",
    "splits=49\n",
    "plt.plot(x_axis, [sum(mean_losses[i:i + splits])/splits for i in range(0, len(mean_losses), splits)], 'g', label='Loss')\n",
    "# plt.plot(x_axis, [sum(mean_acc[i:i + splits])/splits for i in range(0, len(mean_acc), splits)], 'b', label='n')\n",
    "plt.plot(x_axis, [sum(mean_f1s[i:i + splits])/splits for i in range(0, len(mean_f1s), splits)], 'r', label='F1-score')\n",
    "plt.title('Training metrics')\n",
    "plt.xlabel('Épocas')\n",
    "# plt.ylabel('Loss media')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70b9c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"saves/resnet50_PlantVillage_focalloss_transfer.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e46d4c",
   "metadata": {},
   "source": [
    "Now we can reload it w/o training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6ab7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(x, model: pl.LightningModule):\n",
    "    model.freeze() # prepares model for predicting\n",
    "    probabilities = torch.softmax(model(x), dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "inference_model = ResNetCustom.load_from_checkpoint(\"saves/resnet50_PlantVillage_focalloss_transfer.pt\", map_location=\"cuda\", gamma=0., class_sizes=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c153411b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37311891ab5640a297cf9b62fe879154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "true_y, pred_y = [], []\n",
    "for batch in tqdm(iter(dataloaders['val']), total=len(dataloaders['val'])):\n",
    "    x, y = batch\n",
    "    true_y.extend(y)\n",
    "    preds, probs = get_prediction(x, inference_model)\n",
    "    pred_y.extend(preds.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "51ce571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.972     0.975       326\n",
      "           1      0.892     0.914     0.902        81\n",
      "\n",
      "    accuracy                          0.961       407\n",
      "   macro avg      0.935     0.943     0.939       407\n",
      "weighted avg      0.961     0.961     0.961       407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(true_y, pred_y, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12164889",
   "metadata": {},
   "source": [
    "## ResNet50 + transfer learning + 5-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda0a22",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Plant Village</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 1591 / Class 1: 373 / BDeg:  4.265415549597855\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_dataset = datasets.ImageFolder('../data/PlantVillage/train',data_transforms)\n",
    "\n",
    "# Provocar bias cogiendo un porcentaje de la clase 1 solamente (modificando el porcentaje hasta obtener b_deg deseado)\n",
    "class_0_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==0).flatten()\n",
    "class_1_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==1).flatten()\n",
    "# class_1_idxs = class_1_idxs[torch.randperm(len(class_1_idxs))[:int(len(class_1_idxs)*.209)]]\n",
    "\n",
    "c0_s, c1_s = len(class_0_idxs), len(class_1_idxs)\n",
    "b_deg = c0_s / c1_s\n",
    "print('Class 0:', len(class_0_idxs), '/ Class 1:', len(class_1_idxs), '/ BDeg: ', b_deg)\n",
    "\n",
    "class_1_subset = Subset(image_dataset, class_1_idxs)\n",
    "class_0_subset = Subset(image_dataset, class_0_idxs)\n",
    "image_dataset = ConcatDataset([class_0_subset, class_1_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aefa2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "class ResNetCustom(pl.LightningModule):\n",
    "    def __init__(self, config, class_sizes):\n",
    "        super().__init__()\n",
    "        self.gamma = config['gamma']\n",
    "        self.class_sizes = class_sizes\n",
    "        self.lr = config['lr']\n",
    "        self.n_classes = len(self.class_sizes)\n",
    "        \n",
    "        # metrics\n",
    "        task = \"multiclass\" if self.n_classes > 2 else \"binary\"\n",
    "        self.accuracy = torchmetrics.Accuracy(task=task, num_classes=self.n_classes)\n",
    "        self.f1score = torchmetrics.F1Score(task=task, num_classes=self.n_classes)\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.n_classes, bias=True)\n",
    "            \n",
    "        self.fuzzyloss = FuzzyLoss(gamma=self.gamma, class_sizes=self.class_sizes).cuda()\n",
    "#         self.fuzzyloss = nn.CrossEntropyLoss().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        y_onehot = F.one_hot(y, num_classes=self.n_classes).long()\n",
    "        acc = self.accuracy(logits, y_onehot)\n",
    "        f1s = self.f1score(logits, y_onehot)\n",
    "        mean_acc.append(acc.item())\n",
    "        mean_f1s.append(f1s.item())\n",
    "        \n",
    "        mean_loss, losses = self.fuzzyloss(logits, y)\n",
    "#         mean_loss = self.fuzzyloss(logits, y)\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "        # Update focal loss with Fuzzy Control System\n",
    "        self.fuzzyloss.update_hyperparams(losses, y)\n",
    "        return mean_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=self.lr)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
    "                                optimizer ,max_lr=0.01,\n",
    "                                steps_per_epoch=self.SPE,\n",
    "                                epochs=self.EPOCHS)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2762076c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.89it/s, loss=0.0592, v_num=172]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0592, v_num=172]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:41,  1.07s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.10s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.284, v_num=173] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.284, v_num=173]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.10s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.09s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.09s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.09s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.08s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:24,  1.07s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:23,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:22,  1.08s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:21<00:21,  1.09s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.0312, v_num=174]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0312, v_num=174]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.18s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:34,  1.22s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:33,  1.25s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:32,  1.25s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:31,  1.25s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:30,  1.27s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.22s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:25,  1.17s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.10s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.87it/s, loss=0.0432, v_num=175]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0432, v_num=175]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.12s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:37,  1.08s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.13s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.16s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.15s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.12s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0369, v_num=176]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0369, v_num=176]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:39,  1.01s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:51,  1.40s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:46,  1.30s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.24s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:40,  1.18s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.10s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.09s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.08s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:27,  1.10s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:25,  1.08s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.09s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:22,  1.08s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.13s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.09s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.08s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.10s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.281, v_num=177] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.281, v_num=177]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:41,  1.07s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.10s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.09s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.10s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.11s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:23,  1.15s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:22,  1.17s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:21,  1.17s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.09s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.08s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.09s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:12,  1.07s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:11,  1.08s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.09s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.12s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.88it/s, loss=0.0784, v_num=178]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0784, v_num=178]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.16s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.09s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.07s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.07s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:10<00:32,  1.08s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.10s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.09s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:22,  1.09s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:21<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:31<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.07s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.08s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.08s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.08s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.09s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:42<00:01,  1.08s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0579, v_num=179]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0579, v_num=179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.15s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.11s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.10s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.09s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.09s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.09s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.09s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.09s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.0407, v_num=180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0407, v_num=180]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.08s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.09s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.09s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.18s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.16s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.13s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.13s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.108, v_num=181] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.108, v_num=181]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.15s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.16s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.16s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0637, v_num=182]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0637, v_num=182]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.09s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:36,  1.08s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.08s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.07s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.07s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:10<00:32,  1.09s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.11s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.11s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.10s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.09s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.08s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.10s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.10s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.0735, v_num=183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0735, v_num=183]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:39,  1.08s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.09s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.10s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.18s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:30,  1.18s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:29,  1.17s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.10s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.10s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.09s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.23, v_num=184]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.23, v_num=184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.09s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.08s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:32,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.09s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.09s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.10s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.10s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:23,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.08s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.09s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.10s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:31<00:11,  1.09s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.09s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.09s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:42<00:01,  1.09s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.87it/s, loss=0.071, v_num=185] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.071, v_num=185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:32,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:31,  1.10s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.08s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.09s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.09s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:22,  1.09s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.09s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.08s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.10s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0528, v_num=186]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0528, v_num=186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.08s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.08s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.09s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.09s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:21,  1.09s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.09s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.09s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.09s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.12s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.09s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0479, v_num=187]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0479, v_num=187]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.19s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.18s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.16s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.15s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.13s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.13s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.11s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.10s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.15s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.16s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0436, v_num=188]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0436, v_num=188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.11s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0496, v_num=189]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0496, v_num=189]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.14s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.87it/s, loss=0.0372, v_num=190]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0372, v_num=190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:39,  1.01s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:39,  1.03s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:39,  1.08s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.09s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.09s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.08s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.08s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.07s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:10<00:32,  1.08s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:11<00:31,  1.08s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:12<00:30,  1.10s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.09s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:21<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.09s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.09s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:31<00:11,  1.08s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:32<00:10,  1.09s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.08s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.08s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.07s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.08s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:42<00:01,  1.09s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0835, v_num=191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0835, v_num=191]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.08s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.09s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.10s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.09s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.08s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.012, v_num=192] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.012, v_num=192]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.09s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:32,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:31,  1.10s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:27,  1.19s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.13s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0126, v_num=193]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0126, v_num=193]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.15s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.17s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.16s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.17s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.17s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0361, v_num=194] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.82it/s, loss=0.0361, v_num=194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.13s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.10s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0262, v_num=195] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.0262, v_num=195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.16s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.14s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.13s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0498, v_num=196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.0498, v_num=196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:36,  1.07s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.09s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.08s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:10<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.10s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.10s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.09s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:22,  1.08s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:21<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.09s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.08s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.17s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.24, v_num=197]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.82it/s, loss=0.24, v_num=197]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.10s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.09s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.262, v_num=198] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.262, v_num=198]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.14s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.13s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.13s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.15s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0741, v_num=199]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.0741, v_num=199]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.14s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.08s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.09s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.09s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.10s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.09s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.08s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.09s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.10s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.14s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.299, v_num=200] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.81it/s, loss=0.299, v_num=200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.09s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:40,  1.08s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.17s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.16s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.16s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.16s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.17s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.17s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.15s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.12s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.12s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0356, v_num=201]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.80it/s, loss=0.0356, v_num=201]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.09s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.07s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.10s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:23,  1.08s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.10s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.08s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:12,  1.07s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:11,  1.09s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.12s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0222, v_num=202]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.80it/s, loss=0.0222, v_num=202]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:46,  1.19s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.17s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:39,  1.17s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.16s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.13s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:29,  1.14s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:18,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.82it/s, loss=0.258, v_num=203] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.80it/s, loss=0.258, v_num=203]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:38,  1.16s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.16s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.16s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.15s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.18s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.15s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.17s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.18s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:23,  1.17s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.16s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:21,  1.17s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.17s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.17s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.18s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.15s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.14s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.204, v_num=204]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.204, v_num=204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.16s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.16s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.15s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:23,  1.16s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.17s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.16s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.16s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.15s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.16s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.0329, v_num=205] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.0329, v_num=205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.17s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.15s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.81it/s, loss=0.0961, v_num=206] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.78it/s, loss=0.0961, v_num=206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.14s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:37,  1.15s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.16s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.15s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.15s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:09,  1.09s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.09s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.81it/s, loss=0.0581, v_num=207] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.78it/s, loss=0.0581, v_num=207]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.15s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.15s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.16s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.15s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.18s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.22s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:14,  1.24s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:13,  1.25s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:12,  1.27s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:11,  1.27s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.24s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.23s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.21s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:41<00:05,  1.20s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.19s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.19s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:46<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.80it/s, loss=0.0803, v_num=208]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.78it/s, loss=0.0803, v_num=208]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.17s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.16s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.17s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.17s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.16s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.15s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:17,  1.09s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.14s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.16s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.14s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.15s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.16s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.103, v_num=209] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:57<00:00,  2.76it/s, loss=0.103, v_num=209]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.15s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.15s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.16s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.17s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:15,  1.17s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.18s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.18s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.17s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.0179, v_num=210] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:57<00:00,  2.77it/s, loss=0.0179, v_num=210]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.14s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.15s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:20,  1.19s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:19,  1.21s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.19s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.19s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.19s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:14,  1.17s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.16s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.16s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.16s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.022, v_num=211] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:57<00:00,  2.76it/s, loss=0.022, v_num=211]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.15s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.15s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.14s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.16s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.16s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.16s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.16s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:56<00:00,  2.77it/s, loss=0.0604, v_num=212]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.75it/s, loss=0.0604, v_num=212]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.12s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.17s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.15s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:15,  1.16s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.15s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.17s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.16s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.16s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.18s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.76it/s, loss=0.296, v_num=213] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.74it/s, loss=0.296, v_num=213]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.12s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.14s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.15s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.17s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.16s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.15s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.21s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.19s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.75it/s, loss=0.0821, v_num=214] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.73it/s, loss=0.0821, v_num=214]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.16s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.18s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:41,  1.18s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:40,  1.18s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.17s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.16s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.16s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.16s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.18s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.19s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:27,  1.18s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:23,  1.16s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.16s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.16s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.16s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.16s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.16s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.14s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.17s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.19s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.19s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.19s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.18s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.18s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.16s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.15s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.16s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.75it/s, loss=0.0488, v_num=215] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.72it/s, loss=0.0488, v_num=215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.18s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.16s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.16s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.17s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.17s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.17s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:37,  1.22s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:36,  1.21s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:34,  1.19s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.18s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.16s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.13s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.15s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.15s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.18s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.16s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.16s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.16s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.17s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.18s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.18s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.16s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.18s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.20s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.73it/s, loss=0.0374, v_num=216] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.71it/s, loss=0.0374, v_num=216]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.15s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:39,  1.32s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:36,  1.27s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:34,  1.24s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:33,  1.23s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:31,  1.20s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.19s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:28,  1.20s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.18s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.15s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:27<00:19,  1.16s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:28<00:18,  1.16s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.16s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.16s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.16s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.15s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.15s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.16s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.17s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.18s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.18s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.71it/s, loss=0.0226, v_num=217]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.68it/s, loss=0.0226, v_num=217]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.18s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:41,  1.19s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:40,  1.20s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:39,  1.19s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.18s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.17s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.17s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.17s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.18s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.17s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.16s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.17s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:23,  1.17s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.18s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:21,  1.18s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.17s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:28<00:18,  1.17s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.17s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.18s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.18s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.16s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.15s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.16s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.16s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.16s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.18s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.17s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:46<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.70it/s, loss=0.279, v_num=218] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.67it/s, loss=0.279, v_num=218]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.17s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.16s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.16s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.17s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.18s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.18s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.19s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.18s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.17s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:25,  1.17s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.15s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.15s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.15s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.16s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.66it/s, loss=0.0324, v_num=219] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.63it/s, loss=0.0324, v_num=219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.18s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.17s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.18s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.17s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.18s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.18s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:34,  1.20s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.19s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:32,  1.19s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.18s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.20s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.19s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.18s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:26,  1.21s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:25,  1.21s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:24,  1.22s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.22s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:21,  1.22s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:27<00:20,  1.20s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:28<00:19,  1.19s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.19s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.18s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:15,  1.17s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:33<00:14,  1.19s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:34<00:13,  1.19s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:11,  1.20s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.20s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.19s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:39<00:08,  1.19s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:40<00:07,  1.18s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:41<00:05,  1.18s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.18s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.18s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:45<00:02,  1.18s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:46<00:01,  1.18s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:46<00:00,  1.17s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.66it/s, loss=0.0302, v_num=220] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.64it/s, loss=0.0302, v_num=220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.16s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.15s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.16s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:37,  1.15s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.15s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.16s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.16s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.18s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:27,  1.20s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:26,  1.19s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.18s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:23,  1.18s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.20s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:21,  1.17s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.17s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.17s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.19s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.20s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.19s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:14,  1.17s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:13,  1.18s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:11,  1.16s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.18s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.19s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.17s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.17s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.18s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.19s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.19s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:46<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:00<00:00,  2.62it/s, loss=0.0459, v_num=221] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:00<00:00,  2.60it/s, loss=0.0459, v_num=221]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:48,  1.25s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:46,  1.23s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:45,  1.22s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:44,  1.24s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.25s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.21s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.22s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:38,  1.21s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:37,  1.22s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.21s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.19s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.18s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.19s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:29,  1.19s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:28,  1.20s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.19s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:26,  1.20s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:25,  1.21s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.22s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.23s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:21,  1.22s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:27<00:20,  1.23s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:19,  1.24s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:18,  1.23s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:31<00:17,  1.23s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:16,  1.23s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:14,  1.23s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.23s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:36<00:12,  1.22s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:37<00:10,  1.21s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.20s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.19s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:41<00:07,  1.20s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:42<00:05,  1.20s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:43<00:04,  1.20s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:44<00:03,  1.20s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:46<00:02,  1.19s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:47<00:01,  1.19s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:47<00:00,  1.19s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:01<00:00,  2.57it/s, loss=0.188, v_num=222]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:01<00:00,  2.55it/s, loss=0.188, v_num=222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:47,  1.23s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:46,  1.24s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.25s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:45,  1.26s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.24s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.23s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.23s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.23s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.23s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.22s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.22s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.21s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:32,  1.21s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:31,  1.20s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.20s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:28,  1.20s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.20s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:26,  1.19s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:25,  1.20s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.21s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:22,  1.19s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:21,  1.20s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:27<00:20,  1.19s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:19,  1.20s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:17,  1.19s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:31<00:16,  1.20s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:15,  1.21s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:33<00:14,  1.19s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.20s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:36<00:11,  1.19s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:37<00:10,  1.19s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.19s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:39<00:08,  1.19s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:41<00:07,  1.19s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:42<00:05,  1.20s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:43<00:04,  1.19s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:44<00:03,  1.21s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:45<00:02,  1.20s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:47<00:01,  1.21s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:47<00:00,  1.19s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:01<00:00,  2.56it/s, loss=0.0275, v_num=223]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:02<00:00,  2.54it/s, loss=0.0275, v_num=223]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:46,  1.18s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:44,  1.19s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:43,  1.20s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:41,  1.17s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:39,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.17s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.17s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.19s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:37,  1.25s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:37,  1.29s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:36,  1.31s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:35,  1.32s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:34,  1.32s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:32,  1.31s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:30,  1.28s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:28,  1.26s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.27s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:27,  1.32s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:25<00:26,  1.30s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:26<00:24,  1.28s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.27s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.26s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:30<00:19,  1.24s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:18,  1.23s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.23s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:15,  1.23s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:14,  1.23s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.23s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.21s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:10,  1.21s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:39<00:09,  1.21s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:41<00:08,  1.24s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.24s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.22s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:04,  1.23s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:45<00:03,  1.23s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.23s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.23s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:48<00:00,  1.22s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:01<00:00,  2.55it/s, loss=0.229, v_num=224]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:02<00:00,  2.53it/s, loss=0.229, v_num=224]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:46,  1.19s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:45,  1.19s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:44,  1.21s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:43,  1.21s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:42,  1.22s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.21s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.22s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:38,  1.20s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:37,  1.21s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.21s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.20s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:32,  1.21s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:31,  1.20s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.21s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:29,  1.21s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.21s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:27,  1.24s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:26,  1.24s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:25,  1.26s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.25s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:22,  1.24s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:20,  1.22s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:19,  1.22s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:18,  1.22s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:31<00:16,  1.19s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:15,  1.19s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:33<00:14,  1.20s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.19s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:36<00:11,  1.20s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:37<00:10,  1.21s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.21s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.21s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:41<00:07,  1.20s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:42<00:06,  1.21s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:43<00:04,  1.20s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:44<00:03,  1.20s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:45<00:02,  1.19s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:47<00:01,  1.20s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:47<00:00,  1.19s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:03<00:00,  2.48it/s, loss=0.0155, v_num=225] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:04<00:00,  2.46it/s, loss=0.0155, v_num=225]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:48,  1.24s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:47,  1.26s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.25s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:44,  1.23s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:42,  1.22s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.23s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.23s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.24s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.24s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.23s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:34,  1.22s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:32,  1.21s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:31,  1.22s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.21s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:29,  1.23s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:28,  1.23s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.23s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:25,  1.22s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.22s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:22,  1.20s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:21,  1.20s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:20,  1.18s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:18,  1.19s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:17,  1.20s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:31<00:16,  1.21s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:15,  1.19s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:14,  1.21s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.23s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:36<00:12,  1.23s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:37<00:11,  1.22s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.21s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.21s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:41<00:07,  1.23s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:42<00:06,  1.24s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:04,  1.24s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:45<00:03,  1.24s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:46<00:02,  1.22s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:47<00:01,  1.22s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:48<00:00,  1.20s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:04<00:00,  2.45it/s, loss=0.0313, v_num=226] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:04<00:00,  2.43it/s, loss=0.0313, v_num=226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:47,  1.22s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:46,  1.22s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:45,  1.23s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:44,  1.25s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.24s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:42,  1.24s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.24s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.24s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.23s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:37,  1.24s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.24s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:34,  1.24s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:33,  1.23s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:31,  1.22s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.22s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:29,  1.23s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:28,  1.23s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.24s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:26,  1.25s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.23s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.23s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.23s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.27s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:20,  1.26s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:18,  1.26s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.26s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:16,  1.26s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:15,  1.25s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.27s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.25s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.24s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:39<00:10,  1.25s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.23s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.24s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.26s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:05,  1.27s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:46<00:03,  1.27s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.24s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.26s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:48<00:00,  1.22s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:05<00:00,  2.43it/s, loss=0.0372, v_num=227] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:05<00:00,  2.41it/s, loss=0.0372, v_num=227]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:48,  1.24s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:47,  1.25s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.26s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:45,  1.26s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:44,  1.26s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:43,  1.27s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:41,  1.26s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:10<00:40,  1.27s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:39,  1.28s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:38,  1.29s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:36,  1.27s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:15<00:34,  1.25s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:33,  1.24s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:32,  1.26s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.23s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:20<00:30,  1.26s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:28,  1.26s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.27s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:24<00:26,  1.28s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:25<00:25,  1.25s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:26<00:23,  1.26s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.26s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.25s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:30<00:19,  1.24s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:18,  1.25s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.26s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:16,  1.24s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:35<00:14,  1.24s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.26s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.25s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.24s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:40<00:09,  1.24s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:41<00:08,  1.23s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.26s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.23s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:45<00:04,  1.24s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:46<00:03,  1.25s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.24s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.26s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:49<00:00,  1.24s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:05<00:00,  2.42it/s, loss=0.0353, v_num=228] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:05<00:00,  2.40it/s, loss=0.0353, v_num=228]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:48,  1.24s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:45,  1.21s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:45,  1.23s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:43,  1.21s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.24s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.22s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.22s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.24s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.23s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.22s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:34,  1.22s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:33,  1.24s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:32,  1.25s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:31,  1.26s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:30,  1.26s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:28,  1.25s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.26s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:25,  1.23s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.23s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.24s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.24s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.24s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:19,  1.25s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:18,  1.22s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.23s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:15,  1.22s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:14,  1.23s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.25s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.25s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.26s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:39<00:09,  1.24s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.24s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.25s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.24s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:04,  1.22s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:45<00:03,  1.23s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:46<00:02,  1.24s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.23s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:48<00:00,  1.22s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:06<00:00,  2.38it/s, loss=0.0612, v_num=229] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:07<00:00,  2.36it/s, loss=0.0612, v_num=229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:49,  1.27s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:49,  1.30s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.27s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:45,  1.25s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:44,  1.26s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:43,  1.28s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:41,  1.27s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:10<00:40,  1.26s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.24s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:37,  1.26s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:37,  1.28s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:15<00:36,  1.29s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:34,  1.27s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:32,  1.25s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:31,  1.24s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:20<00:30,  1.25s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:28,  1.25s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.26s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:26,  1.26s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:25<00:25,  1.25s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:26<00:23,  1.25s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.25s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.25s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:30<00:19,  1.25s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:18,  1.25s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.23s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:16,  1.24s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:35<00:15,  1.26s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.26s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.26s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.26s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:40<00:10,  1.25s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:41<00:08,  1.27s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.27s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.25s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:45<00:04,  1.23s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:46<00:03,  1.23s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.22s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.23s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:49<00:00,  1.23s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:07<00:00,  2.35it/s, loss=0.0416, v_num=230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:07<00:00,  2.33it/s, loss=0.0416, v_num=230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:51,  1.32s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:48,  1.27s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.26s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:46,  1.28s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:45,  1.29s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:43,  1.29s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:42,  1.28s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:10<00:41,  1.28s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:39,  1.29s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:38,  1.30s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:14<00:37,  1.29s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:15<00:35,  1.27s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:34,  1.27s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:33,  1.27s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:19<00:32,  1.29s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:20<00:30,  1.27s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:29,  1.27s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:23<00:28,  1.27s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:24<00:27,  1.29s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:25<00:25,  1.29s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:26<00:23,  1.26s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:28<00:22,  1.27s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:29<00:21,  1.27s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:30<00:20,  1.27s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:19,  1.28s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:33<00:17,  1.25s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:34<00:16,  1.25s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:35<00:15,  1.28s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:37<00:14,  1.28s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:38<00:12,  1.27s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:39<00:11,  1.27s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:40<00:10,  1.30s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:42<00:08,  1.27s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:43<00:07,  1.27s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:44<00:06,  1.26s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:45<00:05,  1.26s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:47<00:03,  1.26s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:48<00:02,  1.26s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:49<00:01,  1.27s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:50<00:00,  1.26s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:08<00:00,  2.31it/s, loss=0.0642, v_num=231] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:08<00:00,  2.29it/s, loss=0.0642, v_num=231]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:49,  1.27s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:46,  1.23s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:45,  1.23s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:44,  1.24s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:42,  1.21s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.21s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:39,  1.21s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.23s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.24s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:37,  1.24s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.23s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:35,  1.25s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:33,  1.23s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:32,  1.23s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.23s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:29,  1.25s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:28,  1.24s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.24s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:26,  1.26s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.24s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.23s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:21,  1.22s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.24s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:20,  1.26s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:18,  1.26s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.25s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:16,  1.27s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:15,  1.27s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.27s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.28s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.29s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:39<00:10,  1.26s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:41<00:08,  1.25s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.26s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.26s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:05,  1.27s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:46<00:03,  1.25s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.24s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.25s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:49<00:00,  1.23s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lr</th>\n",
       "      <th>f1-0</th>\n",
       "      <th>f1-1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998473</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998410</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998483</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998445</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998415</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998420</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs  gamma      lr      f1-0      f1-1       acc\n",
       "0     10.0    0.0  0.0001  0.998473  0.992366  0.997455\n",
       "1     10.0    0.5  0.0001  0.998410  0.993631  0.997455\n",
       "2     10.0    2.0  0.0001  0.998483  0.992126  0.997455\n",
       "3     10.0    3.0  0.0001  0.998445  0.993007  0.997455\n",
       "4     25.0    0.0  0.0001  1.000000  1.000000  1.000000\n",
       "5     25.0    0.5  0.0001  1.000000  1.000000  1.000000\n",
       "6     25.0    2.0  0.0001  0.998415  0.993548  0.997455\n",
       "7     25.0    3.0  0.0001  1.000000  1.000000  1.000000\n",
       "8     35.0    0.0  0.0001  0.998420  0.993464  0.997455\n",
       "9     35.0    0.5  0.0001  1.000000  1.000000  1.000000\n",
       "10    35.0    2.0  0.0001  0.998430  0.993289  0.997455\n",
       "11    35.0    3.0  0.0001  1.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=5\n",
    "BATCH_SIZE=10\n",
    "EPOCHS=1\n",
    "GAMMA_0=2\n",
    "\n",
    "def get_prediction(x, model: pl.LightningModule):\n",
    "    model.freeze() # prepares model for predicting\n",
    "    probabilities = torch.softmax(model(x), dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def train_tune(config):\n",
    "    kfold = KFold(n_splits=K, shuffle=True)\n",
    "    reports = []\n",
    "    mean_f1s = []\n",
    "    for fold,(train_idx,val_idx) in enumerate(kfold.split(image_dataset)):\n",
    "        print(f'------------fold nº {fold}----------------------')\n",
    "\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                          image_dataset, \n",
    "                          batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "                          image_dataset,\n",
    "                          batch_size=BATCH_SIZE, sampler=val_subsampler)\n",
    "\n",
    "        # Train this fold\n",
    "#         model = ResNetCustom(gamma=GAMMA_0, class_sizes=[c0_s,c1_s])\n",
    "        model = ResNetCustom(config, class_sizes=[c0_s,c1_s])\n",
    "        model.SPE = len(trainloader)\n",
    "        model.EPOCHS = config['epochs']\n",
    "        trainer = pl.Trainer(max_epochs=config['epochs'], devices=1, accelerator=\"gpu\")\n",
    "        trainer.fit(model, trainloader)\n",
    "\n",
    "        # Test this fold\n",
    "        true_y, pred_y = [], []\n",
    "        for batch in tqdm(iter(testloader), total=len(testloader)):\n",
    "            x, y = batch\n",
    "            true_y.extend(y)\n",
    "            preds, probs = get_prediction(x, model)\n",
    "            pred_y.extend(preds.cpu())\n",
    "\n",
    "        report = classification_report(true_y, pred_y, output_dict=True)\n",
    "        reports.append(report)\n",
    "        mean_f1s.append((report['0']['f1-score']+report['1']['f1-score'])/2)\n",
    "#         print('=> CONFIG:', config)\n",
    "#         print(classification_report(true_y, pred_y))\n",
    "    max_f1_idx = mean_f1s.index(max(mean_f1s))\n",
    "    return reports[max_f1_idx]\n",
    "\n",
    "EPOCHS = [10, 25, 35]\n",
    "GAMMAS = [0, 0.5, 2, 3]\n",
    "LRS = [1e-4]\n",
    "\n",
    "grid_search = pd.DataFrame(columns=['epochs','gamma','lr','f1-0','f1-1','acc'])\n",
    "\n",
    "for epochs in EPOCHS:\n",
    "    for gamma in GAMMAS:\n",
    "        for lr in LRS:\n",
    "            config = {'epochs': epochs, 'gamma': gamma, 'lr': lr}\n",
    "            report = train_tune(config)\n",
    "            grid_search = grid_search.append(\n",
    "                            pd.Series(\n",
    "                                [epochs,gamma,lr,report['0']['f1-score'],report['1']['f1-score'],report['accuracy']],\n",
    "                                index=grid_search.columns), \n",
    "                            ignore_index=True)\n",
    "            grid_search.to_csv('./grid_search/plant_village_fuzzyfocalloss.csv')\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dbea118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.00995, v_num=232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.00995, v_num=232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.13s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.14s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.14s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.15s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0259, v_num=233] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0259, v_num=233]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:46,  1.20s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.12s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:31,  1.09s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.10s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.09s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:21,  1.09s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.09s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.09s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.12s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.15s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0155, v_num=234]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0155, v_num=234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:41,  1.07s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:36,  1.08s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.08s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.09s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.10s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:12,  1.08s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.09s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.10s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.027, v_num=235]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.027, v_num=235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.09s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.11s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.11s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.14s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0271, v_num=236] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0271, v_num=236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 311}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 82}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 393}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 393}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "config = {'epochs': 25, 'gamma': 2, 'lr': 1e-3}\n",
    "report = train_tune(config)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e08f8fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean loss\n",
    "splits = 49\n",
    "ml = [sum(mean_losses[i:i + splits])/splits for i in range(0, len(mean_losses), splits)]\n",
    "ma = [sum(mean_acc[i:i + splits])/splits for i in range(0, len(mean_acc), splits)]\n",
    "mf = [sum(mean_f1s[i:i + splits])/splits for i in range(0, len(mean_f1s), splits)]\n",
    "x_axis = [i for i in range(404)]\n",
    "\n",
    "for i, l in enumerate(mean_losses):\n",
    "    mean_losses[i] = l.cpu().detach()\n",
    "plt.plot(x_axis, ml, 'g', label='Loss')\n",
    "plt.plot(x_axis, ma, 'b', label='Accuracy')\n",
    "plt.plot(x_axis, mf, 'r', label='F1-score')\n",
    "plt.title('Training metrics')\n",
    "plt.xlabel('Épocas')\n",
    "# plt.ylabel('Loss media')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70e71d",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">UTKFace</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b44a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 11317 / Class 1: 2589 / BDeg:  4.371185786017768\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_dataset = datasets.ImageFolder('../data/UTKFace/train',data_transforms)\n",
    "\n",
    "# Provocar bias cogiendo un porcentaje de la clase 1 solamente (modificando el porcentaje hasta obtener b_deg deseado)\n",
    "class_0_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==0).flatten()\n",
    "class_1_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==1).flatten()\n",
    "class_1_idxs = class_1_idxs[torch.randperm(len(class_1_idxs))[:int(len(class_1_idxs)*.209)]]\n",
    "\n",
    "c0_s, c1_s = len(class_0_idxs), len(class_1_idxs)\n",
    "b_deg = c0_s / c1_s\n",
    "print('Class 0:', len(class_0_idxs), '/ Class 1:', len(class_1_idxs), '/ BDeg: ', b_deg)\n",
    "\n",
    "class_1_subset = Subset(image_dataset, class_1_idxs)\n",
    "class_0_subset = Subset(image_dataset, class_0_idxs)\n",
    "image_dataset = ConcatDataset([class_0_subset, class_1_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394906f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "class ResNetCustom(pl.LightningModule):\n",
    "    def __init__(self, config, class_sizes):\n",
    "        super().__init__()\n",
    "        self.gamma = config['gamma']\n",
    "        self.class_sizes = class_sizes\n",
    "        self.lr = config['lr']\n",
    "        self.n_classes = len(self.class_sizes)\n",
    "        \n",
    "        # metrics\n",
    "        task = \"multiclass\" if self.n_classes > 2 else \"binary\"\n",
    "        self.accuracy = torchmetrics.Accuracy(task=task, num_classes=self.n_classes)\n",
    "        self.f1score = torchmetrics.F1Score(task=task, num_classes=self.n_classes)\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.n_classes, bias=True)\n",
    "            \n",
    "        self.fuzzyloss = FuzzyLoss(gamma=self.gamma, class_sizes=self.class_sizes).cuda()\n",
    "#         self.fuzzyloss = nn.CrossEntropyLoss().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        y_onehot = F.one_hot(y, num_classes=self.n_classes).long()\n",
    "        acc = self.accuracy(logits, y_onehot)\n",
    "        f1s = self.f1score(logits, y_onehot)\n",
    "        mean_acc.append(acc.item())\n",
    "        mean_f1s.append(f1s.item())\n",
    "        \n",
    "        mean_loss, losses = self.fuzzyloss(logits, y)\n",
    "#         mean_loss = self.fuzzyloss(logits, y)\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "        # Update focal loss with Fuzzy Control System\n",
    "        self.fuzzyloss.update_hyperparams(losses, y)\n",
    "        return mean_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=self.lr)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
    "                                optimizer ,max_lr=0.01,\n",
    "                                steps_per_epoch=self.SPE,\n",
    "                                epochs=self.EPOCHS)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e7d9bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K=5\n",
    "BATCH_SIZE=10\n",
    "EPOCHS=1\n",
    "GAMMA_0=2\n",
    "\n",
    "def get_prediction(x, model: pl.LightningModule):\n",
    "    model.freeze() # prepares model for predicting\n",
    "    probabilities = torch.softmax(model(x), dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def train_tune(config):\n",
    "    kfold = KFold(n_splits=K, shuffle=True)\n",
    "    reports = []\n",
    "    mean_f1s = []\n",
    "    for fold,(train_idx,val_idx) in enumerate(kfold.split(image_dataset)):\n",
    "        print(f'------------fold nº {fold}----------------------')\n",
    "\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                          image_dataset, \n",
    "                          batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "                          image_dataset,\n",
    "                          batch_size=BATCH_SIZE, sampler=val_subsampler)\n",
    "\n",
    "        # Train this fold\n",
    "#         model = ResNetCustom(gamma=GAMMA_0, class_sizes=[c0_s,c1_s])\n",
    "        model = ResNetCustom(config, class_sizes=[c0_s,c1_s])\n",
    "        model.SPE = len(trainloader)\n",
    "        model.EPOCHS = config['epochs']\n",
    "        trainer = pl.Trainer(max_epochs=config['epochs'], devices=1, accelerator=\"gpu\")\n",
    "        trainer.fit(model, trainloader)\n",
    "\n",
    "        # Test this fold\n",
    "        true_y, pred_y = [], []\n",
    "        for batch in tqdm(iter(testloader), total=len(testloader)):\n",
    "            x, y = batch\n",
    "            true_y.extend(y)\n",
    "            preds, probs = get_prediction(x, model)\n",
    "            pred_y.extend(preds.cpu())\n",
    "\n",
    "        report = classification_report(true_y, pred_y, output_dict=True)\n",
    "        reports.append(report)\n",
    "        mean_f1s.append((report['0']['f1-score']+report['1']['f1-score'])/2)\n",
    "#         print('=> CONFIG:', config)\n",
    "#         print(classification_report(true_y, pred_y))\n",
    "    max_f1_idx = mean_f1s.index(max(mean_f1s))\n",
    "    return reports[max_f1_idx]\n",
    "\n",
    "EPOCHS = [10, 25, 35]\n",
    "GAMMAS = [0, 0.5, 2, 3]\n",
    "LRS = [1e-4]\n",
    "\n",
    "grid_search = pd.DataFrame(columns=['epochs','gamma','lr','f1-0','f1-1','acc'])\n",
    "\n",
    "for epochs in EPOCHS:\n",
    "    for gamma in GAMMAS:\n",
    "        for lr in LRS:\n",
    "            config = {'epochs': epochs, 'gamma': gamma, 'lr': lr}\n",
    "            report = train_tune(config)\n",
    "            grid_search = grid_search.append(\n",
    "                            pd.Series(\n",
    "                                [epochs,gamma,lr,report['0']['f1-score'],report['1']['f1-score'],report['accuracy']],\n",
    "                                index=grid_search.columns), \n",
    "                            ignore_index=True)\n",
    "            grid_search.to_csv('./grid_search/UTKFace_fuzzyfocalloss.csv')\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "758d00aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:68: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  \"Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning`\"\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:41<00:00,  2.77it/s, loss=0.458, v_num=299]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:42<00:00,  2.77it/s, loss=0.458, v_num=299]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:15<00:00,  1.13s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:45<00:00,  2.74it/s, loss=0.38, v_num=300] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:46<00:00,  2.74it/s, loss=0.38, v_num=300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:16<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:49<00:00,  2.72it/s, loss=0.274, v_num=301]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:50<00:00,  2.71it/s, loss=0.274, v_num=301]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:20<00:00,  1.15s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:56<00:00,  2.67it/s, loss=0.368, v_num=302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:57<00:00,  2.67it/s, loss=0.368, v_num=302]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:20<00:00,  1.15s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [07:11<00:00,  2.58it/s, loss=0.35, v_num=303] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [07:12<00:00,  2.58it/s, loss=0.35, v_num=303]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:32<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.8938325991189427, 'recall': 0.8985828166519043, 'f1-score': 0.8962014134275618, 'support': 2258}, '1': {'precision': 0.552734375, 'recall': 0.5400763358778626, 'f1-score': 0.5463320463320464, 'support': 524}, 'accuracy': 0.8310567936736161, 'macro avg': {'precision': 0.7232834870594713, 'recall': 0.7193295762648835, 'f1-score': 0.7212667298798041, 'support': 2782}, 'weighted avg': {'precision': 0.8295854857334913, 'recall': 0.8310567936736161, 'f1-score': 0.8303022227884352, 'support': 2782}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "config = {'epochs': 25, 'gamma': 0.5, 'lr': 1e-4}\n",
    "report = train_tune(config)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10627f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean loss\n",
    "splits=49\n",
    "for i, l in enumerate(mean_losses):\n",
    "    mean_losses[i] = l.cpu().detach()\n",
    "\n",
    "ml = [sum(mean_losses[i:i + splits])/splits for i in range(0, len(mean_losses), splits)]\n",
    "ma = [sum(mean_acc[i:i + splits])/splits for i in range(0, len(mean_acc), splits)]\n",
    "mf = [sum(mean_f1s[i:i + splits])/splits for i in range(0, len(mean_f1s), splits)]\n",
    "x_axis = [i for i in range(2840)]\n",
    "\n",
    "plt.plot(x_axis, ml, 'g', label='Loss')\n",
    "plt.plot(x_axis, ma, 'b', label='Accuracy')\n",
    "plt.plot(x_axis, mf, 'r', label='F1-score')\n",
    "plt.title('Training metrics')\n",
    "plt.xlabel('Épocas')\n",
    "# plt.ylabel('Loss media')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5df61",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">gender_clf</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27391d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 23243 / Class 1: 4967 / BDeg:  4.679484598349104\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_dataset = datasets.ImageFolder('../data/gender_clf/train',data_transforms)\n",
    "\n",
    "# Provocar bias cogiendo un porcentaje de la clase 1 solamente (modificando el porcentaje hasta obtener b_deg deseado)\n",
    "class_0_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==0).flatten()\n",
    "class_1_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==1).flatten()\n",
    "class_1_idxs = class_1_idxs[torch.randperm(len(class_1_idxs))[:int(len(class_1_idxs)*.209)]]\n",
    "\n",
    "c0_s, c1_s = len(class_0_idxs), len(class_1_idxs)\n",
    "b_deg = c0_s / c1_s\n",
    "print('Class 0:', len(class_0_idxs), '/ Class 1:', len(class_1_idxs), '/ BDeg: ', b_deg)\n",
    "\n",
    "class_1_subset = Subset(image_dataset, class_1_idxs)\n",
    "class_0_subset = Subset(image_dataset, class_0_idxs)\n",
    "image_dataset = ConcatDataset([class_0_subset, class_1_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e588a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "class ResNetCustom(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 gamma=0.,\n",
    "                 class_sizes=[1,1],\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.n_classes = len(class_sizes)\n",
    "        \n",
    "        # metrics\n",
    "        task = \"multiclass\" if self.n_classes > 2 else \"binary\"\n",
    "        self.accuracy = torchmetrics.Accuracy(task=task, num_classes=self.n_classes)\n",
    "        self.f1score = torchmetrics.F1Score(task=task, num_classes=self.n_classes)\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.n_classes, bias=True)\n",
    "            \n",
    "#         self.fuzzyloss = FuzzyLoss(gamma=gamma, class_sizes=class_sizes).cuda()\n",
    "        self.fuzzyloss = nn.CrossEntropyLoss().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        y_onehot = F.one_hot(y, num_classes=self.n_classes).long()\n",
    "        acc = self.accuracy(logits, y_onehot)\n",
    "        f1s = self.f1score(logits, y_onehot)\n",
    "        mean_acc.append(acc.item())\n",
    "        mean_f1s.append(f1s.item())\n",
    "        \n",
    "#         mean_loss, losses = self.fuzzyloss(logits, y)\n",
    "        mean_loss = self.fuzzyloss(logits, y)\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "        # Update focal loss with Fuzzy Control System\n",
    "#         self.fuzzyloss.update_hyperparams(losses, y)\n",
    "        return mean_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=1e-4)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
    "                                optimizer ,max_lr=0.01,\n",
    "                                steps_per_epoch=len(trainloader),\n",
    "                                epochs=EPOCHS)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc70ab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1bd18bc4cf4168a1b83bbec94e782d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a96164ba2a547138cc2269c2b722d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.875     0.987     0.927      4615\n",
      "           1      0.860     0.365     0.513      1027\n",
      "\n",
      "    accuracy                          0.874      5642\n",
      "   macro avg      0.867     0.676     0.720      5642\n",
      "weighted avg      0.872     0.874     0.852      5642\n",
      "\n",
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b731326106cc46208c12fd9bd4f41f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc728b304ac7458d9b930a351995db15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.902     0.971     0.935      4637\n",
      "           1      0.794     0.513     0.624      1005\n",
      "\n",
      "    accuracy                          0.890      5642\n",
      "   macro avg      0.848     0.742     0.779      5642\n",
      "weighted avg      0.883     0.890     0.880      5642\n",
      "\n",
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5558b886ddbf4547a0c0f09995fb593d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead446aa1f76452f901128564bf111c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.938     0.906     0.922      4650\n",
      "           1      0.620     0.718     0.665       992\n",
      "\n",
      "    accuracy                          0.873      5642\n",
      "   macro avg      0.779     0.812     0.793      5642\n",
      "weighted avg      0.882     0.873     0.876      5642\n",
      "\n",
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed554f990e224146a9d1c67118a4a0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0c7f01057e4e2f96a39afe44139f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.954     0.834     0.890      4678\n",
      "           1      0.500     0.805     0.617       964\n",
      "\n",
      "    accuracy                          0.829      5642\n",
      "   macro avg      0.727     0.820     0.753      5642\n",
      "weighted avg      0.876     0.829     0.843      5642\n",
      "\n",
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9427ef1042cb48b0a28eb3caa0101441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f36a58881864ba8b7bc84b9de9397b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.869     0.991     0.926      4663\n",
      "           1      0.868     0.289     0.434       979\n",
      "\n",
      "    accuracy                          0.869      5642\n",
      "   macro avg      0.869     0.640     0.680      5642\n",
      "weighted avg      0.869     0.869     0.841      5642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=25\n",
    "K=5\n",
    "GAMMA_0=2\n",
    "BATCH_SIZE=10\n",
    "\n",
    "def get_prediction(x, model: pl.LightningModule):\n",
    "    model.freeze() # prepares model for predicting\n",
    "    probabilities = torch.softmax(model(x), dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "kfold = KFold(n_splits=K, shuffle=True)\n",
    "for fold,(train_idx,val_idx) in enumerate(kfold.split(image_dataset)):\n",
    "    print(f'------------fold nº {fold}----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      image_dataset, \n",
    "                      batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      image_dataset,\n",
    "                      batch_size=BATCH_SIZE, sampler=val_subsampler)\n",
    "    \n",
    "    # Train this fold\n",
    "    model = ResNetCustom(gamma=GAMMA_0, class_sizes=[c0_s,c1_s])\n",
    "    trainer = pl.Trainer(gpus=1, max_epochs=EPOCHS, devices=1, accelerator=\"gpu\")\n",
    "    trainer.fit(model, trainloader)\n",
    "    \n",
    "    # Test this fold\n",
    "    true_y, pred_y = [], []\n",
    "    for batch in tqdm(iter(testloader), total=len(testloader)):\n",
    "        x, y = batch\n",
    "        true_y.extend(y)\n",
    "        preds, probs = get_prediction(x, model)\n",
    "        pred_y.extend(preds.cpu())\n",
    "    \n",
    "    print(classification_report(true_y, pred_y, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9b70e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHHCAYAAABtF1i4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAACKi0lEQVR4nO3dd1zU9v8H8NexEQUFFVERcQ9wQVWctVrc1aqte++9qtXa1lFbOylWxbqt1oGzX1sndSt1Ibj3wgHiBFzMz++P/G7n7pJbOe7ez8fjHnDJJ8nncrnknc+KjDHGQAghhBAiESepM0AIIYQQx0bBCCGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIkRcEIIYQQQiRFwQghEpHJZIJehw4dMmk7s2bNgkwmM2rZQ4cOmSUPti4mJgarV68WtYyj7BtCrEFGw8ETIo0TJ06ovf/mm29w8OBBHDhwQG16jRo14O3tbfR2Hjx4gAcPHqBhw4ail83IyMDly5dNzoOtCwkJQfHixUUFFo6ybwixBgpGCLERAwYMwJYtW/Dq1Su96d68eYNChQpZKVeOQUwwkpOTA5lMBhcXF8tnjBAHQdU0hNiw999/HyEhIThy5AgaNWqEQoUKYdCgQQCA2NhYREZGIiAgAJ6enqhevTqmTZuG169fq62Dr5qmfPny6NChA/bs2YN69erB09MT1apVw8qVK9XS8VVFDBgwAIULF8bNmzfRrl07FC5cGIGBgZg8eTKysrLUln/w4AG6deuGIkWKoGjRoujduzdOnz4NmUxmsFpk9erVkMlkOHDgAIYOHQo/Pz94e3ujX79+eP36NVJTU/Hpp5+iaNGiCAgIwGeffYacnBy1dWRnZ2Pu3LmoVq0a3N3dUaJECQwcOBBPnjxR2xeXLl3C4cOHFVVj5cuXV/v8a9euxeTJk1GmTBm4u7vj5s2bOqtpTp48iY4dO8LPzw8eHh6oWLEiJkyYoJj/5MkTDBs2DIGBgYo8NW7cGP/++6/e/UGIPaPQnhAbl5KSgj59+mDq1Kn47rvv4OTE3UPcuHED7dq1w4QJE+Dl5YWrV6/ihx9+wKlTp7SqevicO3cOkydPxrRp0+Dv74/ly5dj8ODBqFSpEpo1a6Z32ZycHHz00UcYPHgwJk+ejCNHjuCbb76Bj48Pvv76awDA69ev0aJFCzx//hw//PADKlWqhD179qB79+6iPv+QIUPQpUsXbNy4EYmJifjiiy+Qm5uLa9euoUuXLhg2bBj+/fdf/PDDDyhdujQmTZoEAMjPz0enTp1w9OhRTJ06FY0aNcK9e/cwc+ZMvP/++zhz5gw8PT2xfft2dOvWDT4+PoiJiQEAuLu7q+Vh+vTpiIiIwO+//w4nJyeULFkSqampWnndu3cvOnbsiOrVqyMqKgrlypXD3bt3sW/fPkWavn374uzZs/j2229RpUoVvHz5EmfPnsWzZ89E7RdC7AojhNiE/v37My8vL7VpzZs3ZwDY/v379S6bn5/PcnJy2OHDhxkAdu7cOcW8mTNnMs2felBQEPPw8GD37t1TTHv79i3z9fVlw4cPV0w7ePAgA8AOHjyolk8AbNOmTWrrbNeuHatatari/aJFixgAtnv3brV0w4cPZwDYqlWr9H6mVatWMQBs7NixatM7d+7MALCoqCi16XXq1GH16tVTvN+wYQMDwLZu3aqW7vTp0wwAi4mJUUyrWbMma968uVYe5J+/WbNmOuep7puKFSuyihUrsrdv3+r8XIULF2YTJkzQOZ8QR0TVNITYuGLFiuGDDz7Qmn779m306tULpUqVgrOzM1xdXdG8eXMAwJUrVwyut06dOihXrpzivYeHB6pUqYJ79+4ZXFYmk6Fjx45q02rVqqW27OHDh1GkSBG0adNGLV3Pnj0Nrl9Vhw4d1N5Xr14dANC+fXut6arb/+eff1C0aFF07NgRubm5iledOnVQqlQpUY1Vu3btajDN9evXcevWLQwePBgeHh4609WvXx+rV6/G3LlzceLECa2qJUIcEQUjhNi4gIAArWmvXr1C06ZNcfLkScydOxeHDh3C6dOnsW3bNgDA27dvDa7Xz89Pa5q7u7ugZQsVKqR1wXV3d8e7d+8U7589ewZ/f3+tZfmm6ePr66v23s3NTed01e0/fvwYL1++hJubG1xdXdVeqampePr0qeA88H0HmuTtUMqWLas3XWxsLPr374/ly5cjIiICvr6+6NevH2+1DyGOgtqMEGLj+MYIOXDgAB49eoRDhw4pSkMA4OXLl1bMmX5+fn44deqU1nRrXXSLFy8OPz8/7Nmzh3d+kSJFBK9LyDgtJUqUAMA12jWUr+joaERHRyM5ORk7duzAtGnTkJaWpjOvhNg7KhkhpACSXxw1G1ouWbJEiuzwat68OTIzM7F792616Rs3brTK9jt06IBnz54hLy8P4eHhWq+qVasq0gotEdKnSpUqqFixIlauXKnVq0iXcuXKYcyYMfjwww9x9uxZk7ZPSEFGJSOEFECNGjVCsWLFMGLECMycOROurq5Yt24dzp07J3XWFPr3749ff/0Vffr0wdy5c1GpUiXs3r0be/fuBQBFryBL6dGjB9atW4d27dph/PjxqF+/PlxdXfHgwQMcPHgQnTp1wscffwwACA0NxcaNGxEbG4sKFSrAw8MDoaGhore5aNEidOzYEQ0bNsTEiRNRrlw5JCcnY+/evVi3bh3S09PRokUL9OrVC9WqVUORIkVw+vRp7NmzB126dDH3LiCkwKBghJACyM/PDzt37sTkyZPRp08feHl5oVOnToiNjUW9evWkzh4AwMvLCwcOHMCECRMwdepUyGQyREZGIiYmBu3atUPRokUtun1nZ2fs2LED8+fPx9q1azFv3jy4uLigbNmyaN68uVqwMXv2bKSkpGDo0KHIzMxEUFAQ7t69K3qbrVu3xpEjRzBnzhyMGzcO7969Q9myZfHRRx8B4BoJN2jQAGvXrsXdu3eRk5ODcuXK4fPPP8fUqVPN9dEJKXBoBFZCiFV99913+PLLL5GcnGywsSchxDFQyQghxGIWLlwIAKhWrRpycnJw4MAB/Pbbb+jTpw8FIoQQBQpGCCEWU6hQIfz666+4e/cusrKyFFUSX375pdRZI4TYEKqmIYQQQoikqGsvIYQQQiRFwQghhBBCJEXBCCGEEEIkVSAasObn5+PRo0coUqSIoGGZCSGEECI9xhgyMzNRunRpvQMdFohg5NGjRwgMDJQ6G4QQQggxwv379/V25y8QwYj8gVb379+Ht7e3xLkhhBBCiBAZGRkIDAw0+GDKAhGMyKtmvL29KRghhBBCChhDTSyoASshhBBCJEXBCCGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIkRcEIIYQQQiRFwYgIOTlAerrUuSD25OZNYMYM4MkTqXNCCCHSKRBP7bUVNWsCN24AqamAv79x67h7F/DyAkqUMGvWSAHVoAHw/DmQlATs3Cl1bggxzs2bgJ8fUKyY1DkhBRWVjIhw4wb3d98+45Z/+hQIDgZKljRfnkjB9vw59/fYMWnzQYgQEycCI0aoT7t5E6hcGfD1Nbz82LHAmDHa09+9A3bsADIzzZNPUvBQMGJhDx8CMTHAq1fAlStS58Yydu0C9u6VOhe268ED7hh4/VrqnBBivDdvgOhoYMkS7rwmd/SosOVfvAAWLgQWLeJuzFR99hnQqRPQpYvZsksKGKOCkZiYGAQHB8PDwwNhYWE4auBoXLRoEapXrw5PT09UrVoVa9asMSqztoIx9f8fP9adtlEjYPRooG9fQCYzfpvz5wNbt4pb5skTYNo04Pp147drSEYG0L490KYNd3dTEOTlma+Nhr7vXq5+fe4YmDzZPNu0FdnZwNdfA8ePS50TYg35+cr/c3LEL5+bq/w/L0993rJl3N9//xW/XmIfRAcjsbGxmDBhAmbMmIHExEQ0bdoUbdu2RXJyMm/6xYsXY/r06Zg1axYuXbqE2bNnY/To0fj7779NzrwtmDwZKFUKWLuWf758t/z1l7KaR6zz54EJE4Bu3cQtN2AA8MMPQFiY8GV27QL69xdeXKraoNeYE5QU2rblqspOnzZtPd99x333UVH606WkcH937zZte7rcuAGkpVlm3fosWgR88w3QpIn1t+0I7t0DevUCzpwxnJYxIDGRK70wRVqa7vPUtm3i13f3LvcZzp5Vn656QwdwgS1xcEyk+vXrsxEjRqhNq1atGps2bRpv+oiICPbZZ5+pTRs/fjxr3Lix4G2mp6czACw9PV1sds2K+wkx9scf2tNKltS/DMBYZKTyfyESExk7cYKxuDjhy61bx1jNmowtXcpYkSLitqea35EjGdu6lbG3b5XzMjK4aa9fK6fdvatcZs0axp4/F74tqcjzO2iQedZjaP/K05Qrp3uet7dxeXjwQPx3bC7Dh0u3bT6vXjH24YeMLVwodU7Mo2FD4ft340YuXd26pm1Tvr0HD7TnlS2rnH/njnJ6xYra+czPZ2zgQPXfyJMnyv9TUpRp370T/lsiBY/Q67eokpHs7GwkJCQgMjJSbXpkZCTi4+N5l8nKyoKHh4faNE9PT5w6dQo5Om6ls7KykJGRofayB7qqaS5f5toUqBZj5ucDdesCDRtyVSGG3LsHVKoE9O4NXLoEDBumXroRH6+79IbP4sVA167ApEnKaT17ctNGjlROU73D6dcP+OAD4dvQhTHtUpYHD4DffjOtgdvt28CCBcr3plSb6bNxI9dQ+exZ9f1jie0lJir/59tvtoAx4P59rqrx5UvLbWfxYiAujr+BpFhPnnD5ffZMOe3QIaB8ecuVcGm6etVwmuPHgVatgOHDufeqx4NYL14o/+/dmzte+/cHKlTgqlGcnZXzVY/rW7e013X3LrBqlfo01WPzxg2u/UhWFvDPP8bnmQhz/z53fYiOljoneoiJcB4+fMgAsOPHj6tN//bbb1mVKlV4l5k+fTorVaoUO3PmDMvPz2enT59mJUuWZADYo0ePeJeZOXMmA6D1KuglI1Wq8Ef/8mm//aaclpWlnL5kifL/+fMZmzNHezvdu6tvS9fr5Elhn1H+cndn7NQpxqZOVZ/++eeMHT/O2K1b2sskJTF2+zZjvXszdv06Y48fC9u/cpGRXKmO6tddurTppRmurur5HDJEO83Dh9xd3+TJXKmPPrru5uTTKlZkrHx55fugIN3rMLZk5J9/lOto1oyxokXV95sljRgh7G62Sxdlus6dLZefmTPF312/ecPYs2fKv3KNGnHr+eAD5TRr3L3n5zM2dy5j//sf910a2h7fbzwxUXf6J0/USztVzZ6t/9wRHKz8//Ztbpm8PP79cv26sPPRoEHa0x484PaDOWVnM5aaat51Wkt2tvhzqKqsLMZateI/lvLz+UvBzEloyYhRwUh8fLza9Llz57KqVavyLvPmzRs2cOBA5uLiwpydnVnp0qXZ1KlTGQD2WMcefvfuHUtPT1e87t+/L1kwcumS8kCQf5mrVyvny6eVKMG/vK4foeqPTT6tVy/ltLdvldNVi8PlrxEj1NfRqZOwH/+6ddwF9+pV7bxeuKCd3s1N//qaNNGe1qKF9rQbN4Tvc/kyGzZoTytdWvh6dK1X9aV6Yv77b/V5NWrwr2f+fMbGjzccjMgDKPmrbFnG/vuPK5bmy1O7dtzf339nbPduxjp04Kro9Nm5U/szrV9v1O4RbeRI/s9/8aLyN6OZPycny+Tl0iXGxowRFyxcuaK97+TVjHzfra7v25z27VNuw9hgRFf6x4+5ef7+/PO//FL/b121OubWLW6Z2Fj+7d64Iex8pOs1ZYpx+0+XOnW49V66ZN71WkOtWlzer1wxbvkaNXQfG198wU2LjjY9n7pYJBjJyspizs7ObNu2bWrTx40bx5o1a6Z32ezsbHb//n2Wm5vLYmJiWJEiRVheXp6g7UrVZuTmTfUvUP6/OYKR3FzG9u9Xrxfu2VO53OvXwn60ly4xtnmz8k7O0OvPP5X/qxZM8Z2YzfniK82Re/CAa4uSl8eVwvBdVOXThAYjd+4wtmMHYwcPMnbunO7vIipKuUzjxvwn9Xv3GPvrL2XwZ+jkL2R/5Ocztny5sLTx8coLQffujF2+zB0rmZn8wYhqEGdJo0Zpf37VO2K+feHsrL6OnTu573zzZmWQduIEY23acMFYbi43LSeHO0ZSUrhAes8ebvrNm4wtWKC9HV13/3L37/Pv67g4xlq25P9udX3f5rRyJX+++G4eNPNkKH9btuifLyYYke8rDw/+7fKVmIp9mZN8nV99Zd71qsrP536XEyYYTnvkiP4SLFXyvM+aJS4/uo5xvnVb8pi2SDDCGNeAdeTIkWrTqlevrrMBK59mzZqxnqpXXgOkCkbWreM/sdaqxdjLl+rTAO6uT7VhVkaG7h/a999rT2vUSNiyprzCwtTfP3+ufZdviZe+w8Pbm0ujeVExJRjR3P6kSfpPsk+f8pfyHD6s/D82ln/dAGMuLowNHqx7vubLHCdrgLEePbSnyfNpKRkZjFWrxn8iW7WK/zcjf6kGIwcPqs+bPJl/vwwdypVGAYz5+SmnHz+ue7+MGaOe59xcrrj7xAllCRTfq3Vr7WlyqtO2bLHMvtUXoEZFcY2gr11jrGtX9X2h+Ro3Tnvdv/+u/Znk8vPNczz++itjCQnmWRfA2Pvvm6fKRr6+L780fV2asrO5kgXVUiJ9Hj1Spvv3X8bWrtWfXp7WUDCiWuKqWmWp63hWXTfABfyWYLFgZOPGjczV1ZWtWLGCXb58mU2YMIF5eXmxu/9fwT5t2jTWt29fRfpr166xtWvXsuvXr7OTJ0+y7t27M19fX3ZHtTm2mT6MOV2+zBVn6jqx9uql3pNE/lJthzB0qPgf382bXHBw/rz5ftC28NJX7KprmXXrtNOUKaOclpfHWHKyuHXqek2bxljTpvrTyDuR6UsjdNuaF2JzvjZtEnu0i8NXEiFvX6N6Z69rX8hpBuRlynBtr/iWUe2JJuTl46PcTn4+F3BqVpsJfa1Zw/9ZzOnNG64aZelSw/nx9RWWb82LuOq8e/eU8xctYuzrry13PJr6unDB9P2r+b2tXs0FTkI9e8YF4Xx++kncsXHihO7PePs2d/6/e5cLeD/5RJlm9mzd6zx6lEvz9dfan1df3lSnBwebv60OYxYMRhhjbNGiRSwoKIi5ubmxevXqscOHDyvm9e/fnzVv3lzx/vLly6xOnTrM09OTeXt7s06dOrGrusocdbBWMPLwIfelNGzImJeX+hel2gjP0EtOtcGX0FeZMtxfzeLPgv4aPVr3fte1TLlyXMnNyZPa+zcnR9nVUH6XevIk9z2pVq+JeVWqpH++vEBQXxq+9j3Wflnqrl0uOlp7m59/zs1bsUI5TbXbseb3xxjXDVfoZ2rbVtw+cHbmSo22bOGqs0zdp3Pm6P4cuqSlcaUEmt6+5S4eublcVaLqOr/6ynzHwddfM3bsmLKqS3N+eDiXR6mPVyEvU6mua8gQ5f+GGqkzpl5lzqdbN+386ruo81WHhYdz8ypU4N5rljzKj8HLl/lvwOrWVaYzVKouD6qWLdOe9+qV4f0hlkWDEWuzZDDy9i1Xx/70qfi7L12v9eu1q0PopdzneXnqdfr6lgkI0J7WvDnXy0f+3stLfT3yxmrmfo0cab7ibEu+/vpL+zjPy+PaZdy7J+x3kZ/PtUd67z2uXYcqeZWJ6mvqVO43JCR/wcFczwZr7Q++O1FzvDTt2cOVaMr3nzzd6dPKNK9eKaebM/DQ9xo4UL3Xlerr44+lP16N2ddycXFc7z3GuNKF997jGn9r0rXec+e40ogGDbjfh6Z797jqEXn6/Hyurcd773FVLIzxByOqzSFfvOCuCfILva68qPag5HupNtB+947Ly6hRXJVdaKhyXkiI/vXIx6Lhm6c6hpS5UDAikLy9RK1ahu+M6WXaS65pU+7Ola/nginrlvrz2cpLJtM+zjXbcuiTna1+pwVw7Q3kddJ825wyhbF69aT/7NZ8Xbyo3GcXLyqnN2yoPuDg4MGM/fgjF6xpDgRGL2EvVfILpmoJ6K+/6k6v79yQlKReQmdouefPtbejWpUif6mWiDVvzk2Tt17QlZf33hO3T5ydjd+fuhorUzBigCWDEdV2IZqtxell3pf8Byp/L28TYo51C+195CgvTX36KOfduaMsuuejqz1LkSJc40m+eePGSf+Zrf1SrQ7btEn6/NjzS07eSHT+fG68J13pR49W70ygK93OnVwVieZ2GOMvBe3VSztffMEIwI3porntlBTp96W+l5TBiMM/tZcx/v+J+X3zjfp7mQxITTXPur28zLMee5KXx406qyk4GAgN5UbcPH5cedyvXs09R0TXc0IyM4GqVfnn/fabWbJcoDipnD2Nfe4UEadnT+7v+PHcs7d0WbQICAriRrG9dEl3uvbt1X8jffsqR8Lmux7Exam/P3GCG5mXT+XK2tPq1dOdF0fnInUGpKZ6wKk+lZJYh9iH/xHhevQAtmwB1q0DXr9Wn3flCuDry/0/fTp3ch84kHvv5PC3KMI8fKj8f8YM6fLhqAzdPGZnA9WrG17P8+fK///8E2jXjgt6+Nav+bTviAjd6335Epg5U32a/KGZRJvDByOqAYjqs2GI+R08CKxZo3zfq5d0ebF3a9ZwgQjAPWdEn3nzgKQk5ft16yyWLbsydiz3HBxDT20m5mONG0b5s8BUgxRjzZlj+jqsScraARlXp2XbMjIy4OPjg/T0dHh7e5t13b6+6g+IIoQQodavp6DaGm7c4B70ZqmHW6rq2pV74CBfFae9y8wEChc27zqFXr8dvmSEAhFCiLEoELGOypWBceOss62tW62zHVskZdEE1Q4TQgixeY7YSNqRUDBCCCGEECoZIYQQQoi00tKk2zYFI4QQQgjBrl3SbZuCEUIIIYRIOryFQwcjNMgZIYQQwpHymujQwciGDVLngBBCCGC9rrtEt7w86bbt0MHItWtS58D+UcBHCBFi/nypc0ComobYreLFpc4BIabbuFHqHBBieVQyQuxWQW2X4+kp7fZ37tQ97/Jl6+WDcAIDpc6BfaP9axusMdy+Lg4djNj+U3lsk/w5EUJUqGDZvFjKTz9Ju/22bfmnDxki7EmkxLzs6VwxYgTwww/W3abm02s1HTtmnXwQ/SgYIbyGDQPc3AynU32UuSXs3q3+Xmgg8scfXNrISPPnydKcJP5lyGTAp59KmweiZE/ByCefAP37q0/bscNy25s6FZg1S3+acuUst31btmcPMGqUedYVF2f6OigYkciTJ+Zf55dfmm9d5csD06cbTle6NPDnn0CPHubbttylS0CbNsr3hQpxf0uU0L8cY0C/ftz/UhTB6iqRmThR2PLyz2mKxo31zx82TP/8glrFZY+krEu3BM2LTrVqxq9LX+nn4cPAt98av257V6ECsGiRedbVqpV51iMVhw5Gliwx/zr57qCmTjX/duTkpRa9e3M9V/bs0U5z4IDx669Rg/tbvjz3t3Vr7m/dusLXkZho/PaN9e+//NOF3uGKvRP+6CPt4PbwYeDMGa7LYtGi2ssYKn157z3taZMmcX8/+0x7XkGtEjPk7l3LPCStZk3195pPN79xgwte9+0D/PzMv32pyGTawYj89y1GUBCQkqK/VKNZM8DF4Z8Nr5uzs9Q5sB0OHYxYiuaPz9DdeK1a3A+7RQtx21m4UL3UAlAGC6patADevAHq19e9rrAw/fXIR48CP/4IrFhhOF9Hjqi/t3YRd1QUtz8bNODuFkqVUs7z8LDMNkuX1u455OzM7df584ELF7j99+gR0L07F2g0bMi/LnngMmEC8OuvwNixynny9iKabVpKlgS6dDHHJ7EN8iAY4L5LvguaZjBhyE8/AV5eyvcXL6pXV0RHq6evVIk7lj78EAgJ4Y79Awe4/y2pfXvLrp+vKN7VVfm/ry/3t3Bh/uUrVuT+9unD/bZUg2qxbVGWLHHs9iLWCkbef19YOqqmKYD03UncuQP88ovyvaEi/3PnuGUMNfLKz+fu1ho0ALZvB0aP5k/HVzqi2Ttk+XIgIgL44ANufbGx/HfbcmXLAlOmAMWKce/1BVhStLeoV0/5//jxXB5OnNCuRxUaGAm5c/zgA2DlSqBRI2D2bP3rk++/gACum+jJk/wX2PfeU+bZzU0ZkGzZAjx4oHv99jRgVKNGXBCgqlkz7XQXL4pbb+HC2m2wypThT/vjj9rTBg3iAvu9e8Vtlw/fdrt14wLUmBjT1y8nprrx9m3uvJKczJWynj+vnNekifL///7jzhdff829V/296ytB+uQT9fdXrnBVlarVmR06CM+vLRJ7Q2CouttcdDWItymsAEhPT2cAWHp6ulnXy12ajHsFBfFPnzGDW/fbt8ppeXn61yV38KD69O++Y+zrr7XTCVG+vPZy27dz7z/5hH+Z/HzlMnXrMrZmjf5tvH3LWIcO2p8nPl49XZ06pu3rgADDac6eVf6fn6++/VKllPOmTjW8rhMnGFu9Wvs7mjNHfdq4cdr75IcfuHn9++vfd4wxtm6d7mNBCNXlcnMZ++wz0/azuV6ZmaYtzxj3HY4fz9gvv/B/Xnk6fespW1b9/YoVjC1dyv0/ejS3fGYmYz16MLZtG2MrVwr7Hgz9njVfPXtqT/vwQ+1pp07p/qzGvLp2ZSwpSXv6wYOMPX6sfD91qu7PevUqY/fuMdakie59ExmpnJedrft4fveOsaNHuderV7q3mZDA2KJF0h/HxrxSU4Wlu32bsRs3TPu+S5bkvmOAO+/oWs+2bYy9fKk9XX6uUn19953+Y98YQq/fPIeW7bHFYKRmTf7p8+Yp1//sGWMZGdrb+vRT/h/s4cPaB4axwUhwMP9y9+9zJ1ND++TiRWHbSUtjbOJExoYNUy7733/qaWrXNrw/Q0O5H5fmdHlgYWj5rCzG/P0Zq1FDO4/9+yvTffGF4XUxxh+M/POP8v3kycrvVtO9e9oBEZ/16/m3LZR8mbp1uffWDEbc3HTPUw1q+V4TJxre/3zq1dNOx5ePOXO470Bz/65axS2TnMz//Tx/zq3vww+F73shr169tKcdO6b/c6tO79tX/Pezbp3uvB46pH7RfPLE8OfVF4y0aaM+LyeHsWnTGNu/3/B6dUlPZ6xQIesdz2Jf+/drT2vZkn9/Dxhg+BjXtZ3hw/mnz53LHcP5+dyxrms99+9z01Vvjq9f56Zfu6adfsUK478z3d+lsOs3VdMYydeXa0ehWbXi46OepkgR7WUDAvjX2agRV2Wiytg6PH9//ully+qvRunalSsSFzqWRYkSXJG6amNgzQZtQnoinD+v3ap8yBD9n1+1TtvNDbh/X71oWe6337jvxd2dq16KiDCcH8b0z//5Z/7vFuA+v5DvzdQeO6tXc9tavZp7b6363unTtauFmjdX/q+ZD83jQbMKRq58eWDBAt3b3bVLuxhf8/sOCwO++orbpuZ3KD/uAwP591WxYkBmpnmqYVTxbSskBHj3TlntqUn+3Z47x30eueBgYdvs1Ut4fkw9bjTbPbi4APPmcdWYxvL2Bl68MC1flqTavq9cOa5aftMm7XR79nBt+8Tavx9Yt45rr6QpPByYMUPZEFlfA+KyZbm/qm2CSpTgpvN971J2saZgRKCRI9XfM8bVo2r21zd0EQPUG1Sqjtnh4sK1c5ArUULY+visXcvVxf79t7jltmzheoEY0+7j3Dmu8Wrp0urTDXVRlTeI69qVG1tj2DAuH/p6UPTsyfVUadSIu0gB3A+Or0GYtzfw8iV38i9enBvddMsWbpqqHj2UvVX4GPtd6NK+PdCxo/5t6tO/P3DvHtcA2hKiorgGwKqNPtu2Bb77TnmSk+vcmX8dLi5cHqtU0b+t0FCu3dSYMbrT+Ptr76uqVdV/M5UrK//X/L4aNdKfB4ALak25OGvuF4B/fYUKccHxlStc8L92rfp8Xd/toEHG502V2GNZXxs5eRf+0FCjs8NLyBhLmo4dAyZPFr+c5k2gITIZdx5p3JjruTdpkrLhr1zNmlyHAi8vrhG2UJGRXCCnK6AUsy45Z2fufBkfr2wgr3pcCh07yqLMXyhjftaspunYUfm/v7/yr2b6f/7hpt26pT590SLD23rzhrF+/bj2JXxF/evWMTZwIFf/amw1jS2pVk1/kWfVqobXoblMr17myZuuolPVapq1a7lpf/9tue/i5k3GHjwwbR1Tppi3KFqueHHltPbtuWnv3qlXf/3xB1cHLv8M8unOztz7SpXU1yv//9NPGTtzRn8bAlUHDvB/BwcPcm0zHj9WTktJ4dK5uTF26ZLYvamfrn0WGKg9rV8/9f2hWqwuxI0byuVfvuTWV66cdnF+hQrc/7Vr68/r4cOMPXqkfP/smeE8pKVx+5ev6iU/X9x3KIbYY/b1a+OWE7uMkDzXrKmcpvp9HTume5mlS7kqFbmtW5XzfvqJse7dueNayP6aP19/Pm/eVKaV/z7j4vQvYwxqMyIA30GmWhf46BFXD3/zpnZ6OaHBSEQEN79VK3F5tIdgJDRUez8/eaL8v1o1w+v4+GP15c0VjHh48O9f1WBEbscO2/4uzNFmpHJl7c+oGoycO6e+Tfn0P/7gny6Tce9V21ipzu/TR9xn1BWM6PL0KRc4mZuu/RcYyNjx41zbpGHDuOBDtW6+UiXx21INRuSf5fPPldMePuQCgjt3uGNA3k5AbsgQxlxclOmPHOFuguTv37wxeXdYjK79rNmYXP7KytK/nDHByOnTjI0Zw9iIEdz7OnWE5Vm1/Zpqg1w+mzcz9vPP2tO3bRN3vP/yC5f2wAHDaVWvXRUrUjAiiDWDkZwcLnAYPFh/ejnV6BJgbOFC/m2lpXGR6tOn4vJoD8GIasNPvh+/kGAkP5+xkyeVy/Tta568HT3K9Tz6+2/16XzBiOpFwRZNmmR8EFK4MGN79nClVJqfsUQJ3Z/bUDAiX+bcOe7OXd6w8tdfucAnOVncZxQbjFiKrv1Yrpx6uuxs9fTGBCOqPSFyc7lpT59yv5tvvhG2DtVeLkePctP+/puxnTvF58eadO3n9HT19/36MbZ7t+HlVF8DB6ofS6q/b75zPWPc9UFfBwDVbasGI7t3G3fcig1GGFMec4bcvq1ct7xUTcpghMbG+3///cfV47q4cPVqQqm2/9CnRAn7GgtCDM3h4DXHcBBSRy+TcYO2Va/O1bMPHGievDVpwrVVEKJSJa49TcmS5tm2uRlqmzNvnvbjBdasAfr2Vb7n+y6MaUPRvz/3bKIZM7j3tWoBt24p50+YwL3EEjvQmbVp7ivVhoPG8vHhxqVxc1O2ifLz434HQvHloyCP6aHZnmTFCvVxe65f58bl0deItkYN4NAhZWN/Ie0mrD2abHi4+GWEHnOqDeilfhYXQA1YFRo2NNwQUP6wJ9VeH15e3HDVcoyZO2cFn+Y+4RvASqiTJ7mGsmJHqzWXZs1Me46HJRkKRlQbogJcg13VQAQw30lp+XKuwdycOeZZn1zJksDNm8Djx+Zdr6XJH4b23XfGLV+/PlCnjtmyY1cuXtQOEipX5j9HaD6/q3lz6/yejb0uBAZygVVamnnzA3BB2OzZwPffm+dZXKaiYESEmTO5k6DmUxaNad0slDEtym2N5g/RlK6FRYpYrveIqqpVLb8Nc9MVjLi7A+3aCVsHXzDSsSP3V99xrvkdu7hw3WwtccdVsaLtlk7p2s8LF3LnDs1RSK3p/fe5rpt8zzwqaFSPN83RpXUJCwPWr1e+t3RXeNU8vv8+18vQmCeYV65suZFav/4a+Pxz5Xspb6apmkYka58Ex4zhhl7u1s262zUnzQNcfoGqVYsbJ0LfmAhSadiQ6+dvE13eBMrN5Z/+6hVXvK85zLjQKpnoaO5E3qmTyVm0W19+yV1s5N1cNclk0gdQBw5wAas9PJxNtSpC85lQqkaOBBYv5v4/dUr9+OY71n19gefPzZNHVZ6eXFdtW933Uj6TRs6o+5aYmBgEBwfDw8MDYWFhOHr0qN7069atQ+3atVGoUCEEBARg4MCBePbsmVEZNif5cwTMXZRsTj4+3AVb/hwIeyC/wB86BPzzj3pkbkt69dL/cEFbo2+sD74ntfKRt2tSvYMrXJg7qWuOH0M4O3dyVbgjR2pXhdkSmcx2L4ZitG7NHdPnz3NVgZpPW1Y1fz537oyP1y6l4/s97N+v/t6UUm++0kJbuOjbKtHBSGxsLCZMmIAZM2YgMTERTZs2Rdu2bZGcnMyb/tixY+jXrx8GDx6MS5cuYfPmzTh9+jSGDBlicuZNJY+u9R3MYlGbEW2q++TDD5WD7hQrxg38RY8YNw++pwC3aqU7Pd+JcfBgrk2O2MHyNBspO5J27ezjIl8QPHumHOQwNJQrsdPH1ZVrF8E36jLf8a/ZLufSJaOySYwgOhiJiorC4MGDMWTIEFSvXh3R0dEIDAzEYnlZmIYTJ06gfPnyGDduHIKDg9GkSRMMHz4cZ86c0bmNrKwsZGRkqL0s4aefuEe79+5tvnVa+vHiBZHq0PSWbF/j6PgCYdVpmneGHh7a6WUyrvpMaFulPXu4ofGlalBMHIuvr/naIRkqpShb1rSSLroxFUfU15qdnY2EhAREarTCiYyMRLyO/rCNGjXCgwcPsGvXLjDG8PjxY2zZsgXt27fXuZ158+bBx8dH8Qq00G1XYCAXPOircxQqMZFrHEUnZW26HtNOzMvQyU+15CQkBPjmG9O32bo1N/w2FT8TQkwhKhh5+vQp8vLy4K/xFDZ/f3+kpqbyLtOoUSOsW7cO3bt3h5ubG0qVKoWiRYtigZ4nYk2fPh3p6emK1/3798VkUxJ16nDPSyFEKqoPDuRTpw737I67d7kSQWoDQhyZrgBa3uPJ1LZsVDIijlEFXjKNb5ExpjVN7vLlyxg3bhy+/vprJCQkYM+ePbhz5w5GjBihc/3u7u7w9vZWexH7QD9Qy3F1BVJTgZQU3WkaN6aqMkIA3cHI+vXc2CWjR1s3P45OVNPB4sWLw9nZWasUJC0tTau0RG7evHlo3LgxpkyZAgCoVasWvLy80LRpU8ydOxcBAQFGZp0UJDNmAEuXcmO1EMvR/BlS8EcIP13BiIuLeUb6pd+eOKJKRtzc3BAWFoa4uDi16XFxcWik4/ncb968gZNGiyPn/296zujbchhz53J37Y7c64IQYjt8fCy7/oJ4eStQg55NmjQJffv2RXh4OCIiIrB06VIkJycrql2mT5+Ohw8fYs2aNQCAjh07YujQoVi8eDFat26NlJQUTJgwAfXr10dpqrR2KLbw/ANHQw1LCVG3aBH3jCnNoeHNzdafo6TKFs4TooOR7t2749mzZ5gzZw5SUlIQEhKCXbt2Iej/K6JTUlLUxhwZMGAAMjMzsXDhQkyePBlFixbFBx98gB9++MF8n4IQwqsg3p0VBKGhXCPgJk2kzol9O31aOXy9fHwRU40apf1ID3M6cwZYtsy2B9O0RTJWAOpKMjIy4OPjg/T0dGrMSogA8judjz4C/vc/afNijx4+BFatAoYO1W6nQ8zn2jXlg+zS0807QCVRqlsXSEoC9u417vk5+gi9flPBOSF2aO1aoF494LffpM6JfSpThnseDQUilqV6q2wLVQnEcigYIcQO9ekDJCRQN15iPygYsW8UjBBCCLFJVDLiOCgYIYQQYvMoGLFvFIwQQgixSfoe9EjsC329hBBCbBJV01iXlH1rKRghhBBi8ygYsRxb2LcUjBBCCLFJVDLiOCgYIYQQYvMoGLFvFIwQQgixSVQy4jgoGCGEEGLzKBixbxSMEEIIsUlUMuI4KBghhBBi8ygYsW8UjBBCCLFJtv9MeWIuLlJngBBCCOFTowYQGAiULCl1ThyDlMEfBSOEEEJskqsrcPs2DQVvabZQBUbBCCGEEJvlQlcph0DxJiGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIkHfSMghFCCCHEgdnCoGcUjBBCCCFEUhSMEEIIIURSFIwQQgghRFIUjBBCCCFEUhSMEEIIIURSFIwQQgghRFIUjBBCCCFEUhSMEEIIIaTgDXoWExOD4OBgeHh4ICwsDEePHtWZdsCAAZDJZFqvmjVrGp1pQgghhJhHgRz0LDY2FhMmTMCMGTOQmJiIpk2bom3btkhOTuZNP3/+fKSkpChe9+/fh6+vLz755BOTM08IIYSQgk90MBIVFYXBgwdjyJAhqF69OqKjoxEYGIjFixfzpvfx8UGpUqUUrzNnzuDFixcYOHCgyZknhBBCSMEnKhjJzs5GQkICIiMj1aZHRkYiPj5e0DpWrFiBVq1aISgoSGearKwsZGRkqL0IIYQQYp9EBSNPnz5FXl4e/P391ab7+/sjNTXV4PIpKSnYvXs3hgwZojfdvHnz4OPjo3gFBgaKySYhhBBCChCjGrDKNFq7MMa0pvFZvXo1ihYtis6dO+tNN336dKSnpyte9+/fNyabhBBCCCkAXMQkLl68OJydnbVKQdLS0rRKSzQxxrBy5Ur07dsXbm5uetO6u7vD3d1dTNYIIYQQUkCJKhlxc3NDWFgY4uLi1KbHxcWhUaNGepc9fPgwbt68icGDB4vPJSGEEEIsSspxRkSVjADApEmT0LdvX4SHhyMiIgJLly5FcnIyRowYAYCrYnn48CHWrFmjttyKFSvQoEEDhISEmCfnhBBCCDGZLYwzIjoY6d69O549e4Y5c+YgJSUFISEh2LVrl6J3TEpKitaYI+np6di6dSvmz59vnlwTQgghxG7IGJOyYEaYjIwM+Pj4ID09Hd7e3lJnhxBCCLEb9esDp08D//wDtG9v3nULvX7Ts2kIIYQQIikKRgghhBAiKQpGCCGEECIpCkYIIYQQIikKRgghhBAiKQpGCCGEECLpoGcUjBBCCCEOzBYGPaNghBBCCCGSomCEEEIIIZKiYIQQQgghkqJghBBCCCGSomCEEEIIIZKiYIQQQgghkqJghBBCCCGSomCEEEIIITToGSGEEEKkQYOeEUIIIcThUTBCCCGEEElRMEIIIYQQSVEwQgghhBBJUTBCCCGEEElRMEIIIYQQSVEwQgghhBBJUTBCCCGEEBr0jBBCCCHSoEHPCCGEEOLwKBghhBBCiKQoGCGEEEKIpCgYIYQQQoikKBghhBBCiKQoGCGEEEKIpCgYIYQQQoikKBghhBBCSMEb9CwmJgbBwcHw8PBAWFgYjh49qjd9VlYWZsyYgaCgILi7u6NixYpYuXKlURkmhBBCiPnYwqBnLmIXiI2NxYQJExATE4PGjRtjyZIlaNu2LS5fvoxy5crxLvPpp5/i8ePHWLFiBSpVqoS0tDTk5uaanHlCCCGEFHyig5GoqCgMHjwYQ4YMAQBER0dj7969WLx4MebNm6eVfs+ePTh8+DBu374NX19fAED58uVNyzUhhBBC7Iaoaprs7GwkJCQgMjJSbXpkZCTi4+N5l9mxYwfCw8Px448/okyZMqhSpQo+++wzvH37Vud2srKykJGRofYihBBCiH0SVTLy9OlT5OXlwd/fX226v78/UlNTeZe5ffs2jh07Bg8PD2zfvh1Pnz7FqFGj8Pz5c53tRubNm4fZs2eLyRohhBBCCiijGrDKNFq7MMa0psnl5+dDJpNh3bp1qF+/Ptq1a4eoqCisXr1aZ+nI9OnTkZ6ernjdv3/fmGwSQgghpAAQVTJSvHhxODs7a5WCpKWlaZWWyAUEBKBMmTLw8fFRTKtevToYY3jw4AEqV66stYy7uzvc3d3FZI0QQgghBZSokhE3NzeEhYUhLi5ObXpcXBwaNWrEu0zjxo3x6NEjvHr1SjHt+vXrcHJyQtmyZY3IMiGEEELsiehqmkmTJmH58uVYuXIlrly5gokTJyI5ORkjRowAwFWx9OvXT5G+V69e8PPzw8CBA3H58mUcOXIEU6ZMwaBBg+Dp6Wm+T0IIIYQQo0k56Jnorr3du3fHs2fPMGfOHKSkpCAkJAS7du1CUFAQACAlJQXJycmK9IULF0ZcXBzGjh2L8PBw+Pn54dNPP8XcuXPN9ykIIYQQYhRbGPRMxpiUsZAwGRkZ8PHxQXp6Ory9vaXODiGEEGI3GjcG4uOB7duBzp3Nu26h1296Ng0hhBBCJEXBCCGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIkRcEIIYQQQiQdZ4SCEUIIIYRIioIRQgghxIHZwqBnFIwQQgghRFIUjBBCCCFEUhSMEEIIIURSFIwQQgghRFIUjBBCCCFEUhSMEEIIIURSFIwQQgghhAY9I4QQQog0aJwRQgghhDg8CkYIIYQQIikKRgghhBAiKQpGCCGE2KwrT67gzos7UmeDWJiL1BkghBBC+Lx4+wI1YmoAANhMCbt6EIujkhFCCCE2KTk9WeosECuhYIQQQgghkqJghBBCiE2S2cIAGA6EBj0jhBBCiCRsIeajYIQQQojNY1LethOLo2CEEEKITZLBBm7ZiVVQMEIIIcTmMVDJiD2jYIQQQojNo2oa+0bBCCGEEJtEvWkcBwUjhBBCbB5V09g3CkYIIYTYpNz8XKmzQKyEghFCCCE2KWxpmOJ/ajNieQVu0LOYmBgEBwfDw8MDYWFhOHr0qM60hw4dgkwm03pdvXrV6EwTQgixf/ksX/E/VdNYji00zREdjMTGxmLChAmYMWMGEhMT0bRpU7Rt2xbJyfofaHTt2jWkpKQoXpUrVzY604QQQgixH6KDkaioKAwePBhDhgxB9erVER0djcDAQCxevFjvciVLlkSpUqUUL2dnZ6MzbS5fHfgK9ZfVR+zFWKmzQgghRA+qprFvooKR7OxsJCQkIDIyUm16ZGQk4uPj9S5bt25dBAQEoGXLljh48KDetFlZWcjIyFB7WcLNFzdx+tFppL5Ktcj6CSGEmAdV09g3UcHI06dPkZeXB39/f7Xp/v7+SE3lv6AHBARg6dKl2Lp1K7Zt24aqVauiZcuWOHLkiM7tzJs3Dz4+PopXYGCgmGwKRkMNE0IIIdJzMWYhzYFoGGM6B6epWrUqqlatqngfERGB+/fv4+eff0azZs14l5k+fTomTZqkeJ+RkWGxgASgiJsQQmwdVdPYN1ElI8WLF4ezs7NWKUhaWppWaYk+DRs2xI0bN3TOd3d3h7e3t9rLEuQBFB3khBBCiHREBSNubm4ICwtDXFyc2vS4uDg0atRI8HoSExMREBAgZtMWIa+moZIRQgixbXSetm+iq2kmTZqEvn37Ijw8HBEREVi6dCmSk5MxYsQIAFwVy8OHD7FmzRoAQHR0NMqXL4+aNWsiOzsbf/75J7Zu3YqtW7ea95MQQgixW1SCbXlS7mLRwUj37t3x7NkzzJkzBykpKQgJCcGuXbsQFBQEAEhJSVEbcyQ7OxufffYZHj58CE9PT9SsWRM7d+5Eu3btzPcpjETVNIQQQhydLQx6ZlQD1lGjRmHUqFG881avXq32furUqZg6daoxm7E4qqYh9uRV9it8svkTdK3eFUPqDZE6O4SYFZ2n7Rs9m4YQOzH/xHzsubkHQ/8eKnVWCCFEFIcORqiahtiTjCzLDA5ItMVejMWBOwekzoZDofO0fTOqmsZeUDUNsSfOTtI/YsER3Hx+Ez229gAAsJl07rAWOk/bN4cuGZEf3Ln5uRLnhBDTOckc+udsNY8yH0mdBULsjkOfvdac47ofzzgwQ+KcEGI6eryBddB+lgZV09g3hw5GCLEnVDJiHboefUEIMR6dvQixE9RmxDqoZEQa1GbE8qQsfKJghBA7QSUj1kH7WRpUTWM5tlDYR78qQuwE3bFbB1XTEGJ+FIwQi8vLz8PWy1vxMOOh1Fmxa3THbn3vct9JnQWHQdU09o3OXsTilp9djm6bu6HygspSZ8Wu0R27dagGfb+d/E3CnDgWqqaxbxSMEIvbc2sPAOBt7luJc0KI6VSrw2jMEULMg4IRQuwEtRmxDtUSKKoasx6qprFv9EsiFkcXSWJPVI9nOrYJMQ8KRojF3X151yLrffH2Bb4++DWuP7tukfUTwke1NITa6VgPtRmxbxSMEIt7/va5RdY7YucIfHPkG9RaXMsi6y9o6MJoHar72VlGA81Zi7mqaXLycix2TiroaNAzO5DwKEHxrBtiHfH34wEAWXlZEufEth26ewhXnlyROht2Q62ahgJAq8nLzzPLeuouqQu/H/2QnJ5slvXZA1s4jCkYMZPwZeHo/1d/7L+9X+qs2Bw6YVvH6+zXiv+fvH4CALj29Bpa/NECNWJqSJUtu6M67D61GbGezrGdzbKeS08uAQB2XNthlvUR86BgxMwuP7ksdRZsjuoJm+p9LScnP0fxf3ZeNgDlidcUjDHcfH4T+Szf5HXZA1cnV8X/tE+s59TDU1JnoUBgjGHKvilYdGqR1FkRhYKR/0cXSctRbfBH3fMsRy3oM+N+/v3M76i8oDIG/m+g2dZZkKkezxSMFFz2es5PSEnAz//9jDG7x0idFVEoGPl/5jp5U5WENtV90nZdW5x+eFrC3Ngv1f0sP9Ga44Q76/AsAKA2UTwoGCm47PXGKP1dutRZMAoFIxoYY+i1tRdmHZpl9PJEt3239qH+8vpSZ8MuWar9gq0d0/fT70vaG0L1IpbHzNOoklifrR3X5lJQgywKRv6f/MA8fv84NlzcgNmHZ0ualzc5bxT/Lzy1kOpLiSj77+xH3+198eztM6mzYlZP3zxFuehy8PvRT+qsAADmn5wvdRaIkQrqRdteuUidASnVKVUHSalJAJQH5tsc056fYo5qmvbr22P3zd24P/E+4u/HY+zusVweZxbMHw/1OLA+efuO/139n8nrsqWT9oXHF6TOAiE2zZjzrZ8fEBAAeHhYIEMCOXTJSOPAxlJngdfum7sBAGvPrcWlNNN7Q0iN2tFYB99zUjKzMyXIiX2z1+J9R2Op7zHuVhwi10ZabORpQ4y5edi8GXj0COjUyQIZEsihgxG+LqeqX+SJByesnid7ZKmSESpxsTy68BJ7MHTHUEzYM0FtmqVK/CL/jETc7Tj0297PIuu3V44djMj0d4W8+vSqNbNjtyxVMmJL1Qe2wND+yM3PxexDs3Es+Zig9U3eOxkVf6uIl+9emiF3hEgjOT0ZyxOXY/7J+cjKVY7WbOlAO+VVikXXb28cOhgx9PjvgnxXmPoqFf3/6m/TpTsJjxIwaucoPH3zVLI8vMl5U6C/Z1WGPsfys8sx6/AsNF3VVND6ok5E4c7LO8jNz9WZZu/NvYj6L8pu9qEQUgbBDzIe4Obzm5JsW99xYMty8pSDAdINjO1y6GDE1kcGNeWHM2THEKw5twYRKyLMmCPj6KpOCV8WjsVnFmPUzlFmXa9QV55cgdd3XuizvY9J6ykoLPF04zbr2mDyvsk4ePeg2ddNtAX+GojKCypbvbQq4VEC3Oe6Y87hOVbdrjnwjb8DWD4woWpkcRw7GDFQTVOQo2hbqmIyVAJ1Me2ioPVce3oNWy5vMVvgGH0iGgCw/sJ6s6zP1lny5Hg//b7F1k203Xt5z6rbm7B3AvJZPmYemmnV7ZrqXe47/JH0B+88W7wBdWSOHYwYODkbc7DaSjRsS4EUX5sRY/ZttUXV8MnmT7Dn5h5zZMvhRJ2IkjoLRI+bz2+i2sJqWJW4Suqs2I0vD3yJOUf4S3MsXjJCvQhFcexgREfxnWKaDV3QxbL1qL/qwqqK/8Xu535/9VNriEY4Yvbjg4wHOuclpyfb7DDntnCC1/xtmatUaOTOkbj27BoG7RhklvUR4K+rf4lKf+/lPYzeORo3nt0wedvXn13Hi7cvTF6Po3DoYMTQA9xs/YKuj60HUjeeG/9jf/rmKb4/9r0Zc2MfxByvgb8G4vDdw1rTYy/GIig6CL239TZn1uxauehy2HVjl9q0+PvxqDC/Ajpt7ITMLGFjvbzOfi14m+cenxOVR0d0/dl13HpxS22a6nmR7/fSfn17xJyJQbPVzcySB9WbLmtIe52GP8//adVtmotDByN8VSoFOQBRZUufwxLVYcfuC+ueSnRbenap1rRvj34LANh4caPFt5+dl23xbViLvP2RXOOVjXHn5R3suLZDsU8NEXMD0f+v/mKyV2Akpyej1ZpWWsGdXPq7dJx/fF7QuvgCAUMNWC894QaZTH2VKmgbhjx588Qs6xGq6aqm+OMcfxsZW2dUMBITE4Pg4GB4eHggLCwMR48eFbTc8ePH4eLigjp16hizWbNTLfLNy9d+4JUlSxd239iNwF8DceDOAW5bNhQ8FAR8+2vkPyPxxf4vzLaNv67+hXOp9nsHyhjD5kub0Xtbb6s/BmH87vFwn+suuPGyLeE7L+ir1nqU+UjYelWO6edvn2PHtR1q3VLNUXVgDW9z3qLHlh5GNQwf+vdQ7L+zH+3Xt+edX+G3Cqj9e23BY+XoY4/nXEv0mLMW0cFIbGwsJkyYgBkzZiAxMRFNmzZF27ZtkZycrHe59PR09OvXDy1btjQ6s+amWk0zed9kfHP4G+Tk5+hZQh1jDMP/Ho7Zh8Q/VK/d+nZ4kPEALde0xONXjxE8P9joJwXz5s2GqmmsUc9/49kN/J7wO+Ydm2fwJJOdl41LaZf07qMzj87g49iPUWdJHTPn1HKM+c4/3fIp1l9Yr7izN/a4YYxhxD8jBB/Dv536DQAKZFdRPqr77cnrJzrn8Rm6YygaLG+gdu5ptqoZOm3shHnH5gHgGrdWWVjFjDm2nAWnFiD2UqxRVX2PXz3WO1/+tOYd13YYlTdiu0QHI1FRURg8eDCGDBmC6tWrIzo6GoGBgVi8eLHe5YYPH45evXohIsLwuBdZWVnIyMhQe1mCavXBsrPL8PWhr/Hj8R8V0wxd1C6kXcDSs0sx6/Ask/Ix79g83Eu/J+mTgi3JUNdec8jKUxlZ0cDJv+26tghZHIJ1F9bpTGMPzwQSI+11GgDj7xYvpl3EkoQlkh3D6y+sR+3fa+PW81uGE1tATl4OFpxcgEtpl/BZ3Geill2euBynHp7C2ZSzimny6oLYS7EAgKP3hJU+i/H0zVOzDziYz/Lx+b+fG728pW9c1NqM2NANGxEZjGRnZyMhIQGRkZFq0yMjIxEfH69zuVWrVuHWrVuYOVNYH/V58+bBx8dH8QoMDBSTTcH4DvyTD08q/lctet1+ZTta/NFCrRfCu9x3etf/7+1/FSeR84/Po9umbrjy5IpWOr4qIn3e5b7DwlML9Y7EWJCKIPlOCq+zX+vdL5rfnZgB7ORVY29y3iim6asuKEj7UgzV/S6TyTDn8BzFRVAs1WBQDHNdfHpv643zj89jxM4RimmMMUzaOwlrzq0xyzZU16vpaPJRjNszDiGLQ/Aw46HB9GK3Z6iHzdWnV5H+Ll3wOrPzslHipxIo8VMJtaogU226tMmk5S09NIJamxED34vq+T83PxexF2MFV7nxyc3PtdtziTmICkaePn2KvLw8+Pv7q0339/dHaip/g58bN25g2rRpWLduHVxcXARtZ/r06UhPT1e87t+3zIBKfAe+aqO6UbtGITmdq37qsqkLDt09hK6buupdfszuMXib8xbP3jzDh2s/RLPVzZCXn4fGKxtj65WtqBFTw+THun939DuM3T0WlRdU1pmmIEX9mj/QtNdpKDyvMBquaCh4GbV5///ZD9w5oLMhnKb3lr2nc97HsR8LWodcdl42NlzYIKgR3I5rO5CYkihq/bqYcqL79cSvJg1oZUrvKHN6lf1K8f++W/vw64lfC3xjzzsv7/BOl/e+SUpNQvVF1VEuupzgdT5780zxv3yf5ebn4si9I7w3WUKDBFMHYzM2OH2X+070tjXPkZq/n6j/lOPyLDi5AD229kD1RdWNyt/bnLcoG1UWH679UG+652+fO2zAYlT5ueYBwxjjPYjy8vLQq1cvzJ49G1WqCK/vdHd3h7e3t9rLEoQc+Jp12qcensL8E/P1Lv/7md/x7K3yx57H8tROkp1jO6ulX3h6odAsAwAO3T0kKr0lMcZw+cllvc+tEPvj+vva3wC4dhv6qO5/zTFj8vLz0HJNS7Rf315QUbS+Uq7/Xfuf4H3+4u0LlIkqg17beqHeknp6055LPYdOGzuh3lL96WyJrv1k7EB05j7xql40pXzmkTUUnlcYz948w+4buwEAGVkZGLVzFO684A9eVPHdrEz/dzqar27O+7RZoTc3ppZ0CQ16GGP4Yv8XGL1zNF68fYHQxaEoP7+8wcBe9XNEn4hW606tWYI2/+R8xf+7bnI3NRlZxjUZOHT3EB6/foz9d/brTLPtyjb4/eiHiXsnGrWNgk5UMFK8eHE4OztrlYKkpaVplZYAQGZmJs6cOYMxY8bAxcUFLi4umDNnDs6dOwcXFxccOHDAtNybyNgiwQl7J+idn56VrrZuKVrBWyu6XnBqAWrG1ETf7X3N1lXTmCJ/1f2dz/KRx5RVPEKf46Gv2qvFHy0EnYh6beuluAgaemqnuYfst0Zp2MyDhktP7P3OztB+1rpZ0xjbYmrcVLONBRF3O07t/eIzi9F2XVuj1vXLf78AADZf3mww7bvcd9h0aZPWoF66zqmH7h7CoP8NMjgImND2ZZnZmZh3bB5izsTA90dfxW9365WtepdTPTafvX2GGQdmKN7LG1VLZUrcFADqQZAjERWMuLm5ISwsDHFx6j+AuLg4NGrUSCu9t7c3Lly4gKSkJMVrxIgRqFq1KpKSktCgQQPTcm8iIVH8isQVOsdc0PXD0ywpkh9kYuk6qQu56Firmkbe2n/jxY1wn+uOndd3aqUxtJ818zp612itNGLqwxmYWn2v0KCz8oLKuP3its75QoIaMSUEUo8mqtpgUqgf4380WG8u/z5VB/vKzMrET8d/EnTXbgqp9ykA3m7Smy5tQvVF1fHriV/xU/xP6Lu9LwAIGqFT3/HLGNP6/Vx7dk1kjsWbsm8Kum/pjtZ/tlbkY/6J+Th+/zhv+hZ/tMCqpFUGG7eqfn/6SiuXJCzhX97QmEYa+0r1AY+ay9pKUB1zOgbfHhE2Vk1BJrqaZtKkSVi+fDlWrlyJK1euYOLEiUhOTsaIEVzDsenTp6NfP66Yz8nJCSEhIWqvkiVLwsPDAyEhIfDy8jLvp7GQnlt78k7Xd+JT7Y2hWkVjLcb+kD7Z/AneX/2+4OHANbfTa1sv0XlRnf/rf7/ypvH/Wb3kTfOk8uKd8qSuuT2ZTIZ159eh+5buBsfT0NdrIZ/lo9PGTvjqwFd616GPoVE28/LzrHYSNHZMgnXndfdCArj9/3P8z/D+3ltR9D1x70RM/Xcqav1eSz0tT9D863+/4uPYj7UaVjLG1AIhvt/V1adXFVWGUgUmmhdkxhi6b+mOq0+vYvK+yYrpWblZ8P3R16RtJaUm6R3aXwwxNzB/XuBKdk4/Og2Aa/s0Ye8E/O+a/vZw+oJ9QP23W/G3ioLzIyf/znXeyGmeG8Bf1QsADzMfYmmC9sCA0/+dLjpfQugKpEbvGo0vD35pciCfm59r1sbK5iY6GOnevTuio6MxZ84c1KlTB0eOHMGuXbsQFBQEAEhJSTE45og9uPzkss6DJ+11mlq7EHNVXxxP5r/r4GPoxKKrp8qWy1tw+N5h3l4/xhJzkpu0bxLvdM2qmwN3Dqj9sFTHNMjIylCbJ4MMfbb3waZLm7Dg1AK929cXhO2/vR87ru3A3KNz9a5Dl0WnFqHwvMKKC7Tm8fM6+zWCooPQfUt3g+vKy8/TughV8bONcSgYmKI0UN54VN7mRl9g/uT1E64HzL5J+OvqX4purXIzD81U+56LzCuiVbLw/O1zdIntAsC4atj0d+mourAqpuzTXZop9nkjuo5/oT0z9AVVP8b/iMVn9A+rYA6a+1LzvblKY+TBDSB8/6iS54vvpggA1p5fa3BZVcP/Ga417fvj4h9FYY6SalNuahljqLKgCkpHlbbZgMSoBqyjRo3C3bt3kZWVhYSEBDRrphzHf/Xq1Th06JDOZWfNmoWkpCRjNmtTasbU1HmSuPlCve2BuR461mRVE8Fp9d1df3/sexT9oSguPL6ge3kjG6wZc1cvf36E2GoD1TYZd1/eVfxf6pdSCF0cyptH1V4EfPR9V49fKwdkavFHC0zYM0FEbrmeVoDuobx3XNuBh5kPBdXZd9vcDYG/BqoN/uTradpdtlCGShz4qshUnxEy7d9piv/vvryLaguroceWHij5c0m1QEzz5PvNkW+0tnX4nvbzdf6+/reBT6DbsrPLcP3Zdfz8388603y08SOj16/K2J4Z5mbo+9x3ax+OJusf58RWHqwob3Oiq2p9/J7xau/lnz0rN0vvfjBnl+NvDmsfx6p5UWWuUtLsvGzceXkHT988xb1003o8WYpDP5vGUjQPXHP/UE09QKfvn45X2a+0GuIas14hy0RWiDSY5ljyMYQtDRO9fV1Uf3D6imI1yRu+8qVTbex26O4hkxuamVKNIH8aqbzRoS1RPSb4PuMPx39Q/H/m0Rlce3ZNUQoiJBDTtS19fjj2g6C0Qsb8Edog2hBjx2YR69mbZzjx4ITRy8vbhahS/V6vPb2G6fstU3Uhltjf1OUnl/Hj8R/h8a0HTj08ZaFcqfv60NcmLZ+XnyfqoYqAbbSlMsShgxFTo119LcdVqQ6uJXobAg6ix68eo/qi6vjp+E+KaeYoFkx/l45p/04T/GAqXdst6VXS4HJNVzXlnZ6bn4sFJ/VXrRgi5odoqTs8oeOdFBSMMSw6tYh/nupgaib8xszZdmba/mlqjRULEmP3obw4Pig6CBErIvDv7X8FL3vq4Sm93fVVqbaDMcTSDevFnmuz87JNGjHWUhadWoTJeyerDREhV3dJXRSeV1h0daGcrTTM1eTYwYipfeJ1LK/5fJsrT41vf8F34Gj+oOccnoOrT69i6r9T9S6nSav1uMp6l59djhE7R+CH4z+g9u+1Red57bm1ika8ppyAFp9ejHF7xhm9PKBRMmLgxC4PRsz9g9V88NdXB74yy0OtVNuNWOskMyVuCmIvxSqqnTSp5iOP5eHIvSMWy4u+Y0vz93k/3fDgiarLDPrfIFHttHQx9Xsx5jy15fIWuM11w9pza/E6h7uLbreunaLxpWaeNO+0GyxvgBn7Z0AXza70tsIaj54A1Pffxosb8dm+z5CTl6OzfaDmPpq0dxJG71T2Grz29Jra0AJjdo9B1Iko/ByvrC6UHwcX0rjqdX1jlhREDh2MmHySsMDQxduubBO9jOoPYO/NvUZt9+f4nxVF/wDX192Yx8gzxrA0YSn6/dUPIYtDFNOMZWogAugeHE1Kc4/OVav2MdbtF7eNejqqqVSf4aRJM0Bovrq5xfLxx7k/DPbQkBMbFK9KWiWqnZa5tqvJmPPMJ5s/AQD0+0s5gFlOfg6+P/49b0kn38B7P8br/o5Vif18+hpidqvRTdS6NFl6OHk5+Tk3/V06em7tiV/++wVjdo1RK51WteHiBrX3v574FTFnYhSNdKstqsa7nGr3eHPdbNhi1S7g6MGIiSeJUbtGmSknSqrDzQP8DUT19XRps64Ntl/ZjidvnmjNy8jKwOdx2kWSJx6cwJS4KVrbNuRY8jG1Rp1yqs8HAaQfml5MycjoXaPN8nhya/r2qPXHIEhM1T3SZUqm/sHehBJy3Oy4tkNwF1BbLZ62NtULHAAkPErQWUqn6+ZG9bwkpmTkwJ0DKDKvCCbv5a/acZY5C16XrnyZq6uzPhEruAe+qgZWS88uxZ5b/OMM6RrB2ZSeLWKOZ9W0fGO0nHxwEvtu7TM6L+bg2MGIiScna1y0NB+65TTHSW1MDT5dNnXhnT5l3xS1ux35CUVoF7rX2a8VvVFy83N523nwXUCkvgiILRnR1X7F0nRdfBljOHjnoM6eQNa6GxSq2epmhhNZAV815KPMRxj+93Ccf3weR+8dxbyj84waIE8MQw/U1Od++n21nmHmoHmctVrbSmfaNuva8E4X82BKPlEnuOe+aAYy5hhO3hJdVzXzlZiaiHlH52k1ZhZbZSXmRk3XgHLG0Kx+bLiiIVr/2VrremNNwp5cZ6e83Gx/0LXlictNXkdefh6WnV2G9Re1i/NPPTwluETE53sf5LE8LOu4TNQzGqQuGVEl9GIj9KR458UdpL1OQ4Oypo0mvPXyVq2hveXWXVinGLHz7Yy38HDxUJt/6ckl3pE4pWLKk01VqV7knr99LmrZG89uaO2PfJaPPtv64ODdg1h6VjmYVRnvMuhXW/t5LOai2v1arMzsTMOJJGbscZeRlYFqC6uhVYVWWPOxeZ6snPY6zWq9lL448AV2XFf/bkUHIyICuZE7R2JE+AjDCfm2o/EdNVnVBFdGX0G14urVQw8zH6KMdxmjtmEqhy4ZGfWe+atZzMlcF5dlZ5dh5M6RWnW1/97+Fw2WC7uIymbLFN1eh/49VGcLelN6DlmK6rgW5m4zUuG3Cmi4oqHJz5nptrkbViet1pqelZulCEQArosq34VZ9TPaizymHI029mKsgdTqqiysojVy8var23l71Fx7qn/Ars2XxHU3dgSqvyMxj2pQte78OqS8SlEbiMzUkqmlZ5dadfwWzS7TliwZMWbZW89vISk1iXfesL+HIf5+vNqo01I2RnboYKSwW2Gps6CXkKhZSPc7U8YYMAepq2lUT3aWyovmYEpyQ3cMxX/3/xO9vqlxU/Eq+5XWMPizDs+C349+WumFNjYsSMbvGc87xoWxdHWvVm1cyBesfrrlU4OPEShI/jz/J3be0H6GlLFUR00Vg6/ni600MNck9CJt7pIRzf0RvjRc1PorLaiEukvq8la/3Eu/h8YrG6tVq0p5rnboYMTWCYl8t1/ZboWcmMZWqg8AGD2UuyG6Gn8tT1yORiu1HyJpyE/xP6HqwqpIzzLurtNe6Kq6Mqc7L+8YHLMh6r8oi+fDWpYkLOEd5lyo7Ve2I+11msn54HuOja21fwKArw9+LXiMFl3BiLEPPZV345VLSElQ/H/+8XnBwc+0/dolp8np2o9tkfJcTcGIDZt5yPDj2t/mGr5jkzoYkLpkpKAS2/aC9rPxXmW/0vsMKdVHDzg6XQ3kxdp9c7fWtHUX9D+EUQp8jyHQhS84mHVols7jx1AwoW+Mnm+Pfqt3LBhVWy5vEZSOqmmI0YTcSUh9kTJnK3BrkXqfEetKTE1EkXlFMOfwHN75dDwYR8jw+oB2r8GCiq99xuzDs3WmN/W4Muahffr876r+py5bEgUjBZyQOlYpS0YupV3C3lvGDcRW0MTfj5c6C3bp5/ifLTKmj6pJeychOy9bZ+8VqUsXC6pNlzYJSmfJgfFsmTmOq62Xt5qt44Cx7X/MwaG79toDGWQGu/+tOy9d0eeys8sk27YpjGlIF3M6xgI5EY6v67Y9mBI3xeLbMNTNnzGGfJZvteHG7cXTN08FpVN9qrMjMUeJW7fN3Ki1bKbp65Ly+KZgpIDrs72PwTR0VyfekB1DRC8j9TM6jHmUAOEYehjk29y3qLqwKuoFaA+bTnST+jdh66btn4b/9TBP1ciZR2dMXgcFI4TYGM2HHQpBJ177dfDuQSSnJ6s9zIwYRr8J/UwZEE+TOdrdSBmMUJkjIWZCJ1775eniKXUWCiQqlTVsyRntZ8UYwxxjtEg5zgsFI4SYCZ147de1Z/pHaSX8bj2/hf237etR9+am+WBRY5mjVMPfy99wIgtx+GCEGqQRc6GSEULUxZyJ0fsgPlWGhuUn+pmjMWybSvwPRrQGh78S2+KIf/Zk/sn5UmfBai6lXZI6C4QUWNUWVTOciOhkjkdCSHk9dPhghEpGiLlQUT4hRCrHko9JnQWTOPyVmIIRQgghRFoOfyWmYIQQQgih3jSSstVHVhNCCCGOwuGDESoZIYQQQqTl8FdiCkYIIYQQaTn8lVi1K1Ml30oS5oQQUtDQzQwh5uHwvyQ6mRBCjJU+LV3qLBBiNjTOiIRUgxEaAI0QIkZht8JSZ4EQu+DwwQj1prGeQq6F0Du0t9TZcAhV/apKnQVCCBHM4YMRqqaxHi9XL/zZ5U+ps+EQjgw8ovi/dJHSEuaEENPNbD5T6iwQC3P4K3GHyh0AAEE+QVRKYmH0VFvrKelVEhWKVQAADKs3TOLc2LewgDCps2D3Zr0/S+osEAtz+GBkftv5WNh2IY4POi51Vuye/KmSz6c+lzgnjuHE4BPY/MlmTG86Xeqs2LXt3bdLnQWH0zOkp9RZIGZmVDASExOD4OBgeHh4ICwsDEePHtWZ9tixY2jcuDH8/Pzg6emJatWq4ddffzU6w+ZW2K0wRtcfjTLeZaTOit2Tl4wU8yyGg/0PSpwb+1fCqwS61egGN2c3qbNi11ydXaXOgsNZ1WmV1FkgZiY6GImNjcWECRMwY8YMJCYmomnTpmjbti2Sk5N503t5eWHMmDE4cuQIrly5gi+//BJffvklli5danLmzY1601hWPstX/P9++fdxfcx1CXNDiHn4efpJnQWHUsu/Ftxd3FHMo5jUWbE7BerZNFFRURg8eDCGDBmC6tWrIzo6GoGBgVi8eDFv+rp166Jnz56oWbMmypcvjz59+qB169Z6S1OIfVINRgCgsl9liXJCiPm4Orvi+dTnOD30NFqUbyF1duyei5OL1FkgFiAqGMnOzkZCQgIiIyPVpkdGRiI+Pl7QOhITExEfH4/mzZvrTJOVlYWMjAy1lzVQA0vL0gxGCCnIirgVUfxfzLMYwkuH40D/AxLmyDHIgxHqcGB+BWbQs6dPnyIvLw/+/v5q0/39/ZGamqp32bJly8Ld3R3h4eEYPXo0hgwZojPtvHnz4OPjo3gFBgaKyabRXJ2o7teScvNzpc4CIWazq/cuqbPgUCZHTAYA/NDqB4lzYr+kvCE3qgGrZkTKGDMYpR49ehRnzpzB77//jujoaGzYsEFn2unTpyM9PV3xun//vjHZJDaGghFiT2j0Vev6OfJnZE7PxPvl3wdgubv4IJ8gi6yX6CcqGClevDicnZ21SkHS0tK0Sks0BQcHIzQ0FEOHDsXEiRMxa9YsnWnd3d3h7e2t9rIGqqaxrJJeJaXOgsPqXK2z1rRR4aMwsM5A62fGTui6GB4beAzNgppZOTeOwZgAsH6Z+qLST2syTfQ27EWBqaZxc3NDWFgY4uLi1KbHxcWhUaNGgtfDGENWVpaYTVtF64qtBaWjobaNs7PXTqmz4LBWfLRCUcwtV6pwKazstFKiHBV8ukqDG5drjHH1x1k5NwTgL9UYUHuAqHXULFETmz/ZDG9369wEE47oappJkyZh+fLlWLlyJa5cuYKJEyciOTkZI0aMAMBVsfTr10+RftGiRfj7779x48YN3LhxA6tWrcLPP/+MPn36mO9TmMm3H3yLmHYx6Fe7n95005pMUxQVEuHqlKpjle2UKFTCKtuxVZEVI7Wm+Xr6at3xfVrzUwBAwrAEq+TL3ui7i+RrrK3a0+aLJl9YJE+Ojm/MlzyWJ3j51Z1Wo2lQU3Sr0Y33OyrqUdSU7BE9RAcj3bt3R3R0NObMmYM6dergyJEj2LVrF4KCuIg0JSVFbcyR/Px8TJ8+HXXq1EF4eDgWLFiA77//HnPmzDHfpzATT1dPjHxvJL794FuDabd8sgWL2i2yQq7swwfBH/BOX9JhieL/cj7lzLItDxcPs6ynoBpbfyzvdPkIuHJVi3MlfPUC6gl+gOFPH/5kWubsiI+Hj855mlW+Xat3VQtQ5rSYg29afGOxvDkqvgBRTC++7iHd9S5HY1FZjlENWEeNGoW7d+8iKysLCQkJaNZMWT+6evVqHDp0SPF+7NixuHjxIl6/fo309HScPXsWI0eOhJOT7Y5EX9a7rME0foX8MOq9UVbIjX0o71Oed/qwMOVzUzQvlkIFFA5Abf/aRi1rj4zdj0I0LNvQYusuaPQFz/UC6in+b1+5Pf7s8ic+rvYxAO7Bhc5OzrwlWIvba4/X5OXqxbsNzWo3RxNcLFhQOjHBiGqw4YhDERSoQc8c1dZPtyr+1xcd+3vpb8jrqIQ8HVnoj/+fnv+gRokaiveRFSORNCJJ8T47L1t0/oTY0FV3DzBbYkxDbKHL0FOuhankW0nxf9NyTeHh4oEx9cdgR48dSBqeBAB4r/R7KFPE8GMozg4/qzVtQJ0B+DnyZ7PkdVcv83ZRtlbpQWy3WHxU9SMcGXAEqzutxrUx13jTiQnOVY/vIu5FtOaLvVg7eimtGHRm0eHciHNqwzx3qd5F8b++E7fQk/W7Ge+Mz5wZfdXsK6tsR99+qVa8GgBlGwY5vjvHMkXKoH2V9jg6UDmCr+b3Ua14NSRPSEb8oHg4y5xNybaaHiE9CkTRuiVLRuTflaaOVTpabJsFnTwwcXZyRseqHVHCi2vTJJPJ8F3L79TSal7I9/XZhyp+VdSmfdHkC/zW5jez5O27D75D28ptzbIuuVYVWpl1fbpUKFYB/+vxPzQNaor+dfpr7adh9YZhWcdlotqMqAYbQ+sN1Zr/84fiAkBrtZMzF0ueOwyhYESHWv618HuH30Uvx3cB5SNVcdjI8JFq721hoLdjA4/hr+5/aTWw7Furr85lfD19Ff/LS1TOjTiHgXUGYs3HaxDoE4iIwAiz5/Xzxp+bfZ3mZlTJiMpJSFeVV/KEZLX9rqp68eqCtjP7/dmi81ZQHRlwBD99+JPajYwhmueFDyt+qJXm25bf8t61G0P+RGchQ6xrBqJTG03lTWfuc5uuaio+YaXDFP8v6bgEQ+oNUVSPieXp6ol9ffapTetdS1jbKrmCUppqCygY0UNXlKivGNLd2V3xw/6o6kc600nVEMoWG2D5FfJDp2qdRAdG8juh7jW5Rme1/GthZaeVZmsIy6cgPKFV13Gr+vRezYuPagCjq3dNoI/+kZCFFEmPqT8GbCZDXN84rXn6Bpva32+/wXXbmqZBTfFZo89EXZxVf59tK4kvsfikxidq77tU74J7E+4ZXO7DCtpBjybVrq5nh53FDx/yj4Rq7nNM/9r9Badd1G4RJkdMxrkR5xTTKvpWFLy85u/iw4of4uLIi4r3MshEjXVSvmh5wWmblmuq9r50kdKCl7UHFIzoYcwdpkwmw+VRl/F9y++xrss6C+TKvKw10Ju57pZU83tm6BmcHXYW7Su3t/h2rdkV09TGuLq+Ux8PH3z7wbeoWaIm7o6/qzbvvdLvKf53dnIWHdDJZDIkDk80OLCd/EKlWZRf2782boy9wbvM0HpDdfbGEmJpB9t7Qric5g2L6vH6T69/FP+/+eIN/un5D9Knpetdn+Z3v/XTrYK+ywVtFwjJroKXG39pRbvK7cxeMiKmIamvpy9+jvwZtfxrCV5m9HujEeQThOUdlxtMK5PJLFaVoXm9iG4dbZHt2CoKRvQw5qDrWKUjKvtVxudNPtcbQev6wYaWDDW4je9bfi86X1Iz5m5JBhm2d9+uNhhdoLfy7ryIexHUDair9+Q3pdEUAMrSE2OpFrUPrTdU6y7GnKY25i/+FkrfcftF0y9wcdRFlPFWbzg5tv5YRLeOxoWRFwAAh/ofwpRGU3irZXqG9NSaFlw0GNWKVzPY9VfXd5UwLEFnqZP8wnJtzDV83exrvevn0yOkh+hlrKWoR1FkfZmFdV3W4VD/Q2rzVNtZebp6on2V9oIG4prehKt6EdO+SUzpAaD799yuUjtR6xHC3L1aNIdk+KrZV7g74S4G1xtscFkZZGr5yf0qFx2qdNC7jLx35qA6g/Sm8yvkhwP9lA9a1FeynvWl7Q0aaioKRvQQW2pwbOAxtKss7Meo68d8Zhh3tz+p4SSdy9YsWVNUvlSp9kIB9F+4pjU237DIxt4tda7WGXv67MGh/ofQrnI70XWw37T4BvGD4vFH5z+M2j6fpR2X4sjAI2Zbn7kZU9rl6uyK8Q3HI6RkCACu2+SPH/7IW1TcoEwDrWlCTuSA+nG/5ZMtAIBx9cfB2Ul3Q2P5RbmKXxXMbmG+NidHBtjGd+jm7IZeob3QvHxzk6s4ZJDh2w++xa1xtzCj6Qy9acUO4MWXN81pDMzs1TRiGqAKodluzr+w/h6QWs9iU/l9OTs5G6yevDH2Bh5/9hgrOq3Q2eYK4I7zFsEtwGYysJkM7i7uetNaQoF7UJ6jEBORFy9UHI3LNRZ80dWVzs3ZDXUD6qodbOas7inqURQpk1MU71tWaKkz7aQI3QGRtTUv3xw7e+0UPLaAnLOTMyICI/T+sAGuMZ6+H7iQBn4AsLDtQlH54yNli3ZjCd0/qsd91xpdwWYyzG87X+8yprYB0vytpU9LR9pnaWgapCzdUh18r6CTyWSoUKyC2ufWHMhxYsOJODnkpOj1av7/dsZbreBjYsOJYrOsl7lLRsTeGKn+HmUymej8eLh4CHoul5ggztSAb8VH/IER9aaxUZb8YgwdTKoRat1SddXnMYYzQ89geNhwUS3NAe4OuFThUkidnIr4QfFoUq6JVU7EPu66R6vUxRo9jkoXKY1PanyCWe/P0jmgV/vK7Q3WQcsgQ0TZCIyuP9rkPL1X5j3DifSw9AnFlO9F7Ek0omyEzjZBo98zbl97u3srutfKCRnoUJWlnj1jqWP+i6ZfKEq5QkuGIqp1lFZXWDHk36O7izuWf6Rsa8EY4+0BJJZqm6aaJYwvCdakOTqx2BIGGfS3GVnVaRXaVGoDgL9rsFiqvTMjyip7B5paMlKxWEWb68xAwYge8oNKs6843wnDmC9WX398QxeUsNJh+L3D77g06hK+avYVmgc1F7RN+dNb/Qv7K7q+Dgsbhr+6/8WbvluNboLWC+ivE7WlUhZVfWv1xaZPNsHT1ZN3PpvJ8E+vfwxeJDKnZ+LYoGNmyZMpFwnAvEWt8mHiVdsy9a/d3+jSCjEX29TJqYgfHK9zGc0um9998B1vOiFUH36pOYaHZtfcGU1nILpNtNHb0kfseeTBxAc4O0w5KJq+/Xt4wGGMfm80/u75t9H5M0S1a60QicMTeacHFQ3C6aGn8U2LbzC2Af/jDYxRzKMYAOD00NMYUGcA7oy/Y3AZ1WH/ZTKZoi3OsHrDtNIOqDMAu3rtwsWRF3lH09WHr3RxU7dNiv9Ve1fJZDL0Cu2FNpXaIH1aOp5NfYYx743B6aGnBW3LSeYkupTZ0oSVrToov0J+eDX9lVadoJg7z3aV22HXDW6Ew2Udl2Ho31y0LJPJ4OmifgFUrcP+sOKHiDoRxbtO1RNOUNEgzGkxB/de3kPLNS0xrsE4jN8zXmd+VLt3qupYtSMmNZyktk1fT1+s6rQKWy5vMfApObq6fjYo00DrTpSPFN1m+9QyzwMbC7kW0roQlPQqiWrFq+HIPdPaJqROTsWGixvQK7QXLj+5jBZ/tNCb3pwlI581+gy1/WurlRr5ePjg7vi7GLRjEFYnrRa1PlFF0TourPv77ceFxxfwQfAHGFRnEFYmrUSbSm2Mulu8MPICnr55igrFKiimNSnXRC1NKa9Siv/fznhr0VE1xZaMlPEuo9UYWZdKvpWwsJ3p1YiA7nw2ChT+9HZA/6Bg4aXDEV46XNT6hAovHY5VnVYJSlvWuywWtl2oaDw8tfFUdK7WGZX9KgOA1nlcJpOJatd3euhpuDq58rabUg2EfD198XDSQxRyLQRAu/p+QTvhPaJkMhliu8Wi4m/qDZeFVrdaApWMGODl5qW3cZ0hWz/dihODTyDv6zyt4sboNtGo7FsZv7f/HWwmU6vD1tdbg+9iE1Q0CDfH3cS4BsYVHzvJnPBL618U74fWGwpnJ2dRferH1B+jNa2KXxXBY0QUdiuMqEhlMGTpYsTHnz1WNNjkI+bun+/k7CRzwuEBh43Kmyr/wv6Y0HACSnqVVHtatOZJUM6cJSMuTi5oW7ktinkWU5suk8l4vx9DgZChi63qxUxXz5EPgj/A+IbjIZPJsKLTCtwdfxf/9PxHZ0NH1eBBc8ThkJIheL/8+2r50vysqr9/Sw/vra+Bo6X90Eo5bsiY97R/y2II6Vqrr0u+rRldfzT61uYGYZTJZKhavKoi+J3Xch5qlqgpqL0YX9VNeOlw1C4lrDt/6SKlzfLkYCeZk1oALqfrZtUaKBgxgpi7Fw8XDzQo24D3rq1CsQq4PvY6hocPF7V9Qw8rU71gGUt1ALLKvpV1pmsc2FjxfzGPYggoHKA2v0lgE51jEvCZGGHexm/6aDYqU+1CPKjOIPzb91+LbXvFRysU3Y7lTgw+gVvjbgEAShTSXZK0s9dOVCxWEf/2s1z+jPVR1Y/g6uSK8kXLY3Bd7R42hgLM3b134/uW3+PciHOCL/xBRYPg7OSs1rCwfpn62NB1A26OvQkXJxdcHnUZ50acw5wWup8WvqHrBsS0i9EaqMqaoxR3qNIBw+oNM3psFFMC+HENxuGTGp9gdafVWNBuAXK/ylULDlXPYYa2c6DfAWzoukFnwPx3z7+xrfs23nnru6w3IvfSKeNdBhdHXRTUXuybFt9gcsRkfFLjE8T1jVPrTGCIOdsT6Tu/SIWqaWyUZsv1+EHxeJj5EM2Dmhus8tjbZy9uPr+Jxisb4+W7lybn5fTQ0zj/+DyWJy7HmnNr1OapRumaFwQAiiJFW+Dl6oXXOa8BAGs6r9GaP63JNJTzKYeWwS0NjjYqhL4T9qC6XPuan+K5cTmKuBVBg7LKLrNRraPQdzv/cPjtKrdTdCEvU6QMHmY+VJtvrYc18n2+Yp7FkDk9E27ObsjJz8HZlLPwdvfG4XvCSoi83b3xeRPjhtxXPfY2dduEoKLKEV2rlzA8XL2u8UimNp6KjZc2ihoJ1FhOMics6ShNzx4PFw9s+kTZRkGzRFhMNZhfIT/0COmBkTtH4m3uW635YQFhOu/Ce4Zqj2NjL1ydXc32gENjLWy7UFHFZEsoGLEiU4rPxTxnxc3ZTWs8EUDcc1VUgyEfDx80DWqKBmUbYHjYcCSmJGLMbq4Y97e2v+Hm85v4rNFnANQ/Y3jpcMx8f6bgberLgzlcHn0Ze2/uRb/a/Xi7+ro5u2FAnQFm255m/sv5lEMh10JqD2DUReidy+3xt5GVm4UyUWWQmZ0JwDwlY0Lo+n7k+9bN2Q1nh5/F7Re3teqmLSEvX1lNoxqImMq/sD8eTHwg6ePVpaIacBrz0EnVartrY66h6kKuobCuc6Etj5ZrL/SV4Eg5zggFI2ZSqnApw4lEUD0JGFv0Wq14NZx4cAIAcHHkRUF3h/q4ObuhUWAjNCjTAL6evogIjED5ouVxdcxVRZrpTaZj4t6J6F6zOzZ222jS9sytnE85DA0zvbudUBWLqV+AnWXOuDTqkqDvU1fvHk1uzm5ad5jWumgaNaquBfOmWrJkbo4YiGhSrTYTuj9US6uKFyrOm8bTxRNvc9/i/sT7ortYi1WQn/citNryx1Y/YknCEuztsxdzj84V3chcKtRmxAiqJ+F/+/6L5kHNsfmTzQaXE9PLQfXHbmy0GtstFr1De+PM0DOoWbKm2Ubtc3ZyRs/QnrwPgRrfYDwujLyAP7v8aZZtFUTHBh5D1+pdefeBk8xJ0Im8Sbkm6BnSE7OazxK0TVu+WFprIKW2ldpi66dbcX3Mdatsz9EYGuqfj+q5S23wMJVz6JMpT5AyOcWigcj/evwPY94bo6geLYjCAoR1m57SeApujruJir4VC9RgflQyYqKWFVrqHcVUlbWLwMr5lLN6UCCTyfT2UBG1LhsblEeoxuUao3G5xlrTxXz/TjInrO9q2w35hAZAqsNtW7IxqEwm0xoThJiP6s2H0JLbqMgoDPtnGCZHTNaZxsvNS1Qjd2N8VPUjvc96sWXnRpzDg4wHgnvcqJKyd4xYVDJio8xRTWOK7Lxsq29TU0EuUhXL1JIN+QBMLYOFBcbWVNitMG6OvYm74++a1E2eWJ9q+yPVklWh41EMDRuKh5MeGlWqQji1/GsJfuaZqaQcDp5KRgiv3Pxcybb9T89/cOXpFbVxVwiQl5eHnJwc3nlfNf4KkUGRqBdQD+/evbNKfip5V0KQF9dQ1NA2yxQqIyidrdjy8RZMiZuC6NbRJufZ1dUVzs6WDcKKFyqOp2+eKkZYNpcvm30Jfy9/tK3cFl5uXpjUcBLe5b4TPNAa4Fg3Fbbux1Y/Sp0FnSgYEaFVhVY4lnwMHat2NGp5Y9uMWLM9wLcffIuFpxZiZnPje8GYqn2V9mhfpeAMiCSUsXcdjDGkpqbi5cuXetOVRVmkPUwzahvGaF+iPRq2aAgvVy/cuWN4WO2CpIZrDfzTlnsMgDk+W9GiRVGqVCmL/Zavjr6KC2kXBD8WQigPFw+14dhVB0aUE1r9KGVPDUd2ZMARnH50GhMbTrTptmUUjIiwr88+5OTnGF0PJ2Y0U6naS3zR9AtMbzLdpg9aRyMPREqWLIlChbSHnZdSRVi+y25BxhjDmzdvkJbGBYkBAQEGljCOXyE/q3XpNgdbOobtXdOgpgWilJmCERFkMplJDYLqlKqDiQ0nmvxIdEujE4XtyMvLUwQifn6GxychtsfTk+umnZaWhpIlS1q8ysbahD6RW8r2CMT2UTBiRTKZDFGt+R9+x5eW2LZOVTvhf9f+p3PkTnOQtxEpVMh2RrIl4sm/v5ycHLsLRjpX64w+tfqgQRnLjfNCrIMGPSNa6C7C9v3Z5U/su7UPbSq1sfi2KDgt2Oz5+3N2csbaj9caTGfP+4CYjrr22ijVLpC6Ri4k0irsVhhdqncR/PwdasBHHBndYNme7d23m330cGNRMGKjnGROiB8UjwP9Dkj6WHFiHVX8qkidBUIsSrW9nbuz9rOhiPV1rtYZjyY9Uns6s1SomsaGiXk4HrFdPUN6YsPFDfiiyRda884MPYNf/vsF37X8ToKcWdaAAQPw8uVL/PXXX1JnhdgAHw8f/Pzhz8hn+SjmWUzq7JD/p/boERr0jBD7tfbjtZj1/ixU9tV+bHdY6TCbH/adEHOZ3Ej3sPBEOrbw6A2qpiHEwpydnFHFrwo14FNx+PBh1K9fH+7u7ggICMC0adOQm6sc9XfLli0IDQ2Fp6cn/Pz80KpVK7x+/RoAcOjQIdSvXx9eXl4oWrQoGjdujHv37kn1UQghZkAlI4QUMIwxvMl5Y/XtFnI1z4BrDx8+RLt27TBgwACsWbMGV69exdChQ+Hh4YFZs2YhJSUFPXv2xI8//oiPP/4YmZmZOHr0KBhjyM3NRefOnTF06FBs2LAB2dnZOHXqFAV6hBRwFIwQUsC8yXmDwvOEj+ZrLq+mvzLL01VjYmIQGBiIhQsXQiaToVq1anj06BE+//xzfP3110hJSUFubi66dOmCoCDu2TehoaEAgOfPnyM9PR0dOnRAxYrc6K/Vq1c3OU+EEGl7/FE1DSHEqq5cuYKIiAi10ozGjRvj1atXePDgAWrXro2WLVsiNDQUn3zyCZYtW4YXL14AAHx9fTFgwAC0bt0aHTt2xPz585GSkiLVRyHELthCyaJRJSMxMTH46aefkJKSgpo1ayI6OhpNm/KPfb9t2zYsXrwYSUlJyMrKQs2aNTFr1iy0bt3apIwT4qgKuRbCq+mvJNmuOTDGtE5+8lb8MpkMzs7OiIuLQ3x8PPbt24cFCxZgxowZOHnyJIKDg7Fq1SqMGzcOe/bsQWxsLL788kvExcWhYcOGZskfIcT6RJeMxMbGYsKECZgxYwYSExPRtGlTtG3bFsnJybzpjxw5gg8//BC7du1CQkICWrRogY4dOyIxMdHkzBPiiGQyGbzcvKz+MtfdU40aNRAfH6/WjTA+Ph5FihRBmTJlFJ+xcePGmD17NhITE+Hm5obt27cr0tetWxfTp09HfHw8QkJCsH499UgipCATXTISFRWFwYMHY8iQIQCA6Oho7N27F4sXL8a8efO00kdHR6u9/+677/C///0Pf//9N+rWrWtcrgkhBUJ6ejqSkpLUpg0bNgzR0dEYO3YsxowZg2vXrmHmzJmYNGkSnJyccPLkSezfvx+RkZEoWbIkTp48iSdPnqB69eq4c+cOli5dio8++gilS5fGtWvXcP36dfTr10+aD0gIMQtRwUh2djYSEhIwbdo0temRkZGIj48XtI78/HxkZmbC11f3qKJZWVnIyspSvM/IyBCTTUKIjTh06JDWTUf//v2xa9cuTJkyBbVr14avry8GDx6ML7/8EgDg7e2NI0eOIDo6GhkZGQgKCsIvv/yCtm3b4vHjx7h69Sr++OMPPHv2DAEBARgzZgyGDx8uxccjxK4UmEHPnj59iry8PPj7+6tN9/f3R2pqqqB1/PLLL3j9+jU+/fRTnWnmzZuH2bNni8kaIcTGrF69GqtXr9Y5/9SpU7zTq1evjj179vDO8/f3V6uuIYSYrsAOesbX+ExIffKGDRswa9YsxMbGomTJkjrTTZ8+Henp6YrX/fv3jckmIYQQQgoAUSUjxYsXh7Ozs1YpSFpamlZpiabY2FgMHjwYmzdvRqtWrfSmdXd3h7s7PUiJEEIIcQSiSkbc3NwQFhaGuLg4telxcXFo1Ej3U/82bNiAAQMGYP369Wjfvr1xOSWEEEKIxUg56Jno3jSTJk1C3759ER4ejoiICCxduhTJyckYMWIEAK6K5eHDh1izZg0ALhDp168f5s+fj4YNGypKVTw9PeHj42PGj0IIIYQQsQrkoGfdu3fHs2fPMGfOHKSkpCAkJAS7du1SDNuckpKiNubIkiVLkJubi9GjR2P06NGK6f3799fbuI0QQgghjsGoEVhHjRqFUaNG8c7TDDAOHTpkzCYIIYQQ4iDo2TSEEEIIkXScEQpGCCGEEAdWYMcZIYQQQggxFwpGCCGEECIpCkYIIRYVHx8PZ2dntGnTRuqsEEL0kHKcEQpGCCEWtXLlSowdOxbHjh1T6/ZvbTk5OZJtmxBbZgvjjFAwQgixmNevX2PTpk0YOXIkOnTooNX1f8eOHQgPD4eHhweKFy+OLl26KOZlZWVh6tSpCAwMhLu7OypXrowVK1YA4IYQKFq0qNq6/vrrL7WT6qxZs1CnTh2sXLkSFSpUgLu7Oxhj2LNnD5o0aYKiRYvCz88PHTp0wK1bt9TW9eDBA/To0QO+vr7w8vJCeHg4Tp48ibt378LJyQlnzpxRS79gwQIEBQVJ2huBkILMqHFGCCHSYQx488b62y1UCBB7AxUbG4uqVauiatWq6NOnD8aOHYuvvvoKMpkMO3fuRJcuXTBjxgysXbsW2dnZ2Llzp2LZfv364b///sNvv/2G2rVr486dO3j69Kmo7d+8eRObNm3C1q1b4ezsDIALkCZNmoTQ0FC8fv0aX3/9NT7++GMkJSXByckJr169QvPmzVGmTBns2LEDpUqVwtmzZ5Gfn4/y5cujVatWWLVqFcLDwxXbWbVqFQYMGGATd5iEFEQUjBBSwLx5AxQubP3tvnoFeHmJW2bFihXo06cPAKBNmzZ49eoV9u/fj1atWuHbb79Fjx49MHv2bEX62rVrAwCuX7+OTZs2IS4uTvFgzQoVKojOc3Z2NtauXYsSJUoopnXt2lUrjyVLlsTly5cREhKC9evX48mTJzh9+jR8fX0BAJUqVVKkHzJkCEaMGIGoqCi4u7vj3LlzSEpKwrZt20TnjxDCoWoaQohFXLt2DadOnUKPHj0AAC4uLujevTtWrlwJAEhKSkLLli15l01KSoKzszOaN29uUh6CgoLUAhEAuHXrFnr16oUKFSrA29sbwcHBAKBoz5KUlIS6desqAhFNnTt3houLC7Zv3w6AaxPTokULlC9f3qS8EiI1KasZqWSEkAKmUCGulEKK7YqxYsUK5ObmokyZMoppjDG4urrixYsX8PT01LmsvnkA4OTkpHXi5Gug6sVTlNOxY0cEBgZi2bJlKF26NPLz8xESEoLs7GxB23Zzc0Pfvn2xatUqdOnSBevXr0d0dLTeZQixZbYw6BkFI4QUMDKZ+OoSa8vNzcWaNWvwyy+/IDIyUm1e165dsW7dOtSqVQv79+/HwIEDtZYPDQ1Ffn4+Dh8+rKimUVWiRAlkZmbi9evXioAjKSnJYL6ePXuGK1euYMmSJWjatCkA4NixY2ppatWqheXLl+P58+c6S0eGDBmCkJAQxMTEICcnR63hLSFEPApGCCFm988//+DFixcYPHgwfHx81OZ169YNK1aswK+//oqWLVuiYsWK6NGjB3Jzc7F7925MnToV5cuXR//+/TFo0CBFA9Z79+4hLS0Nn376KRo0aIBChQrhiy++wNixY3Hq1ClBTwEvVqwY/Pz8sHTpUgQEBCA5ORnTpk1TS9OzZ09899136Ny5M+bNm4eAgAAkJiaidOnSiIiIAABUr14dDRs2xOeff45BgwYZLE0hhOhHbUYIIWa3YsUKtGrVSisQAbiSkaSkJHh7e2Pz5s3YsWMH6tSpgw8++AAnT55UpFu8eDG6deuGUaNGoVq1ahg6dChev34NAPD19cWff/6JXbt2ITQ0FBs2bMCsWbMM5svJyQkbN25EQkICQkJCMHHiRPz0009qadzc3LBv3z6ULFkS7dq1Q2hoKL7//ntFbxy5wYMHIzs7G4MGDTJiDxFiO4bWG4rvW36PWv61JMuDjBWAjvEZGRnw8fFBeno6vL29pc4OIVbz7t073LlzB8HBwfDw8JA6O0TFt99+i40bN+LChQsG09L3SByV0Os3lYwQQogIr169wunTp7FgwQKMGzdO6uwQYhcoGCGEEBHGjBmDJk2aoHnz5lRFQ4iZUANWQggRYfXq1YIayxJChKOSEUIIIYRIioIRQgghhEiKghFCCoD8/Hyps0BMQN8fIfpRmxFCbJibmxucnJzw6NEjlChRAm5ubvRk2AKEMYbs7Gw8efIETk5OcHNzkzpLhNgkCkYIsWFOTk4IDg5GSkoKHj16JHV2iJEKFSqEcuXKwcmJCqMJ4UPBCCE2zs3NDeXKlUNubi7y8vKkzg4RydnZGS4uLlSiRYgeFIwQUgDIZDK4urrC1dVV6qwQQojZUZkhIYQQQiRFwQghhBBCJEXBCCGEEEIkVSDajMgfLJyRkSFxTgghhBAilPy6Lb+O61IggpHMzEwAQGBgoMQ5IYQQQohYmZmZ8PHx0TlfxgyFKzYgPz8fjx49QpEiRczaPS4jIwOBgYG4f/8+vL29zbZeR0H7zzS0/0xD+880tP9MQ/tPGMYYMjMzUbp0ab3j7BSIkhEnJyeULVvWYuv39vamg8kEtP9MQ/vPNLT/TEP7zzS0/wzTVyIiRw1YCSGEECIpCkYIIYQQIimHDkbc3d0xc+ZMuLu7S52VAon2n2lo/5mG9p9paP+ZhvafeRWIBqyEEEIIsV8OXTJCCCGEEOlRMEIIIYQQSVEwQgghhBBJUTBCCCGEEElRMEIIIYQQSTl0MBITE4Pg4GB4eHggLCwMR48elTpLVnfkyBF07NgRpUuXhkwmw19//aU2nzGGWbNmoXTp0vD09MT777+PS5cuqaXJysrC2LFjUbx4cXh5eeGjjz7CgwcP1NK8ePECffv2hY+PD3x8fNC3b1+8fPnSwp/OsubNm4f33nsPRYoUQcmSJdG5c2dcu3ZNLQ3tP90WL16MWrVqKUawjIiIwO7duxXzad+JM2/ePMhkMkyYMEExjfahbrNmzYJMJlN7lSpVSjGf9p2VMQe1ceNG5urqypYtW8YuX77Mxo8fz7y8vNi9e/ekzppV7dq1i82YMYNt3bqVAWDbt29Xm//999+zIkWKsK1bt7ILFy6w7t27s4CAAJaRkaFIM2LECFamTBkWFxfHzp49y1q0aMFq167NcnNzFWnatGnDQkJCWHx8PIuPj2chISGsQ4cO1vqYFtG6dWu2atUqdvHiRZaUlMTat2/PypUrx169eqVIQ/tPtx07drCdO3eya9eusWvXrrEvvviCubq6sosXLzLGaN+JcerUKVa+fHlWq1YtNn78eMV02oe6zZw5k9WsWZOlpKQoXmlpaYr5tO+sy2GDkfr167MRI0aoTatWrRqbNm2aRDmSnmYwkp+fz0qVKsW+//57xbR3794xHx8f9vvvvzPGGHv58iVzdXVlGzduVKR5+PAhc3JyYnv27GGMMXb58mUGgJ04cUKR5r///mMA2NWrVy38qawnLS2NAWCHDx9mjNH+M0axYsXY8uXLad+JkJmZySpXrszi4uJY8+bNFcEI7UP9Zs6cyWrXrs07j/ad9TlkNU12djYSEhIQGRmpNj0yMhLx8fES5cr23LlzB6mpqWr7yd3dHc2bN1fsp4SEBOTk5KilKV26NEJCQhRp/vvvP/j4+KBBgwaKNA0bNoSPj49d7e/09HQAgK+vLwDaf2Lk5eVh48aNeP36NSIiImjfiTB69Gi0b98erVq1UptO+9CwGzduoHTp0ggODkaPHj1w+/ZtALTvpFAgntprbk+fPkVeXh78/f3Vpvv7+yM1NVWiXNke+b7g20/37t1TpHFzc0OxYsW00siXT01NRcmSJbXWX7JkSbvZ34wxTJo0CU2aNEFISAgA2n9CXLhwAREREXj37h0KFy6M7du3o0aNGooTNe07/TZu3IizZ8/i9OnTWvPo+NOvQYMGWLNmDapUqYLHjx9j7ty5aNSoES5dukT7TgIOGYzIyWQytfeMMa1pxLj9pJmGL7097e8xY8bg/PnzOHbsmNY82n+6Va1aFUlJSXj58iW2bt2K/v374/Dhw4r5tO90u3//PsaPH499+/bBw8NDZzrah/zatm2r+D80NBQRERGoWLEi/vjjDzRs2BAA7TtrcshqmuLFi8PZ2VkrMk1LS9OKhB2ZvGW5vv1UqlQpZGdn48WLF3rTPH78WGv9T548sYv9PXbsWOzYsQMHDx5E2bJlFdNp/xnm5uaGSpUqITw8HPPmzUPt2rUxf/582ncCJCQkIC0tDWFhYXBxcYGLiwsOHz6M3377DS4uLorPR/tQGC8vL4SGhuLGjRt0/EnAIYMRNzc3hIWFIS4uTm16XFwcGjVqJFGubE9wcDBKlSqltp+ys7Nx+PBhxX4KCwuDq6urWpqUlBRcvHhRkSYiIgLp6ek4deqUIs3JkyeRnp5eoPc3YwxjxozBtm3bcODAAQQHB6vNp/0nHmMMWVlZtO8EaNmyJS5cuICkpCTFKzw8HL1790ZSUhIqVKhA+1CErKwsXLlyBQEBAXT8ScHKDWZthrxr74oVK9jly5fZhAkTmJeXF7t7967UWbOqzMxMlpiYyBITExkAFhUVxRITExVdnL///nvm4+PDtm3bxi5cuMB69uzJ272tbNmy7N9//2Vnz55lH3zwAW/3tlq1arH//vuP/ffffyw0NLTAd28bOXIk8/HxYYcOHVLrHvjmzRtFGtp/uk2fPp0dOXKE3blzh50/f5598cUXzMnJie3bt48xRvvOGKq9aRijfajP5MmT2aFDh9jt27fZiRMnWIcOHViRIkUU1wDad9blsMEIY4wtWrSIBQUFMTc3N1avXj1Fl0xHcvDgQQZA69W/f3/GGNfFbebMmaxUqVLM3d2dNWvWjF24cEFtHW/fvmVjxoxhvr6+zNPTk3Xo0IElJyerpXn27Bnr3bs3K1KkCCtSpAjr3bs3e/HihZU+pWXw7TcAbNWqVYo0tP90GzRokOL3V6JECdayZUtFIMIY7TtjaAYjtA91k48b4urqykqXLs26dOnCLl26pJhP+866ZIwxJk2ZDCGEEEKIg7YZIYQQQojtoGCEEEIIIZKiYIQQQgghkqJghBBCCCGSomCEEEIIIZKiYIQQQgghkqJghBBCCCGSomCEECLKjRs38PPPPyM/P1/qrBBC7AQFI4QQwfLz89GvXz+UKVMGTk50+iCEmAeNwEoIEezGjRs4evQoBg0aJHVWCCF2hIIRQgghhEiKylkJIQYNGDAAMplM69WmTRups0YIsQMuUmeAEFIwtGnTBqtWrVKb5u7uLlFuCCH2hEpGCCGCuLu7o1SpUmqvYsWKAQBkMhkWL16Mtm3bwtPTE8HBwdi8ebPa8hcuXMAHH3wAT09P+Pn5YdiwYXj16pVampUrV6JmzZpwd3dHQEAAxowZo5gXFRWF0NBQeHl5ITAwEKNGjVJb/t69e+jYsSOKFSsGLy8v1KxZE7t27bLgHiGEmAsFI4QQs/jqq6/QtWtXnDt3Dn369EHPnj1x5coVAMCbN2/Qpk0bFCtWDKdPn8bmzZvx77//qgUbixcvxujRozFs2DBcuHABO3bsQKVKlRTznZyc8Ntvv+HixYv4448/cODAAUydOlUxf/To0cjKysKRI0dw4cIF/PDDDyhcuLD1dgAhxHiMEEIM6N+/P3N2dmZeXl5qrzlz5jDGGAPARowYobZMgwYN2MiRIxljjC1dupQVK1aMvXr1SjF/586dzMnJiaWmpjLGGCtdujSbMWOG4Dxt2rSJ+fn5Kd6HhoayWbNmGf0ZCSHSoTYjhBBBWrRogcWLF6tN8/X1VfwfERGhNi8iIgJJSUkAgCtXrqB27drw8vJSzG/cuDHy8/Nx7do1yGQyPHr0CC1bttS5/YMHD+K7777D5cuXkZGRgdzcXLx79w6vX7+Gl5cXxo0bh5EjR2Lfvn1o1aoVunbtilq1apnhkxNCLI2qaQghgnh5eaFSpUpqL9VghI9MJgMAMMYU//Ol8fT01Luee/fuoV27dggJCcHWrVuRkJCARYsWAQBycnIAAEOGDMHt27fRt29fXLhwAeHh4ViwYIHYj0kIkQAFI4QQszhx4oTW+2rVqgEAatSogaSkJLx+/Vox//jx43ByckKVKlVQpEgRlC9fHvv37+dd95kzZ5Cbm4tffvkFDRs2RJUqVfDo0SOtdIGBgRgxYgS2bduGyZMnY9myZWb8hIQQS6FqGkKIIFlZWUhNTVWb5uLiguLFiwMANm/ejPDwcDRp0gTr1q3DqVOnsGLFCgBA7969MXPmTPTv3x+zZs3CkydPMHbsWPTt2xf+/v4AgFmzZmHEiBEoWbIk2rZti8zMTBw/fhxjx45FxYoVkZubiwULFqBjx444fvw4fv/9d7W8TJgwAW3btkWVKlXw4sULHDhwANWrV7fCniGEmEzqRiuEENvXv39/BkDrVbVqVcYY14B10aJF7MMPP2Tu7u4sKCiIbdiwQW0d58+fZy1atGAeHh7M19eXDR06lGVmZqql+f3331nVqlWZq6srCwgIYGPHjlXMi4qKYgEBAczT05O1bt2arVmzhgFgL168YIwxNmbMGFaxYkXm7u7OSpQowfr27cuePn1q2R1DCDELGg6eEGIymUyG7du3o3PnzlJnhRBSAFGbEUIIIYRIioIRQgghhEiKGrASQkxGtb2EEFNQyQghhBBCJEXBCCGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIkRcEIIYQQQiRFwQghhBBCJEXBCCGEEEIk9X+wUSfwsBHCpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean loss\n",
    "x_axis = [i for i in range(5643)]\n",
    "\n",
    "splits=50\n",
    "plt.plot(x_axis, [sum(mean_losses[i:i + splits])/splits for i in range(0, len(mean_losses), splits)], 'g', label='Loss')\n",
    "plt.plot(x_axis, [sum(mean_acc[i:i + splits])/splits for i in range(0, len(mean_acc), splits)], 'b', label='Accuracy')\n",
    "# plt.plot(x_axis, [sum(mean_f1s[i:i + splits])/splits for i in range(0, len(mean_f1s), splits)], 'r', label='F1-score')\n",
    "plt.title('Training metrics')\n",
    "plt.xlabel('Épocas')\n",
    "# plt.ylabel('Loss media')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
