{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1216511f",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "### - Fuzzy Loss Function\n",
    "\n",
    "### - Training a Net with FuzzyLoss (ft. pytorch_lightning)\n",
    "\n",
    "#### a1) ResNet50\n",
    "\n",
    "#### a2) ResNeXt50_32x4d\n",
    "\n",
    "#### b) VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ddd4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset, ConcatDataset\n",
    "import torchmetrics\n",
    "\n",
    "from fuzzylogic.classes import Domain, Set, Rule\n",
    "from fuzzylogic.hedges import very\n",
    "from fuzzylogic.functions import R, S, alpha, triangular\n",
    "\n",
    "from System import FICAR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# from ray import tune\n",
    "# from ray.tune.integration.pytorch_lightning import TuneReportCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eabf350",
   "metadata": {},
   "source": [
    "# Fuzzy Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f60cf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from FuzzyLoss import FuzzyLoss\n",
    "\n",
    "class FL_FCS():\n",
    "    \"\"\" Fuzzy Control System for Focal Loss \"\"\"\n",
    "    def __init__(self):\n",
    "        # Definir dominios de inputs y output\n",
    "        self.balance_deg = Domain(\"balance_deg\", 0, 1, res=0.1)\n",
    "        self.balance_deg.low = S(0.2, 0.8)\n",
    "        self.balance_deg.high = R(0.2,0.8)\n",
    "\n",
    "        self.loss_tminus = Domain(\"loss_tminus\", 0, 2, res=0.01)\n",
    "        self.loss_tminus.low = S(0.25, 1.75)\n",
    "        self.loss_tminus.med = triangular(0.25, 1.75, c=1.0)\n",
    "        self.loss_tminus.high = R(0.25,1.85)\n",
    "\n",
    "        self.delta_gamma = Domain(\"Delta_gamma\", -0.2, 0.2, res=0.01)\n",
    "        self.delta_gamma.ne = S(-0.2, -0.0)\n",
    "        self.delta_gamma.ze = triangular(-0.2, 0.2, c=-0.0)\n",
    "        self.delta_gamma.po = R(0.0, 0.2)\n",
    "\n",
    "        # Reglas\n",
    "        R1 = Rule({(self.balance_deg.low, self.loss_tminus.low): self.delta_gamma.ne})\n",
    "        R2 = Rule({(self.balance_deg.low, self.loss_tminus.med): self.delta_gamma.ne})\n",
    "        R3 = Rule({(self.balance_deg.low, self.loss_tminus.high): self.delta_gamma.ze})\n",
    "        R4 = Rule({(self.balance_deg.high, self.loss_tminus.low): self.delta_gamma.ze})\n",
    "        R5 = Rule({(self.balance_deg.high, self.loss_tminus.med): self.delta_gamma.po})\n",
    "        R6 = Rule({(self.balance_deg.high, self.loss_tminus.high): self.delta_gamma.po})\n",
    "        self.rules = R1 | R2 | R3 | R4 | R5 | R6\n",
    "    \n",
    "    def evaluate(self, bd, lt):\n",
    "        \"\"\" return how much to change current gamma in terms of:\n",
    "            - current class' balance degree\n",
    "            - current focal loss for current class, obtained during step\n",
    "        \"\"\"\n",
    "        values = {self.balance_deg: bd, self.loss_tminus: lt}\n",
    "        delta_gamma = self.rules(values)\n",
    "        return delta_gamma\n",
    "\n",
    "    \n",
    "class FuzzyLoss(torch.nn.CrossEntropyLoss):\n",
    "    \"\"\" Fuzzy-Adaptive Focal Loss\n",
    "    \n",
    "    gamma in [0, +inf)\n",
    "    alpha in [0, 1]\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=0, class_sizes=[1,1], alpha=None):\n",
    "        super(FuzzyLoss, self).__init__()\n",
    "        \n",
    "        self.class_sizes = np.array(class_sizes)\n",
    "        self.n_classes = len(self.class_sizes)\n",
    "        # balance degree of each class (size_i / max(size_j))\n",
    "        self.balance_deg = dict((i, class_sizes[i]/max(class_sizes)) for i in range(len(class_sizes)))\n",
    "        \n",
    "        # initially all classes with same gamma\n",
    "        self.gamma = dict((i, gamma) for i in range(self.n_classes))\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        \n",
    "        self.FCS = FL_FCS()\n",
    "\n",
    "    def forward(self, input_, target):\n",
    "        if input_.dim()>2:\n",
    "            input_ = input_.view(input_.size(0),input_.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input_ = input_.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input_ = input_.contiguous().view(-1,input_.size(2))   # N,H*W,C => N*H*W,C\n",
    "        ground_truth = target\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input_, dim=1)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = logpt.data.exp()\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input_.data.type():\n",
    "                self.alpha = self.alpha.type_as(input_.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "        \n",
    "        loss = torch.Tensor([0.0]*len(pt))\n",
    "        for i, (pt_, logpt_) in enumerate(zip(pt, logpt)):\n",
    "            curr_class = ground_truth[i].item()\n",
    "            # la loss de cada instancia del batch evaluada con su gamma respectiva\n",
    "            loss[i] = -1 * (1-pt_)**self.gamma[curr_class] * logpt_\n",
    "        \n",
    "        # tanto la media como el loss para cada _Instancia_\n",
    "        return loss.mean(), loss\n",
    "        \n",
    "    def update_hyperparams(self, current_losses, targets, alpha=None):\n",
    "        \"\"\" update each class' gamma based on:\n",
    "            - that class's balance degree\n",
    "            - that class's loss in current step\n",
    "        \"\"\"\n",
    "        if alpha is not None:\n",
    "            self.alpha = alpha\n",
    "        if len(current_losses) != len(targets):\n",
    "            raise ValueError('current loss must be same length as targets!')\n",
    "        \n",
    "        # obtener loss media para cada clase\n",
    "        class_loss = {}\n",
    "        targets = targets.cpu().numpy()\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] not in class_loss:\n",
    "                class_loss[targets[i]] = np.array([current_losses[i].item()])\n",
    "            else:\n",
    "                class_loss[targets[i]] = np.append(class_loss[targets[i]], current_losses[i].item())\n",
    "        for k in class_loss.keys():\n",
    "            class_loss[k] = class_loss[k].mean()\n",
    "        \n",
    "        for i in range(self.n_classes):\n",
    "            try:\n",
    "                delta_gamma = self.FCS.evaluate(self.balance_deg[i], class_loss[i])\n",
    "            except:\n",
    "                delta_gamma = 0\n",
    "            self.gamma[i] += delta_gamma\n",
    "            self.gamma[i] = max(self.gamma[i], 0) # enforce gamma >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c20691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF-CELoss :  1.0661571\n",
      "FuzzyLoss':  1.0661571\n",
      "FuzzyLoss\":  1.0661571\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.tensor([0,  1], dtype=torch.int64)\n",
    "y_pred = torch.tensor([[.7 , 0 , 0 ,0 ,  .3], [0, 0.9, 0, 0.1, 0]])\n",
    "\n",
    "print('DF-CELoss : ', torch.nn.CrossEntropyLoss()(y_pred, y_true).numpy())\n",
    "\n",
    "fuzzyloss = FuzzyLoss(gamma=0., class_sizes=[500,5000])\n",
    "loss, losses = fuzzyloss(y_pred, y_true)\n",
    "print('FuzzyLoss\\': ', loss.numpy())\n",
    "fuzzyloss.update_hyperparams(losses, y_true)\n",
    "print('FuzzyLoss\": ', loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a154ade",
   "metadata": {},
   "source": [
    "# Training a Net with FuzzyLoss (ft. `pytorch_lightning`)\n",
    "\n",
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51825087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from System import get_dataloaders_from_path, plot_images_sample\n",
    "\n",
    "dataloaders, dataset_sizes, class_names = get_dataloaders_from_path('../data/PlantVillage/')\n",
    "plot_images_sample(dataloaders['train'])\n",
    "print('NTrain:', len(dataloaders['train'])*32, '// NVal:', len(dataloaders['val'])*32) # 32-img batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e1d2a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "EPOCHS = 200\n",
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "class ResNetCustom(pl.LightningModule):\n",
    "    def __init__(self, gamma=0., class_sizes=[1,1]):\n",
    "        super().__init__()\n",
    "        self.n_classes = len(class_sizes)\n",
    "        \n",
    "        # metrics\n",
    "        task = \"multiclass\" if self.n_classes > 2 else \"binary\"\n",
    "        self.accuracy = torchmetrics.Accuracy(task=task, num_classes=self.n_classes)\n",
    "        self.f1score = torchmetrics.F1Score(task=task, num_classes=self.n_classes)\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.n_classes, bias=True)\n",
    "            \n",
    "        self.fuzzyloss = FuzzyLoss(gamma=gamma, class_sizes=class_sizes).cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        y_onehot = F.one_hot(y, num_classes=self.n_classes).long()\n",
    "        acc = self.accuracy(logits, y_onehot)\n",
    "        f1s = self.f1score(logits, y_onehot)\n",
    "        mean_acc.append(acc.item())\n",
    "        mean_f1s.append(f1s.item())\n",
    "        \n",
    "        mean_loss, losses = self.fuzzyloss(logits, y)\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "        # Update focal loss with Fuzzy Control System\n",
    "#         self.fuzzyloss.update_hyperparams(losses, y)\n",
    "        return mean_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "#         return torch.optim.RMSprop(self.parameters(), lr=0.005)\n",
    "#         return torch.optim.SGD(self.model[0].fc.parameters(), lr=0.001, momentum=0.9)\n",
    "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=1e-4)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
    "                                optimizer ,max_lr=0.01,\n",
    "                                steps_per_epoch=len(dataloaders['train']),\n",
    "                                epochs=EPOCHS)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2e3c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ResNetCustom(gamma=0., class_sizes=[1591,373])\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=EPOCHS, devices=1, accelerator=\"gpu\")\n",
    "trainer.fit(model, dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e564303e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean loss\n",
    "x_axis = [i for i in range(200)]\n",
    "\n",
    "splits=49\n",
    "plt.plot(x_axis, [sum(mean_losses[i:i + splits])/splits for i in range(0, len(mean_losses), splits)], 'g', label='Loss')\n",
    "# plt.plot(x_axis, [sum(mean_acc[i:i + splits])/splits for i in range(0, len(mean_acc), splits)], 'b', label='n')\n",
    "plt.plot(x_axis, [sum(mean_f1s[i:i + splits])/splits for i in range(0, len(mean_f1s), splits)], 'r', label='F1-score')\n",
    "plt.title('Training metrics')\n",
    "plt.xlabel('Épocas')\n",
    "# plt.ylabel('Loss media')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "70b9c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"saves/resnet50_PlantVillage_focalloss_transfer.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e46d4c",
   "metadata": {},
   "source": [
    "Now we can reload it w/o training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6ab7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(x, model: pl.LightningModule):\n",
    "    model.freeze() # prepares model for predicting\n",
    "    probabilities = torch.softmax(model(x), dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "inference_model = ResNetCustom.load_from_checkpoint(\"saves/resnet50_PlantVillage_focalloss_transfer.pt\", map_location=\"cuda\", gamma=0., class_sizes=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c153411b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37311891ab5640a297cf9b62fe879154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "true_y, pred_y = [], []\n",
    "for batch in tqdm(iter(dataloaders['val']), total=len(dataloaders['val'])):\n",
    "    x, y = batch\n",
    "    true_y.extend(y)\n",
    "    preds, probs = get_prediction(x, inference_model)\n",
    "    pred_y.extend(preds.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "51ce571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.972     0.975       326\n",
      "           1      0.892     0.914     0.902        81\n",
      "\n",
      "    accuracy                          0.961       407\n",
      "   macro avg      0.935     0.943     0.939       407\n",
      "weighted avg      0.961     0.961     0.961       407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(true_y, pred_y, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12164889",
   "metadata": {},
   "source": [
    "## ResNet50 + transfer learning + 5-Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda0a22",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Plant Village</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 1591 / Class 1: 373 / BDeg:  4.265415549597855\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_dataset = datasets.ImageFolder('../data/PlantVillage/train',data_transforms)\n",
    "\n",
    "# Provocar bias cogiendo un porcentaje de la clase 1 solamente (modificando el porcentaje hasta obtener b_deg deseado)\n",
    "class_0_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==0).flatten()\n",
    "class_1_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==1).flatten()\n",
    "# class_1_idxs = class_1_idxs[torch.randperm(len(class_1_idxs))[:int(len(class_1_idxs)*.209)]]\n",
    "\n",
    "c0_s, c1_s = len(class_0_idxs), len(class_1_idxs)\n",
    "b_deg = c0_s / c1_s\n",
    "print('Class 0:', len(class_0_idxs), '/ Class 1:', len(class_1_idxs), '/ BDeg: ', b_deg)\n",
    "\n",
    "class_1_subset = Subset(image_dataset, class_1_idxs)\n",
    "class_0_subset = Subset(image_dataset, class_0_idxs)\n",
    "image_dataset = ConcatDataset([class_0_subset, class_1_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aefa2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "class ResNetCustom(pl.LightningModule):\n",
    "    def __init__(self, config, class_sizes):\n",
    "        super().__init__()\n",
    "        self.gamma = config['gamma']\n",
    "        self.class_sizes = class_sizes\n",
    "        self.lr = config['lr']\n",
    "        self.n_classes = len(self.class_sizes)\n",
    "        \n",
    "        # metrics\n",
    "        task = \"multiclass\" if self.n_classes > 2 else \"binary\"\n",
    "        self.accuracy = torchmetrics.Accuracy(task=task, num_classes=self.n_classes)\n",
    "        self.f1score = torchmetrics.F1Score(task=task, num_classes=self.n_classes)\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.n_classes, bias=True)\n",
    "            \n",
    "        self.fuzzyloss = FuzzyLoss(gamma=self.gamma, class_sizes=self.class_sizes).cuda()\n",
    "#         self.fuzzyloss = nn.CrossEntropyLoss().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        y_onehot = F.one_hot(y, num_classes=self.n_classes).long()\n",
    "        acc = self.accuracy(logits, y_onehot)\n",
    "        f1s = self.f1score(logits, y_onehot)\n",
    "        mean_acc.append(acc.item())\n",
    "        mean_f1s.append(f1s.item())\n",
    "        \n",
    "        mean_loss, losses = self.fuzzyloss(logits, y)\n",
    "#         mean_loss = self.fuzzyloss(logits, y)\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "        # Update focal loss with Fuzzy Control System\n",
    "        self.fuzzyloss.update_hyperparams(losses, y)\n",
    "        return mean_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=self.lr)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
    "                                optimizer ,max_lr=0.01,\n",
    "                                steps_per_epoch=self.SPE,\n",
    "                                epochs=self.EPOCHS)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2762076c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.89it/s, loss=0.0592, v_num=172]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0592, v_num=172]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:41,  1.07s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.10s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.284, v_num=173] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.284, v_num=173]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.10s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.09s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.09s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.09s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.08s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:24,  1.07s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:23,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:22,  1.08s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:21<00:21,  1.09s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.0312, v_num=174]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0312, v_num=174]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.18s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:34,  1.22s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:33,  1.25s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:32,  1.25s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:31,  1.25s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:30,  1.27s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.22s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:25,  1.17s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.10s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.87it/s, loss=0.0432, v_num=175]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0432, v_num=175]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.12s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:37,  1.08s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.13s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.16s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.15s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.12s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0369, v_num=176]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0369, v_num=176]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:39,  1.01s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:51,  1.40s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:46,  1.30s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.24s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:40,  1.18s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.10s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.09s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.08s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:27,  1.10s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:25,  1.08s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.09s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:22,  1.08s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.13s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.09s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.08s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.10s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.281, v_num=177] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.281, v_num=177]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:41,  1.07s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.10s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.09s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.10s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.11s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:23,  1.15s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:22,  1.17s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:21,  1.17s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.09s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.08s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.09s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:12,  1.07s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:11,  1.08s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.09s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.12s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.88it/s, loss=0.0784, v_num=178]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0784, v_num=178]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.16s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.09s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.07s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.07s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:10<00:32,  1.08s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.10s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.09s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:22,  1.09s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:21<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:31<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.07s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.08s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.08s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.08s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.09s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:42<00:01,  1.08s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0579, v_num=179]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0579, v_num=179]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.15s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.11s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.10s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.09s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.09s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.09s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.09s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.09s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.0407, v_num=180]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0407, v_num=180]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.08s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.09s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.09s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.18s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.16s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.13s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.13s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.108, v_num=181] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.108, v_num=181]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.15s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.16s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.16s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0637, v_num=182]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0637, v_num=182]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.09s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:36,  1.08s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.08s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.07s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.07s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:10<00:32,  1.09s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.11s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.11s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.10s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.09s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.08s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.10s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.10s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.0735, v_num=183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0735, v_num=183]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:39,  1.08s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.09s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.10s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.18s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:30,  1.18s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:29,  1.17s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.10s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.10s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.09s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.23, v_num=184]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.23, v_num=184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.09s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.08s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:32,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.09s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.09s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.10s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.10s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:23,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.08s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.09s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.10s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:31<00:11,  1.09s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.09s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.09s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:42<00:01,  1.09s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.87it/s, loss=0.071, v_num=185] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.071, v_num=185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:32,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:31,  1.10s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.08s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.09s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.09s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:22,  1.09s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.09s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.08s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.10s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0528, v_num=186]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0528, v_num=186]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.08s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.08s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.09s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.09s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:21,  1.09s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.09s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.09s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.09s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.12s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.09s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0479, v_num=187]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0479, v_num=187]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.19s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.18s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.16s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.15s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.13s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.13s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.11s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.10s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.15s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.16s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0436, v_num=188]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0436, v_num=188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.11s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0496, v_num=189]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0496, v_num=189]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.14s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:54<00:00,  2.87it/s, loss=0.0372, v_num=190]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0372, v_num=190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:39,  1.01s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:39,  1.03s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:39,  1.08s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.09s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.09s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.08s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.08s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.07s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:10<00:32,  1.08s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:11<00:31,  1.08s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:12<00:30,  1.10s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.09s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:21<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.09s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.09s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:31<00:11,  1.08s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:32<00:10,  1.09s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.08s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.08s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.07s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:41<00:02,  1.08s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:42<00:01,  1.09s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.08s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0835, v_num=191]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0835, v_num=191]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.08s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.09s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.10s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.09s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.08s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.87it/s, loss=0.012, v_num=192] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.012, v_num=192]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.09s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:32,  1.10s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:31,  1.10s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:27,  1.19s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.13s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0126, v_num=193]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0126, v_num=193]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.15s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.17s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.16s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.17s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.17s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.0361, v_num=194] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.82it/s, loss=0.0361, v_num=194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.13s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.10s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0262, v_num=195] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.0262, v_num=195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.16s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.14s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.13s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0498, v_num=196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.0498, v_num=196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.10s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:36,  1.07s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.09s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.08s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:10<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.10s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.10s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.09s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:24,  1.09s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:20<00:22,  1.08s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:21<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.09s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.08s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.17s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.24, v_num=197]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.82it/s, loss=0.24, v_num=197]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.10s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.11s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.10s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.09s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.262, v_num=198] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.262, v_num=198]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.14s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.11s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.13s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.13s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.15s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.84it/s, loss=0.0741, v_num=199]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.0741, v_num=199]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.14s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.11s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:29,  1.10s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.08s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.09s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.09s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.10s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.10s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.09s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.08s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.09s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.10s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.14s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.299, v_num=200] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.81it/s, loss=0.299, v_num=200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.09s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:40,  1.08s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.17s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.16s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.16s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.16s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.17s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.17s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.15s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.12s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.12s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0356, v_num=201]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.80it/s, loss=0.0356, v_num=201]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.09s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.07s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:35,  1.10s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:33,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:19<00:23,  1.08s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.10s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.10s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.09s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.08s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:12,  1.07s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:11,  1.09s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.12s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0222, v_num=202]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.80it/s, loss=0.0222, v_num=202]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:46,  1.19s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.17s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:39,  1.17s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.16s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.13s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:29,  1.14s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:18,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.10s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.82it/s, loss=0.258, v_num=203] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.80it/s, loss=0.258, v_num=203]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.12s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:38,  1.16s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.16s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.16s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.15s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.18s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.15s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.17s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.18s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:23,  1.17s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.16s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:21,  1.17s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.17s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.17s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.18s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.15s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.14s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.204, v_num=204]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.204, v_num=204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.16s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.16s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.15s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:23,  1.16s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.17s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.16s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.16s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.15s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.16s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.13s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.0329, v_num=205] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.0329, v_num=205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.17s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.13s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.11s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.15s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.81it/s, loss=0.0961, v_num=206] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.78it/s, loss=0.0961, v_num=206]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.10s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.14s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:37,  1.15s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.11s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.16s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.15s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.15s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:10,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:09,  1.09s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:08,  1.10s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.09s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.11s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.10s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.11s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.81it/s, loss=0.0581, v_num=207] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.78it/s, loss=0.0581, v_num=207]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.15s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.15s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.16s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.15s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.18s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.22s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:14,  1.24s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:13,  1.25s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:12,  1.27s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:11,  1.27s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.24s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.23s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.21s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:41<00:05,  1.20s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.19s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.19s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:46<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.80it/s, loss=0.0803, v_num=208]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.78it/s, loss=0.0803, v_num=208]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.17s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.16s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.17s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.17s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.16s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.15s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:17,  1.09s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.14s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.16s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.14s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.14s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.15s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.16s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.103, v_num=209] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:57<00:00,  2.76it/s, loss=0.103, v_num=209]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.10s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.12s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.15s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.15s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.16s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.17s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:15,  1.17s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.18s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.18s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.17s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.12s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.0179, v_num=210] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:57<00:00,  2.77it/s, loss=0.0179, v_num=210]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.14s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.14s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.15s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.16s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.15s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:20,  1.19s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:19,  1.21s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.19s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.19s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.19s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:14,  1.17s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.16s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.16s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.16s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.79it/s, loss=0.022, v_num=211] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:57<00:00,  2.76it/s, loss=0.022, v_num=211]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.15s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.14s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.12s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.12s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.15s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.14s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.14s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:07,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.16s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.16s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.16s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.16s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.12s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:56<00:00,  2.77it/s, loss=0.0604, v_num=212]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.75it/s, loss=0.0604, v_num=212]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.12s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.17s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.14s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.15s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.13s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:15,  1.16s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.15s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.17s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.16s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.16s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.18s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.76it/s, loss=0.296, v_num=213] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.74it/s, loss=0.296, v_num=213]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.12s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.14s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.15s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.15s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.17s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.16s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.16s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.12s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.15s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:16,  1.15s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.14s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.13s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.15s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.14s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.15s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.21s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.19s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.75it/s, loss=0.0821, v_num=214] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.73it/s, loss=0.0821, v_num=214]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.11s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.16s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.18s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:41,  1.18s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:40,  1.18s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.17s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.16s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.16s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.16s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.15s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.15s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.18s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.19s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:27,  1.18s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:23,  1.16s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.16s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.16s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.16s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.16s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.16s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.14s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.17s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.19s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.19s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.19s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.18s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.18s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.16s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.15s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.16s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.75it/s, loss=0.0488, v_num=215] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.72it/s, loss=0.0488, v_num=215]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.18s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.16s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.16s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.17s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.17s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.17s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:37,  1.22s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:36,  1.21s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:34,  1.19s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.18s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.16s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.13s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.14s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:25,  1.14s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.16s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.15s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.14s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.15s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.14s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.15s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.15s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.18s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.16s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.16s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.16s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.17s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.18s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.18s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.16s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.18s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.20s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:57<00:00,  2.73it/s, loss=0.0374, v_num=216] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.71it/s, loss=0.0374, v_num=216]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.17s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.15s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.13s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.15s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:39,  1.32s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:36,  1.27s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:34,  1.24s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:33,  1.23s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:31,  1.20s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.19s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:28,  1.20s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.18s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:25,  1.15s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:23,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.14s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.15s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:27<00:19,  1.16s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:28<00:18,  1.16s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.16s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.16s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.16s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.15s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.15s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.16s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.17s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.18s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.18s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.71it/s, loss=0.0226, v_num=217]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.68it/s, loss=0.0226, v_num=217]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:45,  1.18s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:41,  1.19s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:40,  1.20s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:39,  1.19s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.18s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.17s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.17s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.17s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.18s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.17s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:29,  1.15s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:28,  1.15s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:27,  1.14s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.16s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:25,  1.16s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.17s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:23,  1.17s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.18s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:21,  1.18s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.17s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:28<00:18,  1.17s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.17s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.18s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.18s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.16s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.15s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:11,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.16s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.16s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.16s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.18s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.17s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.17s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:46<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:58<00:00,  2.70it/s, loss=0.279, v_num=218] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.67it/s, loss=0.279, v_num=218]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.13s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.17s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.15s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.15s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.16s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.15s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.16s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.17s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.16s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.18s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.18s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.19s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.18s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:26,  1.17s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:25,  1.17s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.15s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:22,  1.13s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:20,  1.14s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.13s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.13s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:17,  1.14s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:15,  1.14s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:12,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:34<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:35<00:10,  1.13s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:36<00:09,  1.15s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:37<00:08,  1.15s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:06,  1.15s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.15s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:41<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:42<00:03,  1.15s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:43<00:02,  1.17s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:44<00:01,  1.16s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:45<00:00,  1.13s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.66it/s, loss=0.0324, v_num=219] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.63it/s, loss=0.0324, v_num=219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.15s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:43,  1.18s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:42,  1.18s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.17s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:39,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.18s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.17s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.18s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:35,  1.18s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:34,  1.20s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.19s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:32,  1.19s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.18s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.20s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.19s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.18s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:26,  1.21s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:25,  1.21s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:24,  1.22s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.22s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:21,  1.22s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:27<00:20,  1.20s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:28<00:19,  1.19s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.19s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.18s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:15,  1.17s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:33<00:14,  1.19s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:34<00:13,  1.19s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:11,  1.20s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.20s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.19s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:39<00:08,  1.19s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:40<00:07,  1.18s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:41<00:05,  1.18s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.18s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.18s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:45<00:02,  1.18s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:46<00:01,  1.18s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:46<00:00,  1.17s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.66it/s, loss=0.0302, v_num=220] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [00:59<00:00,  2.64it/s, loss=0.0302, v_num=220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:44,  1.14s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.16s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:42,  1.15s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.16s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.16s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.14s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:37,  1.15s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.14s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:35,  1.13s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:34,  1.15s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.16s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:31,  1.16s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.17s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:17<00:29,  1.16s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:28,  1.18s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:27,  1.20s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:26,  1.19s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:24,  1.18s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:23<00:23,  1.18s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:24<00:22,  1.20s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:25<00:21,  1.17s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:26<00:19,  1.17s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:27<00:18,  1.17s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:29<00:17,  1.19s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:30<00:16,  1.20s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:31<00:15,  1.19s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:32<00:14,  1.17s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:33<00:13,  1.18s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:35<00:11,  1.16s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:36<00:10,  1.18s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:37<00:09,  1.19s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:38<00:08,  1.17s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:39<00:07,  1.17s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:40<00:05,  1.18s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:42<00:04,  1.19s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:43<00:03,  1.17s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:44<00:02,  1.19s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:45<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:46<00:00,  1.15s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:00<00:00,  2.62it/s, loss=0.0459, v_num=221] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:00<00:00,  2.60it/s, loss=0.0459, v_num=221]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:48,  1.25s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:46,  1.23s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:45,  1.22s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:44,  1.24s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.25s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.21s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.22s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:38,  1.21s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:37,  1.22s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.21s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.19s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:31,  1.18s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:30,  1.19s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:29,  1.19s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:28,  1.20s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.19s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:26,  1.20s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:22<00:25,  1.21s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.22s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.23s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:21,  1.22s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:27<00:20,  1.23s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:19,  1.24s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:18,  1.23s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:31<00:17,  1.23s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:16,  1.23s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:14,  1.23s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.23s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:36<00:12,  1.22s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:37<00:10,  1.21s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.20s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.19s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:41<00:07,  1.20s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:42<00:05,  1.20s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:43<00:04,  1.20s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:44<00:03,  1.20s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:46<00:02,  1.19s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:47<00:01,  1.19s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:47<00:00,  1.19s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:01<00:00,  2.57it/s, loss=0.188, v_num=222]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:01<00:00,  2.55it/s, loss=0.188, v_num=222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:47,  1.23s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:46,  1.24s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.25s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:45,  1.26s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.24s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.23s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.23s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.23s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.23s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.22s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.22s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.21s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:32,  1.21s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:31,  1.20s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.20s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:28,  1.20s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.20s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:26,  1.19s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:25,  1.20s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.21s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:22,  1.19s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:21,  1.20s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:27<00:20,  1.19s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:19,  1.20s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:17,  1.19s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:31<00:16,  1.20s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:15,  1.21s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:33<00:14,  1.19s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.20s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:36<00:11,  1.19s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:37<00:10,  1.19s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.19s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:39<00:08,  1.19s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:41<00:07,  1.19s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:42<00:05,  1.20s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:43<00:04,  1.19s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:44<00:03,  1.21s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:45<00:02,  1.20s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:47<00:01,  1.21s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:47<00:00,  1.19s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:01<00:00,  2.56it/s, loss=0.0275, v_num=223]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:02<00:00,  2.54it/s, loss=0.0275, v_num=223]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:46,  1.18s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:44,  1.17s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:44,  1.19s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:43,  1.20s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:41,  1.17s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:39,  1.16s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:38,  1.17s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:37,  1.17s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:36,  1.19s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:37,  1.25s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:37,  1.29s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:36,  1.31s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:35,  1.32s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:34,  1.32s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:32,  1.31s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:30,  1.28s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:28,  1.26s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.27s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:27,  1.32s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:25<00:26,  1.30s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:26<00:24,  1.28s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.27s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.26s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:30<00:19,  1.24s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:18,  1.23s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.23s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:15,  1.23s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:14,  1.23s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.23s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.21s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:10,  1.21s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:39<00:09,  1.21s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:41<00:08,  1.24s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.24s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.22s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:04,  1.23s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:45<00:03,  1.23s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.23s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.23s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:48<00:00,  1.22s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:01<00:00,  2.55it/s, loss=0.229, v_num=224]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:02<00:00,  2.53it/s, loss=0.229, v_num=224]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:46,  1.19s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:45,  1.19s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:44,  1.21s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:43,  1.21s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:42,  1.22s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.21s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.22s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:38,  1.20s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:37,  1.21s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.21s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:33,  1.20s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:32,  1.21s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:16<00:31,  1.20s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.21s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:29,  1.21s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:27,  1.21s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:21<00:27,  1.24s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:26,  1.24s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:25,  1.26s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.25s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:22,  1.24s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:20,  1.22s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:19,  1.22s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:18,  1.22s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:31<00:16,  1.19s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:15,  1.19s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:33<00:14,  1.20s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.19s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:36<00:11,  1.20s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:37<00:10,  1.21s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.21s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.21s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:41<00:07,  1.20s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:42<00:06,  1.21s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:43<00:04,  1.20s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:44<00:03,  1.20s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:45<00:02,  1.19s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:47<00:01,  1.20s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:47<00:00,  1.19s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:03<00:00,  2.48it/s, loss=0.0155, v_num=225] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:04<00:00,  2.46it/s, loss=0.0155, v_num=225]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:48,  1.24s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:47,  1.26s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.25s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:44,  1.23s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:42,  1.22s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.23s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.23s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.24s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.24s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.23s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:34,  1.22s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:32,  1.21s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:31,  1.22s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.21s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:29,  1.23s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:28,  1.23s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.23s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:25,  1.22s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.22s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:22,  1.20s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:26<00:21,  1.20s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:20,  1.18s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:18,  1.19s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:17,  1.20s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:31<00:16,  1.21s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:32<00:15,  1.19s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:14,  1.21s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.23s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:36<00:12,  1.23s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:37<00:11,  1.22s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:38<00:09,  1.21s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.21s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:41<00:07,  1.23s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:42<00:06,  1.24s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:04,  1.24s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:45<00:03,  1.24s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:46<00:02,  1.22s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:47<00:01,  1.22s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:48<00:00,  1.20s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:04<00:00,  2.45it/s, loss=0.0313, v_num=226] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:04<00:00,  2.43it/s, loss=0.0313, v_num=226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:47,  1.22s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:46,  1.22s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:45,  1.23s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:44,  1.25s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.24s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:42,  1.24s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.24s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.24s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.23s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:37,  1.24s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.24s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:34,  1.24s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:33,  1.23s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:31,  1.22s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.22s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:29,  1.23s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:28,  1.23s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.24s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:26,  1.25s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.23s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.23s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.23s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.27s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:20,  1.26s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:18,  1.26s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.26s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:16,  1.26s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:15,  1.25s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.27s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.25s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.24s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:39<00:10,  1.25s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.23s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.24s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.26s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:05,  1.27s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:46<00:03,  1.27s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.24s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.26s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:48<00:00,  1.22s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:05<00:00,  2.43it/s, loss=0.0372, v_num=227] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:05<00:00,  2.41it/s, loss=0.0372, v_num=227]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:48,  1.24s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:47,  1.25s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.26s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:45,  1.26s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:44,  1.26s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:43,  1.27s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:41,  1.26s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:10<00:40,  1.27s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:39,  1.28s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:38,  1.29s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:36,  1.27s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:15<00:34,  1.25s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:33,  1.24s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:32,  1.26s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.23s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:20<00:30,  1.26s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:28,  1.26s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.27s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:24<00:26,  1.28s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:25<00:25,  1.25s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:26<00:23,  1.26s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.26s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.25s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:30<00:19,  1.24s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:18,  1.25s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.26s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:16,  1.24s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:35<00:14,  1.24s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.26s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.25s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.24s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:40<00:09,  1.24s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:41<00:08,  1.23s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.26s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.23s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:45<00:04,  1.24s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:46<00:03,  1.25s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.24s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.26s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:49<00:00,  1.24s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:05<00:00,  2.42it/s, loss=0.0353, v_num=228] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:05<00:00,  2.40it/s, loss=0.0353, v_num=228]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:48,  1.24s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:45,  1.21s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:45,  1.23s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:43,  1.21s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:43,  1.24s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.22s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:40,  1.22s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.24s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.23s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:36,  1.22s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.21s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:34,  1.22s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:33,  1.24s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:32,  1.25s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:31,  1.26s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:30,  1.26s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:28,  1.25s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.26s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:25,  1.23s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.23s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.24s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.24s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.24s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:19,  1.25s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:18,  1.22s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.23s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:15,  1.22s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:14,  1.23s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:35<00:13,  1.25s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.25s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.26s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:39<00:09,  1.24s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:40<00:08,  1.24s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.25s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.24s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:04,  1.22s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:45<00:03,  1.23s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:46<00:02,  1.24s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.23s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:48<00:00,  1.22s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:06<00:00,  2.38it/s, loss=0.0612, v_num=229] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:07<00:00,  2.36it/s, loss=0.0612, v_num=229]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:49,  1.27s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:49,  1.30s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.27s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:45,  1.25s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:44,  1.26s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:43,  1.28s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:41,  1.27s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:10<00:40,  1.26s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.24s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:37,  1.26s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:37,  1.28s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:15<00:36,  1.29s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:34,  1.27s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:32,  1.25s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:31,  1.24s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:20<00:30,  1.25s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:28,  1.25s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.26s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:26,  1.26s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:25<00:25,  1.25s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:26<00:23,  1.25s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:22,  1.25s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.25s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:30<00:19,  1.25s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:18,  1.25s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.23s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:16,  1.24s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:35<00:15,  1.26s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.26s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.26s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.26s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:40<00:10,  1.25s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:41<00:08,  1.27s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.27s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.25s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:45<00:04,  1.23s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:46<00:03,  1.23s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.22s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.23s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:49<00:00,  1.23s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:07<00:00,  2.35it/s, loss=0.0416, v_num=230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:07<00:00,  2.33it/s, loss=0.0416, v_num=230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:51,  1.32s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:48,  1.27s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:46,  1.26s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:05<00:46,  1.28s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:45,  1.29s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:43,  1.29s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:42,  1.28s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:10<00:41,  1.28s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:39,  1.29s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:38,  1.30s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:14<00:37,  1.29s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:15<00:35,  1.27s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:16<00:34,  1.27s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:33,  1.27s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:19<00:32,  1.29s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:20<00:30,  1.27s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:21<00:29,  1.27s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:23<00:28,  1.27s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:24<00:27,  1.29s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:25<00:25,  1.29s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:26<00:23,  1.26s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:28<00:22,  1.27s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:29<00:21,  1.27s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:30<00:20,  1.27s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:31<00:19,  1.28s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:33<00:17,  1.25s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:34<00:16,  1.25s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:35<00:15,  1.28s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:37<00:14,  1.28s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:38<00:12,  1.27s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:39<00:11,  1.27s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:40<00:10,  1.30s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:42<00:08,  1.27s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:43<00:07,  1.27s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:44<00:06,  1.26s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:45<00:05,  1.26s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:47<00:03,  1.26s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:48<00:02,  1.26s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:49<00:01,  1.27s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:50<00:00,  1.26s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:08<00:00,  2.31it/s, loss=0.0642, v_num=231] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 158/158 [01:08<00:00,  2.29it/s, loss=0.0642, v_num=231]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:49,  1.27s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:46,  1.23s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:45,  1.23s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:44,  1.24s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:06<00:42,  1.21s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:07<00:41,  1.21s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:08<00:39,  1.21s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:39,  1.23s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:11<00:38,  1.24s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:12<00:37,  1.24s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:13<00:35,  1.23s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:14<00:35,  1.25s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:15<00:33,  1.23s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:17<00:32,  1.23s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:18<00:30,  1.23s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:19<00:29,  1.25s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:20<00:28,  1.24s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:22<00:27,  1.24s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:23<00:26,  1.26s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:24<00:24,  1.24s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:25<00:23,  1.23s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:27<00:21,  1.22s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:28<00:21,  1.24s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:29<00:20,  1.26s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:30<00:18,  1.26s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:32<00:17,  1.25s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:33<00:16,  1.27s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:34<00:15,  1.27s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:36<00:13,  1.27s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:37<00:12,  1.28s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:38<00:11,  1.29s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:39<00:10,  1.26s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:41<00:08,  1.25s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:42<00:07,  1.26s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:43<00:06,  1.26s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:44<00:05,  1.27s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:46<00:03,  1.25s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:47<00:02,  1.24s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:48<00:01,  1.25s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:49<00:00,  1.23s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lr</th>\n",
       "      <th>f1-0</th>\n",
       "      <th>f1-1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998473</td>\n",
       "      <td>0.992366</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998410</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998483</td>\n",
       "      <td>0.992126</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998445</td>\n",
       "      <td>0.993007</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998415</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998420</td>\n",
       "      <td>0.993464</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>0.997455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs  gamma      lr      f1-0      f1-1       acc\n",
       "0     10.0    0.0  0.0001  0.998473  0.992366  0.997455\n",
       "1     10.0    0.5  0.0001  0.998410  0.993631  0.997455\n",
       "2     10.0    2.0  0.0001  0.998483  0.992126  0.997455\n",
       "3     10.0    3.0  0.0001  0.998445  0.993007  0.997455\n",
       "4     25.0    0.0  0.0001  1.000000  1.000000  1.000000\n",
       "5     25.0    0.5  0.0001  1.000000  1.000000  1.000000\n",
       "6     25.0    2.0  0.0001  0.998415  0.993548  0.997455\n",
       "7     25.0    3.0  0.0001  1.000000  1.000000  1.000000\n",
       "8     35.0    0.0  0.0001  0.998420  0.993464  0.997455\n",
       "9     35.0    0.5  0.0001  1.000000  1.000000  1.000000\n",
       "10    35.0    2.0  0.0001  0.998430  0.993289  0.997455\n",
       "11    35.0    3.0  0.0001  1.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=5\n",
    "BATCH_SIZE=10\n",
    "EPOCHS=1\n",
    "GAMMA_0=2\n",
    "\n",
    "def get_prediction(x, model: pl.LightningModule):\n",
    "    model.freeze() # prepares model for predicting\n",
    "    probabilities = torch.softmax(model(x), dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def train_tune(config):\n",
    "    kfold = KFold(n_splits=K, shuffle=True)\n",
    "    reports = []\n",
    "    mean_f1s = []\n",
    "    for fold,(train_idx,val_idx) in enumerate(kfold.split(image_dataset)):\n",
    "        print(f'------------fold nº {fold}----------------------')\n",
    "\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                          image_dataset, \n",
    "                          batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "                          image_dataset,\n",
    "                          batch_size=BATCH_SIZE, sampler=val_subsampler)\n",
    "\n",
    "        # Train this fold\n",
    "#         model = ResNetCustom(gamma=GAMMA_0, class_sizes=[c0_s,c1_s])\n",
    "        model = ResNetCustom(config, class_sizes=[c0_s,c1_s])\n",
    "        model.SPE = len(trainloader)\n",
    "        model.EPOCHS = config['epochs']\n",
    "        trainer = pl.Trainer(max_epochs=config['epochs'], devices=1, accelerator=\"gpu\")\n",
    "        trainer.fit(model, trainloader)\n",
    "\n",
    "        # Test this fold\n",
    "        true_y, pred_y = [], []\n",
    "        for batch in tqdm(iter(testloader), total=len(testloader)):\n",
    "            x, y = batch\n",
    "            true_y.extend(y)\n",
    "            preds, probs = get_prediction(x, model)\n",
    "            pred_y.extend(preds.cpu())\n",
    "\n",
    "        report = classification_report(true_y, pred_y, output_dict=True)\n",
    "        reports.append(report)\n",
    "        mean_f1s.append((report['0']['f1-score']+report['1']['f1-score'])/2)\n",
    "#         print('=> CONFIG:', config)\n",
    "#         print(classification_report(true_y, pred_y))\n",
    "    max_f1_idx = mean_f1s.index(max(mean_f1s))\n",
    "    return reports[max_f1_idx]\n",
    "\n",
    "EPOCHS = [10, 25, 35]\n",
    "GAMMAS = [0, 0.5, 2, 3]\n",
    "LRS = [1e-4]\n",
    "\n",
    "grid_search = pd.DataFrame(columns=['epochs','gamma','lr','f1-0','f1-1','acc'])\n",
    "\n",
    "for epochs in EPOCHS:\n",
    "    for gamma in GAMMAS:\n",
    "        for lr in LRS:\n",
    "            config = {'epochs': epochs, 'gamma': gamma, 'lr': lr}\n",
    "            report = train_tune(config)\n",
    "            grid_search = grid_search.append(\n",
    "                            pd.Series(\n",
    "                                [epochs,gamma,lr,report['0']['f1-score'],report['1']['f1-score'],report['accuracy']],\n",
    "                                index=grid_search.columns), \n",
    "                            ignore_index=True)\n",
    "            grid_search.to_csv('./grid_search/plant_village_fuzzyfocalloss.csv')\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c6cd0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.85it/s, loss=0.00995, v_num=232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:56<00:00,  2.82it/s, loss=0.00995, v_num=232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.11s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.13s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:39,  1.13s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:37,  1.14s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:35,  1.12s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.13s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.13s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.13s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.13s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:28,  1.14s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:18<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:19<00:25,  1.12s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.12s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.11s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:20,  1.10s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.12s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:28<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.14s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.13s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.11s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:38<00:06,  1.12s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.14s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.14s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.15s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.11s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0259, v_num=233] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0259, v_num=233]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:46,  1.20s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:42,  1.12s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.13s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:41,  1.15s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:40,  1.14s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:38,  1.13s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:09<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.11s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:31,  1.09s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:30,  1.10s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.09s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:21,  1.09s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.10s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.11s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.09s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.12s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.12s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.09s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.11s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.12s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.12s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.15s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0155, v_num=234]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0155, v_num=234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:41,  1.07s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.09s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.11s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:36,  1.08s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:35,  1.08s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:34,  1.09s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:09<00:34,  1.10s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:32,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.12s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.13s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.13s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.11s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.10s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.12s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:28<00:15,  1.10s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:29<00:14,  1.10s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:30<00:12,  1.08s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.10s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:09,  1.10s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.09s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.10s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.11s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:38<00:05,  1.10s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:39<00:04,  1.09s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:40<00:03,  1.09s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.11s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.10s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.09s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.027, v_num=235]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.027, v_num=235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:42,  1.09s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:41,  1.10s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:41,  1.11s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:39,  1.11s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.10s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.12s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.11s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.13s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:33,  1.14s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.12s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.11s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:29,  1.12s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.11s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.11s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.13s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.11s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:19,  1.10s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:18,  1.11s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.13s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.12s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.11s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:09,  1.13s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.13s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.13s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.14s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.14s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.13s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.12s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:44<00:00,  1.10s/it]\u001b[A\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params\n",
      "---------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy | 0     \n",
      "1 | f1score   | BinaryF1Score  | 0     \n",
      "2 | model     | ResNet         | 23.5 M\n",
      "3 | fuzzyloss | FuzzyLoss      | 0     \n",
      "---------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.86it/s, loss=0.0271, v_num=236] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 158/158 [00:55<00:00,  2.83it/s, loss=0.0271, v_num=236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▎         | 1/40 [00:01<00:43,  1.12s/it]\u001b[A\n",
      "  5%|▌         | 2/40 [00:02<00:43,  1.13s/it]\u001b[A\n",
      "  8%|▊         | 3/40 [00:03<00:40,  1.09s/it]\u001b[A\n",
      " 10%|█         | 4/40 [00:04<00:40,  1.12s/it]\u001b[A\n",
      " 12%|█▎        | 5/40 [00:05<00:38,  1.10s/it]\u001b[A\n",
      " 15%|█▌        | 6/40 [00:06<00:37,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/40 [00:07<00:36,  1.11s/it]\u001b[A\n",
      " 20%|██        | 8/40 [00:08<00:36,  1.13s/it]\u001b[A\n",
      " 22%|██▎       | 9/40 [00:10<00:34,  1.12s/it]\u001b[A\n",
      " 25%|██▌       | 10/40 [00:11<00:33,  1.12s/it]\u001b[A\n",
      " 28%|██▊       | 11/40 [00:12<00:32,  1.12s/it]\u001b[A\n",
      " 30%|███       | 12/40 [00:13<00:31,  1.14s/it]\u001b[A\n",
      " 32%|███▎      | 13/40 [00:14<00:30,  1.12s/it]\u001b[A\n",
      " 35%|███▌      | 14/40 [00:15<00:28,  1.11s/it]\u001b[A\n",
      " 38%|███▊      | 15/40 [00:16<00:27,  1.12s/it]\u001b[A\n",
      " 40%|████      | 16/40 [00:17<00:26,  1.10s/it]\u001b[A\n",
      " 42%|████▎     | 17/40 [00:18<00:25,  1.11s/it]\u001b[A\n",
      " 45%|████▌     | 18/40 [00:20<00:24,  1.12s/it]\u001b[A\n",
      " 48%|████▊     | 19/40 [00:21<00:23,  1.11s/it]\u001b[A\n",
      " 50%|█████     | 20/40 [00:22<00:22,  1.12s/it]\u001b[A\n",
      " 52%|█████▎    | 21/40 [00:23<00:21,  1.13s/it]\u001b[A\n",
      " 55%|█████▌    | 22/40 [00:24<00:20,  1.15s/it]\u001b[A\n",
      " 57%|█████▊    | 23/40 [00:25<00:19,  1.14s/it]\u001b[A\n",
      " 60%|██████    | 24/40 [00:26<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▎   | 25/40 [00:27<00:16,  1.11s/it]\u001b[A\n",
      " 65%|██████▌   | 26/40 [00:29<00:15,  1.12s/it]\u001b[A\n",
      " 68%|██████▊   | 27/40 [00:30<00:14,  1.12s/it]\u001b[A\n",
      " 70%|███████   | 28/40 [00:31<00:13,  1.11s/it]\u001b[A\n",
      " 72%|███████▎  | 29/40 [00:32<00:12,  1.10s/it]\u001b[A\n",
      " 75%|███████▌  | 30/40 [00:33<00:11,  1.11s/it]\u001b[A\n",
      " 78%|███████▊  | 31/40 [00:34<00:10,  1.11s/it]\u001b[A\n",
      " 80%|████████  | 32/40 [00:35<00:08,  1.11s/it]\u001b[A\n",
      " 82%|████████▎ | 33/40 [00:36<00:07,  1.12s/it]\u001b[A\n",
      " 85%|████████▌ | 34/40 [00:37<00:06,  1.10s/it]\u001b[A\n",
      " 88%|████████▊ | 35/40 [00:39<00:05,  1.12s/it]\u001b[A\n",
      " 90%|█████████ | 36/40 [00:40<00:04,  1.13s/it]\u001b[A\n",
      " 92%|█████████▎| 37/40 [00:41<00:03,  1.13s/it]\u001b[A\n",
      " 95%|█████████▌| 38/40 [00:42<00:02,  1.14s/it]\u001b[A\n",
      " 98%|█████████▊| 39/40 [00:43<00:01,  1.14s/it]\u001b[A\n",
      "100%|██████████| 40/40 [00:43<00:00,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 311}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 82}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 393}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 393}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "config = {'epochs': 25, 'gamma': 2, 'lr': 1e-3}\n",
    "report = train_tune(config)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e08f8fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean loss\n",
    "splits = 49\n",
    "ml = [sum(mean_losses[i:i + splits])/splits for i in range(0, len(mean_losses), splits)]\n",
    "ma = [sum(mean_acc[i:i + splits])/splits for i in range(0, len(mean_acc), splits)]\n",
    "mf = [sum(mean_f1s[i:i + splits])/splits for i in range(0, len(mean_f1s), splits)]\n",
    "x_axis = [i for i in range(404)]\n",
    "\n",
    "for i, l in enumerate(mean_losses):\n",
    "    mean_losses[i] = l.cpu().detach()\n",
    "plt.plot(x_axis, ml, 'g', label='Loss')\n",
    "plt.plot(x_axis, ma, 'b', label='Accuracy')\n",
    "plt.plot(x_axis, mf, 'r', label='F1-score')\n",
    "plt.title('Training metrics')\n",
    "plt.xlabel('Épocas')\n",
    "# plt.ylabel('Loss media')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c70e71d",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">UTKFace</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00b44a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 11317 / Class 1: 2589 / BDeg:  4.371185786017768\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_dataset = datasets.ImageFolder('../data/UTKFace/train',data_transforms)\n",
    "\n",
    "# Provocar bias cogiendo un porcentaje de la clase 1 solamente (modificando el porcentaje hasta obtener b_deg deseado)\n",
    "class_0_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==0).flatten()\n",
    "class_1_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==1).flatten()\n",
    "class_1_idxs = class_1_idxs[torch.randperm(len(class_1_idxs))[:int(len(class_1_idxs)*.209)]]\n",
    "\n",
    "c0_s, c1_s = len(class_0_idxs), len(class_1_idxs)\n",
    "b_deg = c0_s / c1_s\n",
    "print('Class 0:', len(class_0_idxs), '/ Class 1:', len(class_1_idxs), '/ BDeg: ', b_deg)\n",
    "\n",
    "class_1_subset = Subset(image_dataset, class_1_idxs)\n",
    "class_0_subset = Subset(image_dataset, class_0_idxs)\n",
    "image_dataset = ConcatDataset([class_0_subset, class_1_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "394906f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "class ResNetCustom(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 gamma=0.,\n",
    "                 class_sizes=[1,1],\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.gamma = config['gamma']\n",
    "        self.class_sizes = class_sizes\n",
    "        self.lr = config['lr']\n",
    "        self.n_classes = len(self.class_sizes)\n",
    "        \n",
    "        # metrics\n",
    "        task = \"multiclass\" if self.n_classes > 2 else \"binary\"\n",
    "        self.accuracy = torchmetrics.Accuracy(task=task, num_classes=self.n_classes)\n",
    "        self.f1score = torchmetrics.F1Score(task=task, num_classes=self.n_classes)\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.n_classes, bias=True)\n",
    "            \n",
    "        self.fuzzyloss = FuzzyLoss(gamma=gamma, class_sizes=self.class_sizes).cuda()\n",
    "#         self.fuzzyloss = nn.CrossEntropyLoss().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        y_onehot = F.one_hot(y, num_classes=self.n_classes).long()\n",
    "        acc = self.accuracy(logits, y_onehot)\n",
    "        f1s = self.f1score(logits, y_onehot)\n",
    "        mean_acc.append(acc.item())\n",
    "        mean_f1s.append(f1s.item())\n",
    "        \n",
    "        mean_loss, losses = self.fuzzyloss(logits, y)\n",
    "#         mean_loss = self.fuzzyloss(logits, y)\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "        # Update focal loss with Fuzzy Control System\n",
    "        self.fuzzyloss.update_hyperparams(losses, y)\n",
    "        return mean_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=1e-4)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
    "                                optimizer ,max_lr=0.01,\n",
    "                                steps_per_epoch=self.SPE,\n",
    "                                epochs=self.EPOCHS)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53e7d9bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:42<00:00,  2.76it/s, loss=0.373, v_num=151]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:43<00:00,  2.76it/s, loss=0.373, v_num=151]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:19<00:00,  1.15s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:41<00:00,  2.77it/s, loss=0.366, v_num=152]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:41<00:00,  2.77it/s, loss=0.366, v_num=152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:21<00:00,  1.15s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:40<00:00,  2.78it/s, loss=0.396, v_num=153]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:40<00:00,  2.78it/s, loss=0.396, v_num=153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:17<00:00,  1.14s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:39<00:00,  2.78it/s, loss=0.453, v_num=154]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:40<00:00,  2.78it/s, loss=0.453, v_num=154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:18<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:40<00:00,  2.78it/s, loss=0.316, v_num=155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1113/1113 [06:40<00:00,  2.78it/s, loss=0.316, v_num=155]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:08<00:00,  1.11s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:41<00:00,  2.77it/s, loss=0.405, v_num=156]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:41<00:00,  2.77it/s, loss=0.405, v_num=156]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:16<00:00,  1.14s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:44<00:00,  2.75it/s, loss=0.409, v_num=157]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:44<00:00,  2.75it/s, loss=0.409, v_num=157]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:20<00:00,  1.15s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:45<00:00,  2.75it/s, loss=0.395, v_num=158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:45<00:00,  2.74it/s, loss=0.395, v_num=158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:23<00:00,  1.16s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:49<00:00,  2.72it/s, loss=0.481, v_num=159]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:49<00:00,  2.72it/s, loss=0.481, v_num=159]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:26<00:00,  1.17s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:51<00:00,  2.71it/s, loss=0.365, v_num=160]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:51<00:00,  2.70it/s, loss=0.365, v_num=160]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:25<00:00,  1.17s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [06:56<00:00,  2.67it/s, loss=0.352, v_num=161]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [06:57<00:00,  2.67it/s, loss=0.352, v_num=161]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:30<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [07:06<00:00,  2.61it/s, loss=0.471, v_num=162]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [07:06<00:00,  2.61it/s, loss=0.471, v_num=162]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:35<00:00,  1.20s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [07:19<00:00,  2.53it/s, loss=0.403, v_num=163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [07:20<00:00,  2.53it/s, loss=0.403, v_num=163]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:38<00:00,  1.21s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [07:33<00:00,  2.45it/s, loss=0.326, v_num=164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [07:34<00:00,  2.45it/s, loss=0.326, v_num=164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:38<00:00,  1.21s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [07:34<00:00,  2.45it/s, loss=0.392, v_num=165]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=35` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 1113/1113 [07:35<00:00,  2.44it/s, loss=0.392, v_num=165]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:45<00:00,  1.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lr</th>\n",
       "      <th>f1-0</th>\n",
       "      <th>f1-1</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.905232</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.837828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.884323</td>\n",
       "      <td>0.522140</td>\n",
       "      <td>0.813736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.894760</td>\n",
       "      <td>0.509165</td>\n",
       "      <td>0.826681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs  gamma     lr      f1-0      f1-1       acc\n",
       "0    10.0    0.0  0.001  0.905232  0.438356  0.837828\n",
       "1    25.0    0.0  0.001  0.884323  0.522140  0.813736\n",
       "2    35.0    0.0  0.001  0.894760  0.509165  0.826681"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=5\n",
    "BATCH_SIZE=10\n",
    "EPOCHS=1\n",
    "GAMMA_0=2\n",
    "\n",
    "def get_prediction(x, model: pl.LightningModule):\n",
    "    model.freeze() # prepares model for predicting\n",
    "    probabilities = torch.softmax(model(x), dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "def train_tune(config):\n",
    "    kfold = KFold(n_splits=K, shuffle=True)\n",
    "    reports = []\n",
    "    mean_f1s = []\n",
    "    for fold,(train_idx,val_idx) in enumerate(kfold.split(image_dataset)):\n",
    "        print(f'------------fold nº {fold}----------------------')\n",
    "\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                          image_dataset, \n",
    "                          batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "                          image_dataset,\n",
    "                          batch_size=BATCH_SIZE, sampler=val_subsampler)\n",
    "\n",
    "        # Train this fold\n",
    "#         model = ResNetCustom(gamma=GAMMA_0, class_sizes=[c0_s,c1_s])\n",
    "        model = ResNetCustom(config, class_sizes=[c0_s,c1_s])\n",
    "        model.SPE = len(trainloader)\n",
    "        model.EPOCHS = config['epochs']\n",
    "        trainer = pl.Trainer(max_epochs=config['epochs'], devices=1, accelerator=\"gpu\")\n",
    "        trainer.fit(model, trainloader)\n",
    "\n",
    "        # Test this fold\n",
    "        true_y, pred_y = [], []\n",
    "        for batch in tqdm(iter(testloader), total=len(testloader)):\n",
    "            x, y = batch\n",
    "            true_y.extend(y)\n",
    "            preds, probs = get_prediction(x, model)\n",
    "            pred_y.extend(preds.cpu())\n",
    "\n",
    "        report = classification_report(true_y, pred_y, output_dict=True)\n",
    "        reports.append(report)\n",
    "        mean_f1s.append((report['0']['f1-score']+report['1']['f1-score'])/2)\n",
    "#         print('=> CONFIG:', config)\n",
    "#         print(classification_report(true_y, pred_y))\n",
    "    max_f1_idx = mean_f1s.index(max(mean_f1s))\n",
    "    return reports[max_f1_idx]\n",
    "\n",
    "EPOCHS = [10, 25, 35]\n",
    "GAMMAS = [0]\n",
    "LRS = [1e-3]\n",
    "\n",
    "grid_search = pd.DataFrame(columns=['epochs','gamma','lr','f1-0','f1-1','acc'])\n",
    "\n",
    "for epochs in EPOCHS:\n",
    "    for gamma in GAMMAS:\n",
    "        for lr in LRS:\n",
    "            config = {'epochs': epochs, 'gamma': gamma, 'lr': lr}\n",
    "            report = train_tune(config)\n",
    "            grid_search = grid_search.append(\n",
    "                            pd.Series(\n",
    "                                [epochs,gamma,lr,report['0']['f1-score'],report['1']['f1-score'],report['accuracy']],\n",
    "                                index=grid_search.columns), \n",
    "                            ignore_index=True)\n",
    "            grid_search.to_csv('./grid_search/UTKFace_baseline.csv')\n",
    "grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cdb50649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:40<00:00,  2.78it/s, loss=0.365, v_num=166]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:40<00:00,  2.78it/s, loss=0.365, v_num=166]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:12<00:00,  1.12s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:40<00:00,  2.78it/s, loss=0.362, v_num=167]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:40<00:00,  2.78it/s, loss=0.362, v_num=167]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:11<00:00,  1.12s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:41<00:00,  2.77it/s, loss=0.305, v_num=168]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:42<00:00,  2.77it/s, loss=0.305, v_num=168]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:12<00:00,  1.12s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:42<00:00,  2.76it/s, loss=0.342, v_num=169]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:43<00:00,  2.76it/s, loss=0.342, v_num=169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:10<00:00,  1.11s/it]\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "C:\\Users\\laraquij\\Anaconda3\\envs\\tfg_dani\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:45<00:00,  2.75it/s, loss=0.419, v_num=170]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 1113/1113 [06:45<00:00,  2.74it/s, loss=0.419, v_num=170]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [05:15<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.8777643747486932, 'recall': 0.9566170026292725, 'f1-score': 0.9154959110924721, 'support': 2282}, '1': {'precision': 0.6632653061224489, 'recall': 0.3907815631262525, 'f1-score': 0.4918032786885246, 'support': 499}, 'accuracy': 0.8550880978065444, 'macro avg': {'precision': 0.7705148404355711, 'recall': 0.6736992828777625, 'f1-score': 0.7036495948904984, 'support': 2781}, 'weighted avg': {'precision': 0.8392764081019849, 'recall': 0.8550880978065444, 'f1-score': 0.8394719543971935, 'support': 2781}}\n"
     ]
    }
   ],
   "source": [
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "config = {'epochs': 25, 'gamma': 0, 'lr': 1e-3}\n",
    "report = train_tune(config)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10627f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean loss\n",
    "ml = [sum(mean_losses[i:i + splits])/splits for i in range(0, len(mean_losses), splits)]\n",
    "ma = [sum(mean_acc[i:i + splits])/splits for i in range(0, len(mean_acc), splits)]\n",
    "mf = [sum(mean_f1s[i:i + splits])/splits for i in range(0, len(mean_f1s), splits)]\n",
    "x_axis = [i for i in range(2840)]\n",
    "\n",
    "splits=49\n",
    "for i, l in enumerate(mean_losses):\n",
    "    mean_losses[i] = l.cpu().detach()\n",
    "plt.plot(x_axis, ml, 'g', label='Loss')\n",
    "plt.plot(x_axis, ma, 'b', label='Accuracy')\n",
    "plt.plot(x_axis, mf, 'r', label='F1-score')\n",
    "plt.title('Training metrics')\n",
    "plt.xlabel('Épocas')\n",
    "# plt.ylabel('Loss media')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa5df61",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">gender_clf</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27391d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 23243 / Class 1: 4967 / BDeg:  4.679484598349104\n"
     ]
    }
   ],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "image_dataset = datasets.ImageFolder('../data/gender_clf/train',data_transforms)\n",
    "\n",
    "# Provocar bias cogiendo un porcentaje de la clase 1 solamente (modificando el porcentaje hasta obtener b_deg deseado)\n",
    "class_0_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==0).flatten()\n",
    "class_1_idxs = torch.nonzero(torch.Tensor(image_dataset.targets)==1).flatten()\n",
    "class_1_idxs = class_1_idxs[torch.randperm(len(class_1_idxs))[:int(len(class_1_idxs)*.209)]]\n",
    "\n",
    "c0_s, c1_s = len(class_0_idxs), len(class_1_idxs)\n",
    "b_deg = c0_s / c1_s\n",
    "print('Class 0:', len(class_0_idxs), '/ Class 1:', len(class_1_idxs), '/ BDeg: ', b_deg)\n",
    "\n",
    "class_1_subset = Subset(image_dataset, class_1_idxs)\n",
    "class_0_subset = Subset(image_dataset, class_0_idxs)\n",
    "image_dataset = ConcatDataset([class_0_subset, class_1_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e588a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "mean_losses = []\n",
    "mean_acc = []\n",
    "mean_f1s = []\n",
    "\n",
    "class ResNetCustom(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 gamma=0.,\n",
    "                 class_sizes=[1,1],\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.n_classes = len(class_sizes)\n",
    "        \n",
    "        # metrics\n",
    "        task = \"multiclass\" if self.n_classes > 2 else \"binary\"\n",
    "        self.accuracy = torchmetrics.Accuracy(task=task, num_classes=self.n_classes)\n",
    "        self.f1score = torchmetrics.F1Score(task=task, num_classes=self.n_classes)\n",
    "        \n",
    "        self.model = resnet50(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, self.n_classes, bias=True)\n",
    "            \n",
    "#         self.fuzzyloss = FuzzyLoss(gamma=gamma, class_sizes=class_sizes).cuda()\n",
    "        self.fuzzyloss = nn.CrossEntropyLoss().cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_no):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        y_onehot = F.one_hot(y, num_classes=self.n_classes).long()\n",
    "        acc = self.accuracy(logits, y_onehot)\n",
    "        f1s = self.f1score(logits, y_onehot)\n",
    "        mean_acc.append(acc.item())\n",
    "        mean_f1s.append(f1s.item())\n",
    "        \n",
    "#         mean_loss, losses = self.fuzzyloss(logits, y)\n",
    "        mean_loss = self.fuzzyloss(logits, y)\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "        # Update focal loss with Fuzzy Control System\n",
    "#         self.fuzzyloss.update_hyperparams(losses, y)\n",
    "        return mean_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=1e-4)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": torch.optim.lr_scheduler.OneCycleLR(\n",
    "                                optimizer ,max_lr=0.01,\n",
    "                                steps_per_epoch=len(trainloader),\n",
    "                                epochs=EPOCHS)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc70ab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold nº 0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1bd18bc4cf4168a1b83bbec94e782d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a96164ba2a547138cc2269c2b722d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.875     0.987     0.927      4615\n",
      "           1      0.860     0.365     0.513      1027\n",
      "\n",
      "    accuracy                          0.874      5642\n",
      "   macro avg      0.867     0.676     0.720      5642\n",
      "weighted avg      0.872     0.874     0.852      5642\n",
      "\n",
      "------------fold nº 1----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b731326106cc46208c12fd9bd4f41f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc728b304ac7458d9b930a351995db15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.902     0.971     0.935      4637\n",
      "           1      0.794     0.513     0.624      1005\n",
      "\n",
      "    accuracy                          0.890      5642\n",
      "   macro avg      0.848     0.742     0.779      5642\n",
      "weighted avg      0.883     0.890     0.880      5642\n",
      "\n",
      "------------fold nº 2----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5558b886ddbf4547a0c0f09995fb593d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead446aa1f76452f901128564bf111c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.938     0.906     0.922      4650\n",
      "           1      0.620     0.718     0.665       992\n",
      "\n",
      "    accuracy                          0.873      5642\n",
      "   macro avg      0.779     0.812     0.793      5642\n",
      "weighted avg      0.882     0.873     0.876      5642\n",
      "\n",
      "------------fold nº 3----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed554f990e224146a9d1c67118a4a0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0c7f01057e4e2f96a39afe44139f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.954     0.834     0.890      4678\n",
      "           1      0.500     0.805     0.617       964\n",
      "\n",
      "    accuracy                          0.829      5642\n",
      "   macro avg      0.727     0.820     0.753      5642\n",
      "weighted avg      0.876     0.829     0.843      5642\n",
      "\n",
      "------------fold nº 4----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:467: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  f\"The flag `devices={devices}` will be ignored, \"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | accuracy  | BinaryAccuracy   | 0     \n",
      "1 | f1score   | BinaryF1Score    | 0     \n",
      "2 | model     | ResNet           | 23.5 M\n",
      "3 | fuzzyloss | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/d/miniconda3/envs/tfg/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9427ef1042cb48b0a28eb3caa0101441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f36a58881864ba8b7bc84b9de9397b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/565 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.869     0.991     0.926      4663\n",
      "           1      0.868     0.289     0.434       979\n",
      "\n",
      "    accuracy                          0.869      5642\n",
      "   macro avg      0.869     0.640     0.680      5642\n",
      "weighted avg      0.869     0.869     0.841      5642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=25\n",
    "K=5\n",
    "GAMMA_0=2\n",
    "BATCH_SIZE=10\n",
    "\n",
    "def get_prediction(x, model: pl.LightningModule):\n",
    "    model.freeze() # prepares model for predicting\n",
    "    probabilities = torch.softmax(model(x), dim=1)\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "kfold = KFold(n_splits=K, shuffle=True)\n",
    "for fold,(train_idx,val_idx) in enumerate(kfold.split(image_dataset)):\n",
    "    print(f'------------fold nº {fold}----------------------')\n",
    "    \n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      image_dataset, \n",
    "                      batch_size=BATCH_SIZE, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      image_dataset,\n",
    "                      batch_size=BATCH_SIZE, sampler=val_subsampler)\n",
    "    \n",
    "    # Train this fold\n",
    "    model = ResNetCustom(gamma=GAMMA_0, class_sizes=[c0_s,c1_s])\n",
    "    trainer = pl.Trainer(gpus=1, max_epochs=EPOCHS, devices=1, accelerator=\"gpu\")\n",
    "    trainer.fit(model, trainloader)\n",
    "    \n",
    "    # Test this fold\n",
    "    true_y, pred_y = [], []\n",
    "    for batch in tqdm(iter(testloader), total=len(testloader)):\n",
    "        x, y = batch\n",
    "        true_y.extend(y)\n",
    "        preds, probs = get_prediction(x, model)\n",
    "        pred_y.extend(preds.cpu())\n",
    "    \n",
    "    print(classification_report(true_y, pred_y, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9b70e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot mean loss\n",
    "x_axis = [i for i in range(5643)]\n",
    "\n",
    "splits=50\n",
    "plt.plot(x_axis, [sum(mean_losses[i:i + splits])/splits for i in range(0, len(mean_losses), splits)], 'g', label='Loss')\n",
    "plt.plot(x_axis, [sum(mean_acc[i:i + splits])/splits for i in range(0, len(mean_acc), splits)], 'b', label='Accuracy')\n",
    "# plt.plot(x_axis, [sum(mean_f1s[i:i + splits])/splits for i in range(0, len(mean_f1s), splits)], 'r', label='F1-score')\n",
    "plt.title('Training metrics')\n",
    "plt.xlabel('Épocas')\n",
    "# plt.ylabel('Loss media')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
