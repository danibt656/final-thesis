En determinadas ocasiones, no siempre se puede alterar artificialmente la distribución de los datos \cite{yan2019joint}. Véase el ejemplo de un dataset compuesto de radiografías para una determinada enfermedad \cite{rahimzadeh2020modified}; Usar aquí métodos generativos, como las GAN, implica crear radiografías de pacientes que realmente no existen, pudiendo llegar a ``confundir'' al algoritmo \cite{rahimzadeh2020modified}. Además, los métodos a nivel de datos tienen el inconveniente de añadir tiempo extra al entrenamiento de los clasificadores \cite{han2020toward,johnson2019survey}, pues hay un paso previo de entrenamiento y generación sobre el dominio objetivo (imágenes faciales, radiografías...).

Por todo ello, la otra familia de métodos que mitigan el desbalanceo de clases lo hacen modificando la estructura interna de los algoritmos clasificadores, sin alterar la de los datasets \cite{zhao2021lightweight,zhong2021improving,han2020toward}. Así, se persigue que todas las clases tengan una contribución más igualitaria al modelo, pese a no estar balanceadas en número absoluto de muestras. Varios estudios \cite{liu2017fuzzy,cho2020instance,patel2017classification,vluymans2019dealing,hong2021fuzzy,fernandez2010solving,tuncc2020fuzzy,lin2017focal} utilizan funciones de pérdida dinámicas para ajustar el nivel de contribución de cada clase al aprendizaje, y quizás la más representativa es la Loss Focal de \citet{lin2017focal}. Otro ejemplo es \citet{li2019learning}, que diseña un sistema de reponderación ubicua (del inglés \textit{Ubiquitous Reweighting}) para balancear la contribución de clases y muestras individuales a la pérdida de entropía cruzada.

Otros autores aplican el llamado ``suavizado de etiquetas'' \cite{zhong2021improving,Szegedy_2016_CVPR} al problema del desbalanceo, si bien su efectividad sólo llega a ser notable en entornos con gran cantidad de clases (habitualmente más de 50), por lo que pierde interés para este trabajo. En \citet{liu2022solving}, se resuelve la infra-representación de radiografías de pacientes con covid-19 frente a los sanos con un sistema mixto que utiliza dos redes convolucionales y un mecanismo de repetición para que el modelo visite más frecuentemente las muestras minoritarias. Este sistema se conoce como PRM-IM (\textit{Probabilistic Relational Model for IMbalanced learning}), y en \citet{guo2004learning} incluyen la creación de conjuntos de clasificadores (\textit{ensembles}) para mejorar el rendimiento de un único modelo .
% En línea con la creación de \textit{ensembles}, en \cite{guo2004learning} se combina generación sintética de muestras infra-representadas con un conjunto de clasificadores.
Por último, en \citet{khan2017cost} se usan matrices de costes para imponer penalizaciones más altas al algoritmo cuando éste clasifica erróneamente una muestra de una clase minoritaria, que cuando lo hace con una mayoritaria. Otros estudios \cite{patel2017classification,cho2020instance,liu2017fuzzy} usan sistemas de control por lógica difusa para adaptar algoritmos de índole diversa a entornos desbalanceados.