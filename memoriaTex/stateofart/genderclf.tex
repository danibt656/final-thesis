La clasificación de género facial (o cualquier otro tipo de clasificación basada en imágenes) es un proceso que, a rasgos generales, suele dividirse en dos fases. La primera consiste en la extracción de características en forma de vectores de las imágenes que componen el dataset, y en la segunda fase se envían dichos vectores a un modelo que predice la etiqueta final, como puede ser una Máquinas de Vector Soporte (SVM) ó un Perceptrón Multicapa (MLP). En el estado del arte estudiado, los algoritmos de clasificación se dividen entre los que usan clasificadores tradicionales para aprender de la información de los vectores de características \cite{loo2018influence,lin2020face,khryashchev2013adaptive,tianyu2018human}, y los que utilizan Redes Neuronales Convolucionales (CNNs) para unificar las fases de extracción y predicción en una única arquitectura \cite{wu2020gender,islam2020human,garain2021gra_net,agbo2020deeply,sumi2021human,zhang2020gender}. Dichas familias de métodos se resumen a continuación:

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Métodos tradicionales\label{SUBSEC:TRADITIONAL}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

En estas técnicas, el primer paso es realizar una extracción de características manual, pre-procesando las imágenes para extraer sus Histogramas de Gradientes Orientados (HOG) \cite{dalal2005histograms}, o Patrones Locales Binarios (LBP) \cite{tianyu2018human}. Luego, estos conjuntos de características sirven para alimentar el aprendizaje de modelos de mayor o menor complejidad. Una técnica común a muchos trabajos es el uso de un clasificador sencillo como las SVM \cite{lin2020face,hiremath2021human,tianyu2018human,khryashchev2013adaptive,verma2019local,loo2018influence}, especializado en problemas de clasificación binaria; lo cual, por otro lado, lo hace ideal para un problema como la distinción de género \cite{khryashchev2013adaptive}. De forma similar, en \citet{poornima2021classification} se compara el rendimiento del SVM con respecto al \textit{Random Forest} (RF), o su variante \textit{Adaptive Boosting} (AdaBoost), concluyendo que RF puede obtener un rendimiento notablemente superior. Estudios más complejos y recientes han empleado técnicas de aprendizaje evolutivo \cite{yilmaz2021evolutionary}, pero también los hay que emplean métodos tan clásicos como los K vecinos próximos \cite{lin2020face}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Redes convolucionales\label{SUBSEC:CNNS}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

No obstante, en comparación con los métodos tradicionales, en el campo de la clasificación de género las CNNs han probado tener el mejor rendimiento \cite{ahmed2019facial,rezaoana2020detection,wu2020gender}. Esto es debido a que los filtros de extracción de características se optimizan automáticamente en el entrenamiento de la propia red, mientras que en los métodos anteriores esta extracción se realiza manualmente en una fase previa. Además, cuando se usan algoritmos tradicionales, basados en vectores de píxeles, se puede perder información muy valiosa sobre la interacción espacial entre ellos. Las CNNs pueden extraer esa información de los ``vecindarios de píxeles'' de forma eficiente, por medio de la convolución, y luego usar esa información en las capas densamente conexas para la predicción final.

% En el estado del arte estudiado, los investigadores toman tres opciones a la hora de usar un modelo de clasificación facial basado en CNNs: o bien usan un modelo pre-entrenado, o bien modifican uno de dichos modelos, o bien crean el suyo propio desde cero.

Los modelos convolucionales más relevantes son los basados en VGG \cite{simonyan2014very} y ResNet \cite{he2016deep}, aunque hay otros como GoogLeNet o Inception \cite{szegedy2015going}. Por ejemplo, en \citet{gurnani2019saf}, una combinación de VGG-16 para la extracción de características faciales con un clasificador basado en AlexNet \cite{krizhevsky2017imagenet} da lugar a un clasificador combinado de edad, género y expresión facial. O en el trabajo de  \citet{zhang2020gender} proponen una VGG-19 con imágenes RGB-D (combinación de canales de color y un ``mapa de profundidad'') para detectar el género en imágenes de cuerpo entero. Por otro lado, en \citet{lin2020face} un extractor de características basado en las capas convolucionales de ResNet-50 se une a un clasificador SVM para distinguir género en imágenes faciales. Por último, algunos estudios proponen arquitecturas prometedoras construidas prácticamente desde cero: la red propuesta en \citet{sumi2021human} (aunque lejanamente inspirada en VGG) logra resultados comparativamente superiores a métodos de estado del arte que combinaban LBP con redes neuronales no convolucionales.
 
% vgg16/19 -> zhang2020gender (20), gurnani2019saf (28) sumi2021human (13)(comparada con state-of-art LBP), simonyan2014very (autor)

% resnet -> lin2020face (3)(se basa en resnet), he2016deep (autor)

% cnn propia -> sumi2021human (13)

